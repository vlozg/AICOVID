{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[Torch009_base] AICOVID_115M.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KkxxsDa8r0ql",
        "g2Lc0HIA2ZjG"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e41deeeafe184838bb2ec973db7cbbc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a3b0e98c25ce4dea9f362f4fee26dea6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0db17309bedf4e5598ae0b03b63124c7",
              "IPY_MODEL_c1f94ff477ce4cc3a0fde6c4c437f983",
              "IPY_MODEL_d95ed8bbb98d49dbb741fb3610f8b728"
            ]
          }
        },
        "a3b0e98c25ce4dea9f362f4fee26dea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "0db17309bedf4e5598ae0b03b63124c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2e38e8f06d5d4331aaa3ccbd62607509",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validation sanity check:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f878bc609a6427da8de0eeacfe87b3c"
          }
        },
        "c1f94ff477ce4cc3a0fde6c4c437f983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_40c6457b6fdb4b55bcc5aebf4e5af277",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53010b9b5f5245f1a16670e02e3912bf"
          }
        },
        "d95ed8bbb98d49dbb741fb3610f8b728": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1fb73726d1a94c8abf028a062ce0b59e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:01&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b8c66bbf7b54d3596ad8c8cf81f2398"
          }
        },
        "2e38e8f06d5d4331aaa3ccbd62607509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f878bc609a6427da8de0eeacfe87b3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40c6457b6fdb4b55bcc5aebf4e5af277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53010b9b5f5245f1a16670e02e3912bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fb73726d1a94c8abf028a062ce0b59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b8c66bbf7b54d3596ad8c8cf81f2398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a90b8a5f7bf54c55b8c9325b6912f729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2dcc3c0527e747dfa72f637a9ce79ee2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cf4b8dd1db5440328bec8d372fd47b94",
              "IPY_MODEL_f629115e3ec5447ca0b54f9405468346",
              "IPY_MODEL_65473740184c43e99bd19be545b7a289"
            ]
          }
        },
        "2dcc3c0527e747dfa72f637a9ce79ee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "cf4b8dd1db5440328bec8d372fd47b94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5f9946e3486b4542a755e13cf9b0cbd4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch 4: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6715d44595944dbfb782204157f8660f"
          }
        },
        "f629115e3ec5447ca0b54f9405468346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff2fd454537a4ec6a3e254f7abb071af",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1753,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1753,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a86e998231e64c5a9f118d420c3779ea"
          }
        },
        "65473740184c43e99bd19be545b7a289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c229aa1f15f34e35a643823aecc3b97b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1753/1753 [18:16&lt;00:00,  1.60it/s, loss=0.00175, v_num=-167]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b6262d4367047d6ac0da033ac0a1a6d"
          }
        },
        "5f9946e3486b4542a755e13cf9b0cbd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6715d44595944dbfb782204157f8660f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff2fd454537a4ec6a3e254f7abb071af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a86e998231e64c5a9f118d420c3779ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c229aa1f15f34e35a643823aecc3b97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b6262d4367047d6ac0da033ac0a1a6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "132677ffe928494ca33d9b79e884deb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5846efb3da154389a8102d78c92ae70f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9082004366e349e9a2cde95d0d660900",
              "IPY_MODEL_496d17ee22ac48509be7b3add78a9a9d",
              "IPY_MODEL_8838006f7d40462f9b04fff49d749a58"
            ]
          }
        },
        "5846efb3da154389a8102d78c92ae70f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "9082004366e349e9a2cde95d0d660900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f52406a6383c4ac38bbcf7e2bb39af36",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validating: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_814ef1fb39a9481d9bd2def3b2c9d4cc"
          }
        },
        "496d17ee22ac48509be7b3add78a9a9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_342dee2157054769a73c7234f8ba4a3f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 226,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 226,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41708a6514c4434080817c95dd59ac4e"
          }
        },
        "8838006f7d40462f9b04fff49d749a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3abfe0105196434a88e448290873df80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226/226 [00:54&lt;00:00,  4.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf70183e25e84eddb1ceecc6bdb04371"
          }
        },
        "f52406a6383c4ac38bbcf7e2bb39af36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "814ef1fb39a9481d9bd2def3b2c9d4cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "342dee2157054769a73c7234f8ba4a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41708a6514c4434080817c95dd59ac4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3abfe0105196434a88e448290873df80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf70183e25e84eddb1ceecc6bdb04371": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e75d977db5547e18b255ea58f095881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fed530a8bf7d41d08e86ad39d7a79f74",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4c78bd036e90432a98af36565cffb61e",
              "IPY_MODEL_7f489d2a582c46f4a2e169fd9067d2ac",
              "IPY_MODEL_b84c62cc88fe43c4ac6c10df9e6ff935"
            ]
          }
        },
        "fed530a8bf7d41d08e86ad39d7a79f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "4c78bd036e90432a98af36565cffb61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_faa0fd793f5b45d5ab96c898eee10089",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validating: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c610a7a12e634cde91f27a9078fe8dff"
          }
        },
        "7f489d2a582c46f4a2e169fd9067d2ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_207bda3136d74165bf00f0f4354692f9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 226,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 226,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c12847484b7424993a407673761b0a5"
          }
        },
        "b84c62cc88fe43c4ac6c10df9e6ff935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ba25f3d53fd4977a6a4affde5247553",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226/226 [00:54&lt;00:00,  4.27it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc5d7c8118884f97a50e291f599045e8"
          }
        },
        "faa0fd793f5b45d5ab96c898eee10089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c610a7a12e634cde91f27a9078fe8dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "207bda3136d74165bf00f0f4354692f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c12847484b7424993a407673761b0a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ba25f3d53fd4977a6a4affde5247553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc5d7c8118884f97a50e291f599045e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3137096a5b914d3094d0fa8c51229c1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a5ced09cb6e34a10ae661fd129c100b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fa0e0f69e5664cc1906aecf2cc560789",
              "IPY_MODEL_2a81388b57b44c9498dbfd50a45b9f47",
              "IPY_MODEL_5ff99ee3cd094b489805f86860a3b123"
            ]
          }
        },
        "a5ced09cb6e34a10ae661fd129c100b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "fa0e0f69e5664cc1906aecf2cc560789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c6a310dc7e264316822593e19bd6460d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validating: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_741d70206e57469d991aa4cdeef21739"
          }
        },
        "2a81388b57b44c9498dbfd50a45b9f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11d0ac63d255413ebbb8c8441a653931",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 226,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 226,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d5937bff7e041f3ab0666a736c088a0"
          }
        },
        "5ff99ee3cd094b489805f86860a3b123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44e9b3011b15466e8c503f3cbf5891ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226/226 [00:54&lt;00:00,  4.26it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02be64c09e004b3787f54330eeb03c4d"
          }
        },
        "c6a310dc7e264316822593e19bd6460d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "741d70206e57469d991aa4cdeef21739": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11d0ac63d255413ebbb8c8441a653931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d5937bff7e041f3ab0666a736c088a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44e9b3011b15466e8c503f3cbf5891ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02be64c09e004b3787f54330eeb03c4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1783b9cfb284459a7815f17aba7bd51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bebee48f0307449f885b96d8b15c491a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac923c349ae9483da061d446140f4982",
              "IPY_MODEL_14c77ead3e064186a408fc616265cb56",
              "IPY_MODEL_055fba5107514a91980df672e1537732"
            ]
          }
        },
        "bebee48f0307449f885b96d8b15c491a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "ac923c349ae9483da061d446140f4982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4857d62b473b4bc1803c4dee97718d93",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validating: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83dc4fb29c3142908fcbc677a593cb6e"
          }
        },
        "14c77ead3e064186a408fc616265cb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b94ef357e6ef4601b806d84f8dd1822b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 226,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 226,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd45aca19e584b57b9fe4021e9a5ef33"
          }
        },
        "055fba5107514a91980df672e1537732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4b2df485a404d558453ada063ad16a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226/226 [00:54&lt;00:00,  4.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a25db867d394c29a86175c22c04e50a"
          }
        },
        "4857d62b473b4bc1803c4dee97718d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83dc4fb29c3142908fcbc677a593cb6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b94ef357e6ef4601b806d84f8dd1822b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd45aca19e584b57b9fe4021e9a5ef33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e4b2df485a404d558453ada063ad16a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a25db867d394c29a86175c22c04e50a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "827745ee04c14cb3b5e39873e203d913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c6e9fdb7492f4a489d2659ad0f939d84",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3fc60d8c61ba4c9dbb567e5cc6e8942a",
              "IPY_MODEL_386f449a143f44c6a481b52e47dfdf14",
              "IPY_MODEL_cc276e6206474021b89edd1e8633eb8a"
            ]
          }
        },
        "c6e9fdb7492f4a489d2659ad0f939d84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "3fc60d8c61ba4c9dbb567e5cc6e8942a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6e1f3d119a4f41ec8cf9129e786990d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Validating: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50aad611d9a144bfb140363e28afec32"
          }
        },
        "386f449a143f44c6a481b52e47dfdf14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_88fe6b1b88f24b79852633fbf84a4d5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 226,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 226,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b11b378154c4abb9dd60c87e68c946f"
          }
        },
        "cc276e6206474021b89edd1e8633eb8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fda36c32f8a3405cb55b02325d509545",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226/226 [00:54&lt;00:00,  4.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55fa166a78e440aeb23607b88ba9697a"
          }
        },
        "6e1f3d119a4f41ec8cf9129e786990d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50aad611d9a144bfb140363e28afec32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88fe6b1b88f24b79852633fbf84a4d5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b11b378154c4abb9dd60c87e68c946f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fda36c32f8a3405cb55b02325d509545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55fa166a78e440aeb23607b88ba9697a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9d24eac1eb54255936581839da2116c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0eab31b0acd548239fd9114909b9f341",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f6810927e7034862a5218e8a96894b0c",
              "IPY_MODEL_1d6aa6d40a104e10ad3351aed28c21c9",
              "IPY_MODEL_7ef0beeee1f2445d93b9494a8b20bb2c"
            ]
          }
        },
        "0eab31b0acd548239fd9114909b9f341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "f6810927e7034862a5218e8a96894b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_feb6ec6ea2ee4880848c8f2a3aef93db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Testing: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c53150e315b744709245335a28523327"
          }
        },
        "1d6aa6d40a104e10ad3351aed28c21c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_45c32ab6ac114147abc8147bff6e9c2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_422e9c86cad7486095b9adc8412c2c4c"
          }
        },
        "7ef0beeee1f2445d93b9494a8b20bb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6e79b5f223324e2f8e6c458346d9cafb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226/226 [00:52&lt;00:00,  4.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f180749a46ba4ce7971535882323a513"
          }
        },
        "feb6ec6ea2ee4880848c8f2a3aef93db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c53150e315b744709245335a28523327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45c32ab6ac114147abc8147bff6e9c2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "422e9c86cad7486095b9adc8412c2c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6e79b5f223324e2f8e6c458346d9cafb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f180749a46ba4ce7971535882323a513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "792954b1312a4cd29172456711454406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_723166e73bbd4cf6bdad6dfdf36f5a89",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8bee8d0e6a454c8e99b44b5ab86f057f",
              "IPY_MODEL_42568b86016f44219ad2595f2ed9d373",
              "IPY_MODEL_96f737bbf6cb4bfb926856c83df54490"
            ]
          }
        },
        "723166e73bbd4cf6bdad6dfdf36f5a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "8bee8d0e6a454c8e99b44b5ab86f057f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_48bf5fc3c8e84debb985569c3e04578a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Predicting: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cdf7d041c6204973bfc2c35783300756"
          }
        },
        "42568b86016f44219ad2595f2ed9d373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_04d1e7e4403c4c8abf8f9b61cc45e781",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14e84a178f5844a6888e4570894f7805"
          }
        },
        "96f737bbf6cb4bfb926856c83df54490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13752e22304f49609d33ab7e7a85ae46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1233/1233 [01:13&lt;00:00, 16.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e7e34a185e7947c09b1af66b89d42ea8"
          }
        },
        "48bf5fc3c8e84debb985569c3e04578a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cdf7d041c6204973bfc2c35783300756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04d1e7e4403c4c8abf8f9b61cc45e781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14e84a178f5844a6888e4570894f7805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13752e22304f49609d33ab7e7a85ae46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e7e34a185e7947c09b1af66b89d42ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9cb414045074fd38fe7c7333af0bc50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5169e58afbe44779b04d95ddb0f37416",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_680630f6acc6434d8e405faaf91207e9",
              "IPY_MODEL_9ff49d936bf14af78ec51e79337e90ea",
              "IPY_MODEL_4a13acecf50d4fa0a1d0618457dac651"
            ]
          }
        },
        "5169e58afbe44779b04d95ddb0f37416": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "680630f6acc6434d8e405faaf91207e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_64464c43ebe7493b9a0249e2b7e523b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Predicting: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84cd5c45e05f47e590a36e0ef38a990f"
          }
        },
        "9ff49d936bf14af78ec51e79337e90ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9d3ef45d653408e86fa9d7a3bb7ba07",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b880147565f49e0b48252e1965882fd"
          }
        },
        "4a13acecf50d4fa0a1d0618457dac651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e950ff58b5274be78253b836157bb69b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1627/1627 [01:39&lt;00:00, 16.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b73517d9f8ca44328da72c7fd17bac31"
          }
        },
        "64464c43ebe7493b9a0249e2b7e523b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84cd5c45e05f47e590a36e0ef38a990f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b9d3ef45d653408e86fa9d7a3bb7ba07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b880147565f49e0b48252e1965882fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e950ff58b5274be78253b836157bb69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b73517d9f8ca44328da72c7fd17bac31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlozg/aicovid/blob/main/%5BTorch009_base%5D_AICOVID_115M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-YXyY9kYZcG",
        "outputId": "72fd42ca-0f5a-4518-8213-cb2a6c5896d9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep  4 10:45:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYEmHeR7z_l1"
      },
      "source": [
        "Thí nghiệm trước mình đã thực hiện tinh chỉnh engineering khá nhiều, đặc biệt là việc tạo ra class dataset hoàn chỉnh cũng như tạo ra sampler phục vụ việc oversampling/undersampling. Bên cạnh đó mình còn giải quyết được vấn đề chunking gây bùng nổ data và cải thiện lại lightning module để có thể thực hiện multi-task learning.\n",
        "\n",
        "Các vấn đề tồn đọng cho tới hiện tại:\n",
        "- Tinh chỉnh lại code để hoạt động được với lightning 1.4.0\n",
        "\n",
        "Trong notebook này, trọng tâm mình sẽ thử xoay quanh AST. Sở dĩ mình chuyển qua một phiên bản thí nghiệm mới vì mình nhận thấy rằng transformer có cách sử dụng với sequence khác với CNN nên tạo phiên bản mới để có thể dễ dàng quản lý, cũng như trong này mình hy vọng có thể học hỏi và hiểu rõ hơn về vision transformer.\n",
        "\n",
        "exp000: Thử pretrain AST trên audioset. --> Chỉ chạy được batch size là 3. Rất chậm, memory tiêu tốn rất lớn.\n",
        "\n",
        "exp001: Tinh chỉnh lại, remove bớt các thành phần đã được handle bởi lightning, loại bỏ MLP head vì cái này task dependent.\n",
        "\n",
        "exp001-exp003_db: train model thất bại, không có dấu hiệu cải thiện của model khi loại bỏ đi 1 lớp linear giữa cls token và linear từng task. Đề xuất 2 hướng: (1) thêm 1 lớp giữa nhưng nhẹ hơn (exp000 dùng 527); (2) train single task. Bên cạnh đó mình đọc paper thì cũng bị khó hiểu khi tác giả lại mix cls với dist cls token trong quá trình train, trong khi suppose là dist cls token chỉ dùng khi có teacher?\n",
        "\n",
        "***PHÁT HIỆN NGUYÊN NHÂN TRAIN KHÔNG ĐƯỢC: MODEL KHÔNG LOAD ĐƯỢC PRETRAINED WEIGHT***\n",
        "\n",
        "exp003: fix bug thành công. --> 0.752\n",
        "\n",
        "exp004: \n",
        "- Thử accumulate gradient batch 16 để được batchsize 64. Số lượng epoch dùng để train cần căn cứ theo tình hình fit của exp003 (tiêu chuẩn là gấp 16 lần, nhưng theo bên how to train resnet thì batchsize lớn cần ít epoch hội tụ hơn)? 🔁\n",
        "- Chỉnh tỉ lệ loss cho các task phụ vì theo quan sát gradient thì thấy chủ yếu khó khăn vì phải tối ưu gradient cho task phụ là chính, thậm chí còn dẫn tới performance trên task chính giảm sút. ✅\n",
        "- Chỉnh lại model để cho phép inference trên length bất kỳ. \n",
        "- Thử chỉ classify với cls token 🔁"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khpFMuqN4BzU"
      },
      "source": [
        "Đoạn code giúp tránh việc bị shutdown notebook do inactive.\n",
        "```javascript\n",
        "function prevent_timeout(){\n",
        "document\n",
        ".querySelector('#top-toolbar > colab-connect-button')\n",
        "    .shadowRoot.querySelector('#connect').click()\n",
        "}\n",
        "\n",
        "setInterval(prevent_timeout, 60000)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "ikasEdh-I_wD"
      },
      "source": [
        "#@title Cài các thư viện bổ sung.\n",
        "#@markdown (note: cài xong phải restart runtime nếu tính dùng tensorboard hay tensorflow gì đó do pl downgrade tensorboard...)\n",
        "\n",
        "#@markdown Các thư viện bổ sung bao gồm:\n",
        "#@markdown - PyDrive2 (để upload file có kích thước lớn lên GDrive)\n",
        "#@markdown - torchaudio\n",
        "#@markdown - Pytorch Lightning\n",
        "#@markdown - Neptune client (để tạo logger coi online, tránh phải ngồi canh và backup thủ công khi dùng tensor board)\n",
        "\n",
        "try:\n",
        "  import torchaudio\n",
        "except ImportError:\n",
        "  !pip install PyDrive2\n",
        "  !pip install torchaudio\n",
        "  !pip install pytorch-lightning==1.3.8\n",
        "  !pip install 'neptune-client[pytorch-lightning]'\n",
        "  !pip install torchinfo\n",
        "  # exit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "xsOJoIodiHt1"
      },
      "source": [
        "#@title Lấy xác thực google để upload/download file\n",
        "#@markdown Vui lòng bấm vào link khi được yêu cầu và lấy mã để nhập vào\n",
        "\n",
        "# Xác thực google để upload/download qua google drive\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "class GDrive():\n",
        "    def __init__(self):\n",
        "        self._gauth = GoogleAuth()\n",
        "        self._gauth.credentials = self._get_creds()\n",
        "        self._drive = GoogleDrive(self._gauth)\n",
        "\n",
        "    def _get_creds(self):\n",
        "        auth.authenticate_user()\n",
        "        return GoogleCredentials.get_application_default()\n",
        "\n",
        "    def Refresh_Auth(self):\n",
        "        self._gauth.credentials = self._get_creds()\n",
        "\n",
        "    def SearchInFolder(self, parent_id, file_name):\n",
        "        self.Refresh_Auth()\n",
        "        return self._drive.ListFile({'q': f\"'{parent_id}' in parents and title = '{file_name}'\"}).GetList()\n",
        "\n",
        "    def CreateFile(self, file_name=None, parent_id=None):\n",
        "        self.Refresh_Auth()\n",
        "        file = self._drive.CreateFile({'title': file_name, \n",
        "                                       'parents': [{'id': parent_id}]})\n",
        "        return file\n",
        "\n",
        "    def Upload(self, file_path, parent_id, file_name=None):\n",
        "        if file_name == None:\n",
        "          file_name = file_path.split('/')[-1]\n",
        "        # Kiểm tra file tồn tại\n",
        "        file_list = self.SearchInFolder(parent_id, file_name)\n",
        "        if len(file_list) > 1:\n",
        "          for file in file_list:\n",
        "            print('title: %s, id: %s' % (file['title'], file['id']))\n",
        "          raise NameError('More than 1 file with same name exist, please resolve this')\n",
        "        \n",
        "        elif len(file_list) == 0:\n",
        "          # File chưa có thì tạo mới\n",
        "          file = self.CreateFile(file_name, parent_id)\n",
        "        else:\n",
        "          # Tồn tại duy nhất 1 file\n",
        "          file = file_list[0]\n",
        "        \n",
        "        file.SetContentFile(file_path)\n",
        "        file.Upload()\n",
        "\n",
        "    def Download(self, file_name, parent_id):\n",
        "        # Kiểm tra file tồn tại\n",
        "        file_list = self.SearchInFolder(parent_id, file_name)\n",
        "        if len(file_list) > 1:\n",
        "            for file in file_list:\n",
        "                print('title: %s, id: %s' % (file['title'], file['id']))\n",
        "            raise NameError('More than 1 file with same name exist, please resolve this')\n",
        "        elif len(file_list) == 0:\n",
        "            raise NameError(f'File named {file_name} not exist')\n",
        "        else:\n",
        "            # Tồn tại duy nhất 1 file\n",
        "            file = file_list[0]\n",
        "        \n",
        "        file.GetContentFile(file_name)\n",
        "\n",
        "drive = GDrive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "U8N-dhNNq152"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.path.exists(\"tmp.tmp\"):\n",
        "    #@title Nhập Neptune API token\n",
        "    api_token = getpass('Enter your private Neptune API token: ')\n",
        "    with open('tmp.tmp', 'w') as tmp:\n",
        "        tmp.write(api_token)\n",
        "else:\n",
        "    with open('tmp.tmp', 'r') as tmp:\n",
        "        api_token = tmp.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_pyzy0LjMrg"
      },
      "source": [
        "# Detect COVID-19 patients via forced-cough cell phone recording\n",
        "\n",
        "- **Bài toán**: Nhận diện người nhiễm COVID-19 qua tiếng ho ép buộc\n",
        "    - **Input**: Đoạn ghi âm tiếng ho, tuổi và giới tính\n",
        "    - **Output**: Phân loại người nhiễm bệnh hay không"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_YA074tx3l"
      },
      "source": [
        "## Tìm hiểu bài toán \n",
        "Qua paper (https://dspace.mit.edu/bitstream/handle/1721.1/128954/09208795.pdf?sequence=1&isAllowed=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02xm0kpbQBgJ"
      },
      "source": [
        "## Đọc papers\n",
        "[1] Kranthi Kumar Lella and Alphonse Pja (2021), *Automatic diagnosis of COVID-19 disease using deep convolutional neural network with multi-feature channel from respiratory sound data: Cough, voice, and breath*, access via: https://www.sciencedirect.com/science/article/pii/S1110016821003859\n",
        "\n",
        "- Nguồn tham khảo tốt cho các paper có liên quan làm cùng chủ đề.\n",
        "- Chỉ ra các paper trước đó không thành công lắm.\n",
        "> From all these background work senses, there is **no accurate model** for diagnosing COVID-19 disease symptom\n",
        "- Chỉ ra rằng hầu hết các dataset bị redundancy (1 speaker tạo nhiều mẫu).\n",
        "- Dùng 4 loại augment: time stretch, shift pitch, dynamic range (nôm na là cân bằng volume), background noise inject.\n",
        "- Dùng 3 channel: DAE (remove background noise), GFCC (short respiratory feature) và IMFCC (rich respiratory feature) -> Model có thực sự dùng hết cả 3 channel?\n",
        "- Phần nói về implement hơi messed up (text mô tả kiến trúc 1 đường hình minh họa một nẻo?)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pbmNRtmnFNl"
      },
      "source": [
        "# Các biến thiết lập cho thử nghiệm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "T9Pxvi0cclld"
      },
      "source": [
        "# Nếu muốn train mô hình thì set thành True\n",
        "experiment_id = '009' #@param {type:\"string\"}\n",
        "val_split = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.05}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPKjksovwzjL"
      },
      "source": [
        "# ID của folder lưu model trên drive\n",
        "model_zoo = 'secret'\n",
        "# ID của folder chứa submission\n",
        "submission_folder = 'secret'\n",
        "# Tên của file nén để nộp\n",
        "zip_name = f'Torch_ver{experiment_id}'\n",
        "# ID của folder chứa data đã preprocess\n",
        "datadump_folder = 'secret'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6trLD9GlZeY"
      },
      "source": [
        "# Setup\n",
        "Import thư viện, tải data, đọc data, tạo helper function,..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ewK6TTR-tdL"
      },
      "source": [
        "## Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zceUdpcYV4aK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af5e994-973e-448c-b508-96255edb8078"
      },
      "source": [
        "# Quản lý file, folder\n",
        "import os\n",
        "\n",
        "# Xử lý audio\n",
        "import torchaudio\n",
        "\n",
        "# Hiện audio nghe thử\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio, display\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler, Sampler\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "pl.utilities.seed.seed_everything(seed=1)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GxCO0fvq1yr"
      },
      "source": [
        "## Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "YjCQwg-opB0L"
      },
      "source": [
        "#@markdown ## Các hàm vỏ bọc cho đọc file\n",
        "#@markdown `read_audio(path)`: vỏ bọc cho `torchaudio.load(path)`.<br>\n",
        "#@markdown `read_resample_audio(path)`: chỉ trả về wave vì sample rate đã được cố định.\n",
        "\n",
        "'''\n",
        "  Read audio from given path and return (wave, sample_rate)\n",
        "'''\n",
        "def read_audio(full_audio_path):\n",
        "  return torchaudio.load(full_audio_path)\n",
        "\n",
        "'''\n",
        "  Read audio from given path, then resample if sample rate is not matched \n",
        "  and return wave.\n",
        "\n",
        "  Tips: \n",
        "    you should provide resampler from torchaudio.transform\n",
        "    when batch resampling with same params since this can\n",
        "    give a huge speed up.\n",
        "'''\n",
        "def read_resample_audio(\n",
        "    full_audio_path, resample,\n",
        "    resampler=None\n",
        "):\n",
        "  wave, sr = torchaudio.load(full_audio_path)\n",
        "  if resampler is not None:\n",
        "      wave = resampler(wave)\n",
        "  elif sr != resample:\n",
        "      wave = torchaudio.functional.resample(wave, sr, resample)\n",
        "  return wave"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx7B78dVp8r_"
      },
      "source": [
        "class AudioChunking(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 chunk_size: int=400,\n",
        "                 chunk_step: int=200,\n",
        "                 idx_instead: bool=False) -> None:\n",
        "        super(AudioChunking, self).__init__()\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_step = chunk_step\n",
        "        self.idx_instead = idx_instead\n",
        "        \n",
        "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
        "        spec_len = spec.shape[-1]\n",
        "        pad_size = self.chunk_size - spec_len%self.chunk_size\n",
        "        pad_size = (pad_size//2, pad_size//2+pad_size%2)\n",
        "        padded_spec = torch.nn.functional.pad(spec, pad_size, mode='constant', value=0)\n",
        "        \n",
        "        if self.idx_instead:\n",
        "            spec_len = padded_spec.shape[-1]\n",
        "            chunk_idxs = [(i, i+self.chunk_size-1) for i in range(0,spec_len-self.chunk_size+1,self.chunk_step)]\n",
        "            return padded_spec, chunk_idxs\n",
        "        else:\n",
        "            chunks = padded_spec.unfold(-1, self.chunk_size, self.chunk_step).permute(2,0,1,3)\n",
        "            return chunks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWl97B56jd2B"
      },
      "source": [
        "## check_integrity.py\n",
        "from typing import Optional, Any\n",
        "import hashlib\n",
        "import os\n",
        "\n",
        "def calculate_md5(fpath: str, chunk_size: int = 1024 * 1024) -> str:\n",
        "    md5 = hashlib.md5()\n",
        "    with open(fpath, 'rb') as f:\n",
        "        for chunk in iter(lambda: f.read(chunk_size), b''):\n",
        "            md5.update(chunk)\n",
        "    return md5.hexdigest()\n",
        "\n",
        "\n",
        "def check_md5(fpath: str, md5: str, **kwargs: Any) -> bool:\n",
        "    return md5 == calculate_md5(fpath, **kwargs)\n",
        "\n",
        "\n",
        "def check_integrity(fpath: str, md5: Optional[str] = None) -> bool:\n",
        "    if not os.path.isfile(fpath):\n",
        "        return False\n",
        "    if md5 is None:\n",
        "        return True\n",
        "    return check_md5(fpath, md5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqDYmGGjjiwV"
      },
      "source": [
        "from urllib.parse import urlparse\n",
        "from typing import Optional\n",
        "import re\n",
        "\n",
        "def _get_google_drive_file_id(url: str) -> Optional[str]:\n",
        "    # Src: pytorch/vision/utils\n",
        "    parts = urlparse(url)\n",
        "\n",
        "    if re.match(r\"(drive|docs)[.]google[.]com\", parts.netloc) is None:\n",
        "        return None\n",
        "\n",
        "    match = re.match(r\"/file/d/(?P<id>[^/]*)\", parts.path)\n",
        "    if match is None:\n",
        "        return None\n",
        "\n",
        "    return match.group(\"id\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "uhmXygRTh_Dy"
      },
      "source": [
        "#@markdown `StandardScaler(mean, std)`\n",
        "class StandardScaler(nn.Module):\n",
        "    def __init__(self, mean=None, std=None, target_std_scale=1.0) -> None:\n",
        "        super(StandardScaler, self).__init__()\n",
        "        \n",
        "        # Set property for query, can't change inner scaler if change these value\n",
        "        self.mean = mean\n",
        "        self.std = std/target_std_scale\n",
        "\n",
        "        if mean is None:\n",
        "            if std is None:\n",
        "                  self.scaler = lambda spec: (spec-spec.mean)/spec.std\n",
        "            else:\n",
        "                  self.scaler = lambda spec: (spec-spec.mean)/std\n",
        "        elif std is None:\n",
        "            self.scaler = lambda spec: (spec-mean)/spec.std\n",
        "        else:\n",
        "            self.scaler = lambda spec: (spec-mean)/std\n",
        "        \n",
        "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
        "        return self.scaler(spec).nan_to_num(posinf=0.0, neginf=0.0)\n",
        "\n",
        "#@markdown `MinMaxScaler(min, max)`\n",
        "class MinMaxScaler(nn.Module):\n",
        "    def __init__(self, min=None, max=None) -> None:\n",
        "        super(MinMaxScaler, self).__init__()\n",
        "        if min:\n",
        "            self._min = lambda x: min\n",
        "        else:\n",
        "            self._min = lambda x: x.min()\n",
        "        if max:\n",
        "            self._max = lambda x: max\n",
        "        else:\n",
        "            self._max = lambda x: x.max()\n",
        "        \n",
        "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
        "        return ((spec-self._min(spec))/(self._max(spec)-self._min(spec))).nan_to_num(posinf=0.0, neginf=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkGwlGUh6iM0"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "from tqdm import tqdm\n",
        "import tempfile, shutil\n",
        "import weakref\n",
        "import pickle\n",
        "import warnings\n",
        "import ast\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class AICOVIDDataset(Dataset):\n",
        "    '''\n",
        "    AICOVID dataset made easy\n",
        "    '''\n",
        "\n",
        "    available_splits = [\"w_pub_train\", \"w_pub_test\", \"w_pri_test\", \"f_pub_train\", \"f_pub_test\", \"f_pri_test\"]\n",
        "\n",
        "    official_urls = {\n",
        "        \"w_pub_train\": \"https://drive.google.com/file/d/1MPhz3zYl2yefCq-J5XySbFJt99BfKIZD/view\",\n",
        "        \"w_pub_test\": \"https://drive.google.com/file/d/1UrMudzopA3CyR1Ih2J63Kfi2mY_0uhRK/view\",\n",
        "        \"w_pri_test\": \"https://drive.google.com/file/d/1hP8rHwJ_bz3J1T4MtEEp53ZBe9fdFKrW/view\",\n",
        "        \"f_pub_train\": \"https://drive.google.com/file/d/1Oq9UgA9cEGMNRGvF7oNKkFOg6udsDprl/view\",\n",
        "        \"f_pub_test\": \"https://drive.google.com/file/d/159SghfGeqVj3AfgTRZXsAAAj0-3ogccX/view\",\n",
        "        \"f_pri_test\": \"https://drive.google.com/file/d/1KJmH12giVJl8mIP-sTP2RK7Y5fKABFx_/view\"\n",
        "    }\n",
        "\n",
        "    mirrored_urls = {\n",
        "        \"w_pub_train\": \"https://drive.google.com/file/d/1hoGLxjLmPY-pX-jSVGIaWIZhovQBMKU1/view\",\n",
        "        \"w_pub_test\": \"https://drive.google.com/file/d/1X7vOjHos9f9w48-iTWyu5JElFqCjcH_R/view\",\n",
        "        \"w_pri_test\": \"https://drive.google.com/file/d/1Ec64sSm2dZqe3da_LVyE_jUBD0DnLyqB/view\",\n",
        "        \"f_pub_train\": \"https://drive.google.com/file/d/1HoRJllAfYNeBPoCz2nXkf7lQ3raPcFYf/view\",\n",
        "        \"f_pub_test\": \"https://drive.google.com/file/d/1w5N5prH-uWqLvoSZnuY8TIqm_BBgN2ND/view\",\n",
        "        \"f_pri_test\": \"https://drive.google.com/file/d/1pqx6vGc0_nR4Ta1XzUWfDTbVATQ5EhUI/view?usp=sharing\"\n",
        "    }\n",
        "\n",
        "    resources = {\n",
        "        \"w_pub_train\": (\"aicv115m_public_train.zip\", None),\n",
        "        \"w_pub_test\": (\"aicv115m_public_test.zip\", None),\n",
        "        \"w_pri_test\": (\"aicv115m_private_test.zip\", None),\n",
        "        \"f_pub_train\": (\"aicv115m_final_public_train.zip\", None),\n",
        "        \"f_pub_test\": (\"aicv115m_final_public_test.zip\", None),\n",
        "        \"f_pri_test\": (\"aicv115m_final_private_test.zip\", None)\n",
        "    }\n",
        "\n",
        "    audio_paths = {\n",
        "        \"w_pub_train\": 'aicv115m_public_train/train_audio_files_8k/',\n",
        "        \"w_pub_test\": 'aicv115m_public_test/public_test_audio_files_8k/',\n",
        "        \"w_pri_test\": 'aicv115m_private_test/private_test_audio_files_8k/',\n",
        "        \"f_pub_train\": 'aicv115m_final_public_train/public_train_audio_files/',\n",
        "        \"f_pub_test\": 'aicv115m_final_public_test/public_test_audio_files/',\n",
        "        \"f_pri_test\": 'aicv115m_final_private_test/private_test_audio_files/'\n",
        "    }\n",
        "\n",
        "    ############\n",
        "    #   init\n",
        "    ############\n",
        "\n",
        "    def __init__(self, \n",
        "                 split: Optional[str]=None,\n",
        "                 audio_transforms: Optional[nn.ModuleList]=None, \n",
        "                 normalize: Optional[Union[str, nn.Module]]=None,\n",
        "                 chunking: Optional[Tuple[int, int]]=None,\n",
        "                 val_split: Optional[bool]=None,\n",
        "                 split_ratio: float=0.8,\n",
        "                 cleanup_after: bool=True) -> None:\n",
        "        \n",
        "        # Dataset statistic: mean, std, mean by freq band, std by freq band\n",
        "        if split is None: return  # Allow empty dataset for loading from gdrive later\n",
        "\n",
        "        if split not in self.available_splits:\n",
        "            raise NameError(f\"{split} is not a valid split, please check again!\")\n",
        "\n",
        "        self.split = split\n",
        "        self.download()\n",
        "\n",
        "        self.meta_df = self.extract_archive()\n",
        "\n",
        "        if val_split is not None:\n",
        "            idx_train, idx_val = train_test_split(self.meta_df.index, train_size=split_ratio, random_state=1)\n",
        "            self.meta_df = self.meta_df.iloc[idx_val if val_split else idx_train]\n",
        "\n",
        "        # Create temporary folder to dump preprocessed data\n",
        "        self._temp_folder = tempfile.mkdtemp()\n",
        "        self._finalizer = weakref.finalize(self, shutil.rmtree, self._temp_folder)\n",
        "\n",
        "        self.file_paths = []\n",
        "        self.idxs = []\n",
        "        self.chunk_idxs = None\n",
        "        \n",
        "        self.mean = []\n",
        "        self.std = []\n",
        "  \n",
        "        self.process_files(audio_transforms, chunking, normalize)\n",
        "\n",
        "        if normalize == 'ast':\n",
        "            self.scaler = StandardScaler(self.mean, self.std, 0.5)\n",
        "        elif normalize == 'by_freq_band':\n",
        "            self.mean = torch.tensor(self.mean).unsqueeze(-1)\n",
        "            self.std = torch.tensor(self.std).unsqueeze(-1)\n",
        "            self.scaler = StandardScaler(self.mean, self.std)\n",
        "        elif isinstance(normalize, StandardScaler):\n",
        "            self.scaler = normalize\n",
        "            self.mean = normalize.mean\n",
        "            self.std = normalize.std\n",
        "        elif normalize is None:\n",
        "            self.scaler = lambda x: x\n",
        "            print(\"This dataset is not normalized, be careful!\")\n",
        "        else:\n",
        "            raise KeyError(\"Invalid 'normalize' value\")\n",
        "\n",
        "        self.normalize_dataset()\n",
        "        \n",
        "        if cleanup_after:\n",
        "            self.cleanup_extract()\n",
        "\n",
        "\n",
        "    ################################\n",
        "    #   download/extract/cleanup\n",
        "    ################################\n",
        "\n",
        "    def _check_exists(self) -> bool:\n",
        "        return check_integrity(*self.resources[self.split])\n",
        "\n",
        "\n",
        "    def download(self) -> None:\n",
        "        if self._check_exists():\n",
        "            print(\"> Archive have already downloaded\")\n",
        "            return\n",
        "        file_id = _get_google_drive_file_id(self.official_urls[self.split])\n",
        "        os.system(f\"gdown --id {file_id}\")\n",
        "        print(\"\\n> Archive download complete\")\n",
        "\n",
        "\n",
        "    def extract_archive(self) -> pd.DataFrame:\n",
        "        file_name, _ = self.resources[self.split]\n",
        "        os.system(f\"unzip -n -q {file_name}\")\n",
        "        print(\"\\n> Extract complete\")\n",
        "\n",
        "        # split standardize (some split have different folder organize style)\n",
        "        if self.split == \"w_pub_train\":\n",
        "            os.system(\"unzip -n -q aicv115m_public_train/train_audio_files_8k.zip -d ./aicv115m_public_train\")\n",
        "            meta = pd.read_csv('aicv115m_public_train/metadata_train_challenge.csv').drop(columns=[\"file_path\"])\n",
        "        elif self.split == \"w_pub_test\":\n",
        "            os.system(\"unzip -n -q aicv115m_public_test/public_test_audio_files_8k.zip -d /aicv115m_public_test\")\n",
        "            meta = pd.read_csv('aicv115m_public_test/metadata_public_test.csv').drop(columns=[\"file_path\"])\n",
        "        elif self.split == \"w_pri_test\":\n",
        "            meta = pd.read_csv('aicv115m_private_test/metadata_private_test.csv').drop(columns=[\"file_path\"])\n",
        "        elif self.split == \"f_pub_train\":\n",
        "            meta = pd.read_csv('aicv115m_final_public_train/public_train_metadata.csv')\n",
        "            med_meta = pd.read_csv(\"aicv115m_final_public_train/public_train_medical_condition.csv\")\n",
        "            meta = meta.merge(med_meta, how=\"left\", on=\"uuid\")\n",
        "            meta = self._process_final_meta(meta)\n",
        "        elif self.split == \"f_pub_test\":\n",
        "            meta = pd.read_csv('aicv115m_final_public_test/public_test_sample_submission.csv').drop(columns=[\"assessment_result\"])\n",
        "        elif self.split == \"f_pri_test\":\n",
        "            meta = pd.read_csv('aicv115m_final_private_test/private_test_sample_submission.csv').drop(columns=[\"assessment_result\"])\n",
        "\n",
        "        return meta\n",
        "\n",
        "\n",
        "    def _process_final_meta(self, meta):\n",
        "        # Convert string in list/dict format to real list/dict object\n",
        "        str_to_obj = lambda x: ast.literal_eval(x)\n",
        "        col_tobe_processed = ['cough_intervals', 'symptoms_status_choice', 'medical_condition_choice',]\n",
        "        for col in col_tobe_processed:\n",
        "            meta[col] = meta[col].map(str_to_obj, na_action='ignore')\n",
        "\n",
        "        # Process list type columns and categorical columns\n",
        "        medical_condition_choice_df = pd.get_dummies(meta['medical_condition_choice'].apply(pd.Series).stack()).sum(level=0)\n",
        "        medical_condition_choice_df = medical_condition_choice_df.drop(columns=['No'])\n",
        "        symptoms_status_choice_df = pd.get_dummies(meta['symptoms_status_choice'].apply(pd.Series).stack()).sum(level=0)\n",
        "        symptoms_status_choice_df = symptoms_status_choice_df.drop(columns=['No'])\n",
        "        sex_dummies = pd.get_dummies(meta['subject_gender'])\n",
        "        meta = meta.join([sex_dummies, medical_condition_choice_df, symptoms_status_choice_df])\n",
        "        meta.drop(columns=['subject_gender', 'symptoms_status_choice','medical_condition_choice'], inplace=True)\n",
        "\n",
        "        # Convert to ordinal values\n",
        "        age_map = {'group_0_2': 1, \n",
        "                  'group_3_5': 2,\n",
        "                  'group_6_13': 3,\n",
        "                  'group_14_18': 4,\n",
        "                  'group_19_33': 5,\n",
        "                  'group_34_48': 6,\n",
        "                  'group_49_64': 7,\n",
        "                  'group_65_78': 8,\n",
        "                  'group_79_98': 9\n",
        "                  }\n",
        "\n",
        "        smoke_map = {\n",
        "            'never': 0,\n",
        "            'ex': 1,\n",
        "            'ltOnce': 2,\n",
        "            '1to10': 3,\n",
        "            '11to20': 4,\n",
        "            '21+': 5,\n",
        "            'ecig': 6\n",
        "        }\n",
        "\n",
        "        insomnia_map = {\n",
        "            'No': 0,\n",
        "            'Onceper2Weeks': 1,\n",
        "            '2to3': 2,\n",
        "            '1': 3,\n",
        "            '4+': 4\n",
        "        }\n",
        "\n",
        "        meta = meta.replace({'subject_age': age_map, \n",
        "                             'smoke_status_choice': smoke_map, \n",
        "                             'insomnia_status_choice': insomnia_map})\n",
        "        \n",
        "        return meta\n",
        "\n",
        "\n",
        "    def cleanup_extract(self) -> None:\n",
        "        file_name, _ = self.resources[self.split]\n",
        "        folder_name = file_name[:-4]  # Remove .zip part\n",
        "        shutil.rmtree(folder_name)\n",
        "\n",
        "\n",
        "    ##################\n",
        "    #   read audio\n",
        "    ##################\n",
        "\n",
        "    def process_files(self,\n",
        "                      audio_transforms: torch.nn.ModuleList=None, \n",
        "                      chunking: Optional[Tuple[int, int]]=None,\n",
        "                      normalize: Optional[Union[str, nn.Module]]=None):\n",
        "      \n",
        "        # Join audio path with file name for reading\n",
        "        audio_path = self.audio_paths[self.split]\n",
        "        audio_files = audio_path + self.meta_df['uuid'] + '.wav'\n",
        "\n",
        "        # Make chunker\n",
        "        if chunking:\n",
        "            self.chunk_idxs = []\n",
        "            chunking = AudioChunking(*chunking, idx_instead=True)\n",
        "\n",
        "        # Specify special case for accumulate statistic\n",
        "        if normalize == 'by_freq_band':\n",
        "            # Only reduce last dimension when calculating statistic\n",
        "            accum_dim = -1\n",
        "        else:\n",
        "            # Reduce whole tensor\n",
        "            accum_dim = None\n",
        "\n",
        "        for id, file in enumerate(tqdm(audio_files)):\n",
        "            # Read audio and perform transformations\n",
        "            specs = self._read_spec_audio(file, audio_transforms)\n",
        "\n",
        "            # Accumulate mean, std of the audio\n",
        "            self._accumulate_stats(specs, accum_dim)\n",
        "\n",
        "            if chunking:\n",
        "                for spec in specs:\n",
        "                    new_spec, chunk_idxs = chunking(spec)\n",
        "                    paths = self._dump_to_disk([new_spec])\n",
        "                    \n",
        "                    self.file_paths += paths*len(chunk_idxs)\n",
        "                    self.idxs += [id]*len(chunk_idxs)\n",
        "                    self.chunk_idxs += chunk_idxs\n",
        "            else:\n",
        "                paths = self._dump_to_disk(specs)\n",
        "                self.file_paths += paths\n",
        "                self.idxs += [id]*len(paths)\n",
        "\n",
        "        self._finalize_stats()\n",
        "\n",
        "        print(\"\\n> File processing complete\")\n",
        "\n",
        "        # Pickle for backup later\n",
        "        with open(f\"{self._temp_folder}/meta_df.pkl\",'wb') as tmp:\n",
        "            pickle.dump(self.meta_df, tmp)\n",
        "        with open(f\"{self._temp_folder}/file_paths.pkl\",'wb') as tmp:\n",
        "            pickle.dump(self.file_paths, tmp)\n",
        "        with open(f\"{self._temp_folder}/idxs.pkl\",'wb') as tmp:\n",
        "            pickle.dump(self.idxs, tmp)\n",
        "        with open(f\"{self._temp_folder}/chunk_idxs.pkl\",'wb') as tmp:\n",
        "            if self.chunk_idxs is None:\n",
        "                pickle.dump(\"None\", tmp)\n",
        "            else:\n",
        "                pickle.dump(self.chunk_idxs, tmp)\n",
        "\n",
        "\n",
        "    def _read_spec_audio(self, \n",
        "                         file: str,\n",
        "                         transforms: torch.nn.ModuleList=None) -> list:\n",
        "        wave = read_resample_audio(file, 8000).cuda()\n",
        "        if transforms:\n",
        "            specs = [trans(wave) for trans in transforms]\n",
        "        else:\n",
        "            specs = [wave]\n",
        "        return specs\n",
        "\n",
        "    def _dump_to_disk(self, specs: list or torch.Tensor) -> list:\n",
        "        file_paths = []\n",
        "        for spec in specs:\n",
        "            fd, path = tempfile.mkstemp(suffix=\".pt\", dir=self._temp_folder)\n",
        "            with os.fdopen(fd, 'wb') as tmp:\n",
        "                # Clone to prevent view preserving of PyTorch\n",
        "                # also moving tensor to cpu so when load up\n",
        "                # pytorch will not moving them to gpu bebforehand!\n",
        "                torch.save(spec.cpu(), tmp)\n",
        "            file_paths.append(path)\n",
        "        return file_paths\n",
        "\n",
        "    def _accumulate_stats(self, specs, dim=None):\n",
        "        if dim:\n",
        "            for spec in specs:\n",
        "                self.mean.append(spec.mean(dim=dim))\n",
        "                self.std.append(spec.std(dim=dim))\n",
        "        else:\n",
        "            for spec in specs:\n",
        "                self.mean.append(spec.mean().view(1))\n",
        "                self.std.append(spec.std().view(1))\n",
        "\n",
        "    def _finalize_stats(self):\n",
        "        self.mean = torch.cat(self.mean).mean(dim=-1).cpu()\n",
        "        self.std = torch.cat(self.std).mean(dim=-1).cpu()\n",
        "\n",
        "    def normalize_dataset(self):\n",
        "        print(\"\\n> Start normalizing data\")\n",
        "        for file_path in tqdm(np.unique(self.file_paths)):\n",
        "            spec = torch.load(file_path)\n",
        "            spec = self.scaler(spec)\n",
        "            with open(file_path, 'wb') as tmp:\n",
        "                torch.save(spec.cpu(), tmp)\n",
        "        print(\"\\n> Normalizing data complete\")\n",
        "\n",
        "\n",
        "    ###################\n",
        "    #   backup/load\n",
        "    ###################\n",
        "\n",
        "    def backup_to_drive(self, folder_id: str, upload_name: str):\n",
        "        if self.meta_df is None:\n",
        "            raise NameError(\"Cannot backup an empty dataset.\")\n",
        "        \n",
        "        os.system(f'zip -j ./{upload_name} {self._temp_folder}/*')\n",
        "        drive.Upload(upload_name, folder_id)\n",
        "        os.remove(upload_name)\n",
        "\n",
        "\n",
        "    def load_from_drive(self, folder_id: str, backuped_name: str):\n",
        "        drive.Download(backuped_name, folder_id)\n",
        "        os.system(f'unzip -o {backuped_name} -d {self._temp_folder}')\n",
        "        os.remove(backuped_name)\n",
        "        with open(f\"{self._temp_folder}/meta_df.pkl\",'rb') as tmp:\n",
        "            self.meta_df = pickle.load(tmp)\n",
        "        with open(f\"{self._temp_folder}/idxs.pkl\",'rb') as tmp:\n",
        "            self.idxs = pickle.load(tmp)\n",
        "        with open(f\"{self._temp_folder}/file_paths.pkl\",'rb') as tmp:\n",
        "            self.file_paths = pickle.load(tmp)\n",
        "        with open(f\"{self._temp_folder}/chunk_idxs.pkl\",'rb') as tmp:\n",
        "            self.chunk_idxs = pickle.load(tmp)\n",
        "            if self.chunk_idxs == \"None\":\n",
        "                self.chunk_idxs = None\n",
        "\n",
        "        # Replace old tmp dir with current tmp dir\n",
        "        for i, path in enumerate(self.file_paths):\n",
        "            self.file_paths[i] = self._temp_folder+'/'+path.split('/')[-1]\n",
        "\n",
        "    \n",
        "    ################\n",
        "    #   getitem\n",
        "    ################\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        spec = torch.load(self.file_paths[idx])\n",
        "        if self.chunk_idxs:\n",
        "            start, end = self.chunk_idxs[idx]\n",
        "            spec = spec[..., start:end]\n",
        "\n",
        "        meta = self.meta_df.iloc[self.idxs[idx]]\n",
        "       \n",
        "        label = meta.get('assessment_result')\n",
        "        if label is not None:\n",
        "            label = torch.tensor(label)\n",
        "            meta = meta.drop('assessment_result')\n",
        "\n",
        "        return spec, label, meta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTp2e79LSHVx"
      },
      "source": [
        "# Hàm xử lý âm thanh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEboAF063rLi"
      },
      "source": [
        "### Audio features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPA3iLpQ1fhs"
      },
      "source": [
        "# Spectrogram transformation\n",
        "n_fft = 2048\n",
        "win_length = 250\n",
        "hop_length = 100\n",
        "n_mels = 128\n",
        "n_mfcc = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "iuHhNXmvCYuR"
      },
      "source": [
        "#@markdown `spectrogram(waveform)` --> spec \n",
        "spectrogram = torchaudio.transforms.Spectrogram(\n",
        "    n_fft=n_fft,\n",
        "    win_length=win_length,\n",
        "    hop_length=hop_length,\n",
        "    center=True,\n",
        "    normalized=True,\n",
        "    pad_mode=\"reflect\",\n",
        "    power=2.0,\n",
        ")\n",
        "\n",
        "#@markdown `mel_spectrogram(waveform)` --> mel_spec \n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=8000,\n",
        "    n_fft=n_fft,\n",
        "    win_length=win_length,\n",
        "    hop_length=hop_length,\n",
        "    center=True,\n",
        "    pad_mode=\"reflect\",\n",
        "    power=2.0,\n",
        "    #norm='slaney',\n",
        "    onesided=True,\n",
        "    normalized=True,\n",
        "    n_mels=n_mels,\n",
        "    mel_scale=\"htk\",\n",
        ")\n",
        "\n",
        "#@markdown `log_spectrogram(spec)` --> log(spec)\n",
        "log_spectrogram = torchaudio.transforms.AmplitudeToDB(\n",
        "    stype='power',\n",
        "    top_db=80\n",
        ")\n",
        "\n",
        "#@markdown `mfcc_transform(waveform)` --> mfcc\n",
        "mfcc_transform = torchaudio.transforms.MFCC(\n",
        "    sample_rate=8000,\n",
        "    n_mfcc=n_mfcc,\n",
        "    log_mels=False,\n",
        "    melkwargs={\n",
        "      'n_fft': n_fft,\n",
        "      'n_mels': n_mels,\n",
        "      'hop_length': hop_length,\n",
        "      'win_length': win_length,\n",
        "    }\n",
        ")\n",
        "\n",
        "#@markdown `delta_transform(spec)` --> delta 1\n",
        "delta_transform = torchaudio.transforms.ComputeDeltas(\n",
        "    win_length = 5, \n",
        "    mode = 'replicate'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkxxsDa8r0ql"
      },
      "source": [
        "### Augmentation cho audio\n",
        "Bao gồm: thêm noise (nhiều mức độ), SpecAugment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "JK5OCYJfpYz6"
      },
      "source": [
        "#@markdown `SpecAugment(time_W=50, freq_W=50, T=80, F=80)`\n",
        "def _h_poly(t):\n",
        "    tt = t.unsqueeze(-2)**torch.arange(4, device=t.device).view(-1,1)\n",
        "    A = torch.tensor([\n",
        "        [1, 0, -3, 2],\n",
        "        [0, 1, -2, 1],\n",
        "        [0, 0, 3, -2],\n",
        "        [0, 0, -1, 1]\n",
        "    ], dtype=t.dtype, device=t.device)\n",
        "    return A @ tt\n",
        "\n",
        "\n",
        "def _cspline_interpolate(x, y, xs):\n",
        "    '''\n",
        "    Input x and y must be of shape (batch, n) or (n)\n",
        "    '''\n",
        "    m = (y[..., 1:] - y[..., :-1]) / (x[..., 1:] - x[..., :-1])\n",
        "    m = torch.cat([m[...,[0]], (m[...,1:] + m[...,:-1]) / 2, m[...,[-1]]], -1)\n",
        "    idxs = torch.searchsorted(x[..., 1:], xs)\n",
        "    dx = (x.take_along_dim(idxs+1, dim=-1) - x.take_along_dim(idxs, dim=-1))\n",
        "    hh = _h_poly((xs - x.take_along_dim(idxs, dim=-1)) / dx)\n",
        "    return hh[...,0,:] * y.take_along_dim(idxs, dim=-1) \\\n",
        "        + hh[...,1,:] * m.take_along_dim(idxs, dim=-1) * dx \\\n",
        "        + hh[...,2,:] * y.take_along_dim(idxs+1, dim=-1) \\\n",
        "        + hh[...,3,:] * m.take_along_dim(idxs+1, dim=-1) * dx\n",
        "        \n",
        "\n",
        "class SpecAugment(torch.nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      time_W: int = 0,\n",
        "      freq_W: int = 0,\n",
        "      T: int = 0,\n",
        "      F: int = 0,\n",
        "      mT: int = 1,\n",
        "      mF: int = 1\n",
        "  ) -> None:\n",
        "      super(SpecAugment, self).__init__()\n",
        "      self.identity_fn = lambda x: x\n",
        "      self.time_W = time_W\n",
        "      self.freq_W = freq_W\n",
        "      if time_W==0 and freq_W==0:\n",
        "          self.cum_warping = lambda x: x\n",
        "      elif time_W!=0 and freq_W==0:\n",
        "          self.cum_warping = self.time_warping\n",
        "      elif time_W==0 and freq_W!=0:\n",
        "          self.cum_warping = self.freq_warping\n",
        "      else:\n",
        "          self.cum_warping = self.time_freq_warping\n",
        "      self.time_masking = torchaudio.transforms.TimeMasking(time_mask_param=T) if T>0 else self.identity_fn\n",
        "      self.freq_masking = torchaudio.transforms.FrequencyMasking(freq_mask_param=F) if F>0 else self.identity_fn\n",
        "\n",
        "\n",
        "  def _get_warping_flow(self,\n",
        "                        warp_p: torch.Tensor,\n",
        "                        warp_d: torch.Tensor,\n",
        "                        interp_len: int) -> torch.Tensor:\n",
        "      '''\n",
        "      Get interpolated flow\n",
        "      Warning: This function doesn't check for batch size match between warp_p and warp_d\n",
        "      '''\n",
        "      device = warp_p.device\n",
        "      batch_size = warp_p.shape[0]\n",
        "\n",
        "      src_control_points = torch.stack([torch.tensor([0], device=device).expand(batch_size),\n",
        "                                        warp_p, torch.tensor([interp_len-1], device=device).expand(batch_size)], dim=1)\n",
        "      dest_control_points = torch.stack([torch.tensor([-1.], device=device).expand(batch_size),\n",
        "                                        (warp_p-warp_d)*2/(interp_len-1)-1, torch.tensor([1], device=device).expand(batch_size)], dim=1)\n",
        "\n",
        "      # Interpolate from 3 points to interp_len points\n",
        "      src_interp_points = torch.linspace(0, interp_len-1, interp_len, device=device).unsqueeze(0).expand(batch_size, -1)\n",
        "      dest_interp_points = _cspline_interpolate(src_control_points, dest_control_points, src_interp_points)\n",
        "\n",
        "      return dest_interp_points\n",
        "\n",
        "\n",
        "  def freq_warping(self, specs: torch.Tensor) -> torch.Tensor:\n",
        "      '''\n",
        "      Frequency warping augmentation, only return interpolated flow\n",
        "\n",
        "      param:\n",
        "        specs: spectrogram of size (batch, channel, freq_bin, length)\n",
        "      '''\n",
        "      W = self.freq_W\n",
        "      device = specs.device\n",
        "      batch_size, _, num_freqs, num_frames = specs.shape\n",
        "\n",
        "      warp_p = torch.randint(W, num_freqs - W, (batch_size,), device=device)\n",
        "\n",
        "      # Uniform distribution from (0,W) with chance to be up to W negative\n",
        "      warp_d = torch.randint(-W, W, (batch_size,), device=device)\n",
        "      \n",
        "      dest_freq_points = self._get_warping_flow(warp_p, warp_d, num_freqs)\n",
        "      dest_frame_points = torch.linspace(-1, 1, num_frames, device=device)\n",
        "\n",
        "      grid = torch.cat(\n",
        "          (dest_frame_points.view(-1,1).expand(batch_size,num_freqs,-1,-1),\n",
        "          dest_freq_points.view(batch_size,-1,1,1).expand(-1,-1,num_frames,-1)), dim=-1)\n",
        "\n",
        "      return torch.nn.functional.grid_sample(specs, grid, align_corners=True)\n",
        "\n",
        "\n",
        "  def time_warping(self, specs: torch.Tensor) -> torch.Tensor:\n",
        "      '''\n",
        "      Time warping augmentation, only return interpolated flow\n",
        "\n",
        "      param:\n",
        "        specs: spectrogram of size (batch, channel, freq_bin, length)\n",
        "      '''\n",
        "      W = self.time_W\n",
        "      device = specs.device\n",
        "      batch_size, _, num_freqs, num_frames = specs.shape\n",
        "\n",
        "      warp_p = torch.randint(W, num_frames - W, (batch_size,), device=device)\n",
        "\n",
        "      # Uniform distribution from (0,W) with chance to be up to W negative\n",
        "      warp_d = torch.randint(-W, W, (batch_size,), device=device)\n",
        "\n",
        "      # Interpolate from 3 points to num_frames points\n",
        "      dest_frame_points = self._get_warping_flow(warp_p, warp_d, num_frames)\n",
        "      dest_freq_points = torch.linspace(-1, 1, num_freqs, device=device)\n",
        "\n",
        "      grid = torch.cat(\n",
        "          (dest_frame_points.view(batch_size,1,-1,1).expand(-1,num_freqs,-1,-1),\n",
        "          dest_freq_points.view(-1,1,1).expand(batch_size,-1,num_frames,-1)), dim=-1)\n",
        "\n",
        "      return torch.nn.functional.grid_sample(specs, grid, align_corners=True)\n",
        "\n",
        "\n",
        "  def time_freq_warping(self,specs: torch.Tensor) -> torch.Tensor:\n",
        "      '''\n",
        "      Doing both time warping and frequency warping augmentation\n",
        "\n",
        "      param:\n",
        "        specs: spectrogram of size (batch, channel, freq_bin, length)\n",
        "        W: strength of warp\n",
        "      '''\n",
        "      device = specs.device\n",
        "      batch_size, _, num_freqs, num_frames = specs.shape\n",
        "\n",
        "      time_warp_p = torch.randint(self.time_W, num_frames - self.time_W, (batch_size,), device=device)\n",
        "      freq_warp_p = torch.randint(self.freq_W, num_freqs - self.freq_W, (batch_size,), device=device)\n",
        "\n",
        "      # Uniform distribution from (0,W) with chance to be up to W negative\n",
        "      time_warp_d = torch.randint(-self.time_W, self.time_W, (batch_size,), device=device)\n",
        "      freq_warp_d = torch.randint(-self.freq_W, self.freq_W, (batch_size,), device=device)\n",
        "\n",
        "      # Interpolate lên theo kích thước spec\n",
        "      dest_freq_points = self._get_warping_flow(freq_warp_p, freq_warp_d, num_freqs)\n",
        "      dest_frame_points = self._get_warping_flow(time_warp_p, time_warp_d, num_frames)\n",
        "\n",
        "      grid = torch.cat(\n",
        "          (dest_frame_points.view(batch_size,1,-1,1).expand(-1,num_freqs,-1,-1),\n",
        "          dest_freq_points.view(batch_size,-1,1,1).expand(-1,-1,num_frames,-1)), dim=-1)\n",
        "\n",
        "      return torch.nn.functional.grid_sample(specs, grid, align_corners=True)\n",
        "\n",
        "\n",
        "  def forward(self, specs: torch.Tensor) -> torch.Tensor:\n",
        "      aug_specs = self.cum_warping(specs)\n",
        "      aug_specs = self.time_masking(aug_specs)\n",
        "      aug_specs = self.freq_masking(aug_specs)\n",
        "      return aug_specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "fOlyVYDtuJDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d1ca1e-6d0a-4112-ff1b-b3b343a9642b"
      },
      "source": [
        "#@markdown Tải noise audio\n",
        "import requests\n",
        "\n",
        "!mkdir _sample_data\n",
        "SAMPLE_NOISE_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav\"\n",
        "SAMPLE_NOISE_PATH = os.path.join('_sample_data', \"bg.wav\")\n",
        "SAMPLE_RIR_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav\"\n",
        "SAMPLE_RIR_PATH = os.path.join('_sample_data', \"rir.wav\")\n",
        "\n",
        "def _fetch_data():\n",
        "  uri = [\n",
        "    (SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH),\n",
        "    (SAMPLE_RIR_URL, SAMPLE_RIR_PATH)\n",
        "  ]\n",
        "  for url, path in uri:\n",
        "    with open(path, 'wb') as file_:\n",
        "      file_.write(requests.get(url).content)\n",
        "\n",
        "_fetch_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘_sample_data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcKSZU1F4rAK"
      },
      "source": [
        "def _get_sample(path, resample=None):\n",
        "  effects = [\n",
        "    [\"remix\", \"1\"]\n",
        "  ]\n",
        "  if resample:\n",
        "    effects.extend([\n",
        "      [\"lowpass\", f\"{resample // 2}\"],\n",
        "      [\"rate\", f'{resample}'],\n",
        "    ])\n",
        "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
        "\n",
        "def get_noise_sample(*, resample=None):\n",
        "  return _get_sample(SAMPLE_NOISE_PATH, resample=resample)\n",
        "\n",
        "def get_rir_sample(*, resample=None, processed=False):\n",
        "  rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
        "  if not processed:\n",
        "    return rir_raw, sample_rate\n",
        "  rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
        "  rir = rir / torch.norm(rir, p=2)\n",
        "  rir = torch.flip(rir, [1])\n",
        "  return rir, sample_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "BEH8Qh2SqH6c"
      },
      "source": [
        "import math\n",
        "\n",
        "#@markdown `RoomReverb`, `NoiseInject`, `PhoneSim`\n",
        "class RoomReverb(torch.nn.Module):\n",
        "    def __init__(self, rir_list):\n",
        "        super(RoomReverb, self).__init__()\n",
        "        self.rirs = rir_list\n",
        "\n",
        "    def _get_rir(self):\n",
        "        if type(self.rirs) is list:\n",
        "            return random.choice(self.rirs)\n",
        "        else: \n",
        "            return next(self.rirs)\n",
        "\n",
        "    def forward(self, wave: torch.Tensor):\n",
        "        rir = self._get_rir()\n",
        "        _wave = torch.nn.functional.pad(wave, (rir.shape[-1]-1, 0))\n",
        "        _wave = torch.nn.functional.conv1d(_wave[None, ...], rir[None, ...])[0]\n",
        "        return _wave\n",
        "\n",
        "\n",
        "class NoiseInject(torch.nn.Module):\n",
        "    def __init__(self, noise_list, snr_db):\n",
        "        super(NoiseInject, self).__init__()\n",
        "        self.noises = noise_list\n",
        "        self.snr_db = snr_db\n",
        "\n",
        "    def _get_noise(self):\n",
        "        if type(self.noises) is list:\n",
        "            return random.choice(self.noises)\n",
        "        else: \n",
        "            return next(self.noises)\n",
        "\n",
        "    def forward(self, wave: torch.Tensor):\n",
        "        noise = self._get_noise()\n",
        "        _noise = noise.repeat(1, 1 + wave.shape[-1] // noise.shape[-1])[..., :wave.shape[-1]]\n",
        "        scale = math.exp(self.snr_db / 10) * _noise.norm(p=2) / wave.norm(p=2)\n",
        "        _wave = (scale * wave + _noise) / 2\n",
        "        return _wave\n",
        "\n",
        "\n",
        "class PhoneSim(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PhoneSim, self).__init__()\n",
        "\n",
        "    def forward(self, wave: torch.Tensor):\n",
        "        device = wave.device\n",
        "        _wave = wave.cpu()\n",
        "        _wave, _ = torchaudio.sox_effects.apply_effects_tensor(\n",
        "          _wave, 8000,\n",
        "          effects=[[\"lowpass\", \"4000\"],\n",
        "                   [\"compand\", \"0.02,0.05\", \"-60,-60,-30,-10,-20,-8,-5,-8,-2,-8\", \"-8\", \"-7\", \"0.05\"]]\n",
        "        )\n",
        "        _wave = torchaudio.functional.apply_codec(_wave, 8000, format=\"gsm\")\n",
        "        return _wave.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6qT41qMqY10"
      },
      "source": [
        "rir, _ = get_rir_sample(resample=8000, processed=True)\n",
        "noise, _ = get_noise_sample(resample=8000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Lc0HIA2ZjG"
      },
      "source": [
        "## Các hàm bổ trợ trực quan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jQCI3iYC5fVe"
      },
      "source": [
        "#@markdown Vẽ specgram `plot_specgram(wave, sr, title, xlim, ylim)`\n",
        "#@markdown (specgram chỉ đơn giản là apply discrete-time Fourier transform)\n",
        "\n",
        "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
        "  # Tensor --> Numpy\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
        "\n",
        "  figure, axes = plt.subplots(num_channels, 1)\n",
        "  if num_channels == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "  # Plot specgram for each channel\n",
        "  for c in range(num_channels):\n",
        "    axes[c].specgram(waveform[c], Fs=sample_rate)\n",
        "    if num_channels > 1:\n",
        "      axes[c].set_ylabel(f'Channel {c+1}')\n",
        "    if xlim:\n",
        "      axes[c].set_xlim(xlim)\n",
        "  figure.suptitle(title)\n",
        "  plt.show(block=False)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown Vẽ waveform `plot_waveform(wave, sr, title, xlim, ylim)`\n",
        "\n",
        "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n",
        "  # Tensor --> Numpy\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
        "\n",
        "  figure, axes = plt.subplots(num_channels, 1)\n",
        "  if num_channels == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "  # Plot waveform for each channel\n",
        "  for c in range(num_channels):\n",
        "    axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
        "    axes[c].grid(True)\n",
        "    if num_channels > 1:\n",
        "      axes[c].set_ylabel(f'Channel {c+1}')\n",
        "    if xlim:\n",
        "      axes[c].set_xlim(xlim)\n",
        "    if ylim:\n",
        "      axes[c].set_ylim(ylim)\n",
        "  figure.suptitle(title)\n",
        "  plt.show(block=False)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown Vẽ spectrogram `plot_spectrogram(spec, axs, title, ylabel, aspect, xmax)`\n",
        "\n",
        "def plot_spectrogram(spec, fig=None, axs=None, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n",
        "  if axs is None:\n",
        "    fig, axs = plt.subplots(1, 1)\n",
        "  axs.set_title(title or 'Spectrogram (db)')\n",
        "  axs.set_ylabel(ylabel)\n",
        "  axs.set_xlabel('frame')\n",
        "  im = axs.imshow(log_spectrogram(spec), origin='lower', aspect=aspect)\n",
        "  if xmax:\n",
        "    axs.set_xlim((0, xmax))\n",
        "  fig.colorbar(im, ax=axs)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown Hiển thị audio box `play_audio(wave, sr)`\n",
        "\n",
        "def play_audio(waveform, sample_rate):\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  if num_channels == 1:\n",
        "    display(Audio(waveform[0], rate=sample_rate))\n",
        "  elif num_channels == 2:\n",
        "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
        "  else:\n",
        "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y9lvxslO4sU"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaOs5PBXAil-"
      },
      "source": [
        "## AST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6QXGlT6Aj8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba51f69-b54c-4887-d5e3-6b12dbdba13e"
      },
      "source": [
        "!pip install timm==0.4.5 wget==3.2\n",
        "!pip install einops"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timm==0.4.5 in /usr/local/lib/python3.7/dist-packages (0.4.5)\n",
            "Requirement already satisfied: wget==3.2 in /usr/local/lib/python3.7/dist-packages (3.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm==0.4.5) (0.10.0+cu102)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm==0.4.5) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm==0.4.5) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.4.5) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm==0.4.5) (7.1.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A5-qarJKfUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640f81f7-e9f3-4a62-d89a-2d06280d1858"
      },
      "source": [
        "!mkdir '../../pretrained_models'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘../../pretrained_models’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P6qyQBXUFkW"
      },
      "source": [
        "os.environ['TORCH_HOME'] = '../../pretrained_models'\n",
        "import timm\n",
        "from timm.models.layers import to_2tuple,trunc_normal_\n",
        "import wget\n",
        "from einops.layers.torch import Reduce\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hmN3pAlThLh"
      },
      "source": [
        "# override the timm package to relax the input shape constraint.\n",
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "\n",
        "        img_size = to_2tuple(img_size)\n",
        "        patch_size = to_2tuple(patch_size)\n",
        "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "class ASTModel(nn.Module):\n",
        "    \"\"\"\n",
        "    The AST model.\n",
        "    :param representation_size: the representation dimension\n",
        "    :param fstride: the stride of patch spliting on the frequency dimension, for 16*16 patchs, fstride=16 means no overlap, fstride=10 means overlap of 6\n",
        "    :param tstride: the stride of patch spliting on the time dimension, for 16*16 patchs, tstride=16 means no overlap, tstride=10 means overlap of 6\n",
        "    :param input_fdim: the number of frequency bins of the input spectrogram\n",
        "    :param input_tdim: the number of time frames of the input spectrogram\n",
        "    :param imagenet_pretrain: if use ImageNet pretrained model\n",
        "    :param audioset_pretrain: if use full AudioSet and ImageNet pretrained model\n",
        "    :param model_size: the model size of AST, should be in [tiny224, small224, base224, base384], base224 and base 384 are same model, but are trained differently during ImageNet pretraining.\n",
        "    \"\"\"\n",
        "    def __init__(self, representation_size=None, fstride=10, tstride=10, input_fdim=128, input_tdim=1024, imagenet_pretrain=True, audioset_pretrain=False, model_size='base384', verbose=True):\n",
        "\n",
        "        super(ASTModel, self).__init__()\n",
        "        assert timm.__version__ == '0.4.5', 'Please use timm == 0.4.5, the code might not be compatible with newer versions.'\n",
        "\n",
        "        if verbose == True:\n",
        "            print('---------------AST Model Summary---------------')\n",
        "            print('ImageNet pretraining: {:s}, AudioSet pretraining: {:s}'.format(str(imagenet_pretrain),str(audioset_pretrain)))\n",
        "        # override timm input shape restriction\n",
        "        timm.models.vision_transformer.PatchEmbed = PatchEmbed\n",
        "\n",
        "        # if AudioSet pretraining is not used (but ImageNet pretraining may still apply)\n",
        "        if audioset_pretrain == False:\n",
        "            if model_size == 'tiny224':\n",
        "                self.v = timm.create_model('vit_deit_tiny_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
        "            elif model_size == 'small224':\n",
        "                self.v = timm.create_model('vit_deit_small_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
        "            elif model_size == 'base224':\n",
        "                self.v = timm.create_model('vit_deit_base_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
        "            elif model_size == 'base384':\n",
        "                self.v = timm.create_model('vit_deit_base_distilled_patch16_384', pretrained=imagenet_pretrain)\n",
        "            else:\n",
        "                raise Exception('Model size must be one of tiny224, small224, base224, base384.')\n",
        "            self.original_num_patches = self.v.patch_embed.num_patches\n",
        "            self.oringal_hw = int(self.original_num_patches ** 0.5)\n",
        "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
        "            # self.pooling_layer = nn.LayerNorm(self.original_embedding_dim)\n",
        "            # original bert do max/mean pooling, idk why author use layernorm?\n",
        "            self.pooling_layer = Reduce('b n e -> b e', reduction='mean')\n",
        "            \n",
        "            if representation_size:\n",
        "                self.pre_logits = nn.Sequential(OrderedDict([\n",
        "                    ('fc', nn.Linear(self.original_embedding_dim, representation_size)),\n",
        "                    ('act', nn.Tanh())\n",
        "                ]))\n",
        "            else:\n",
        "                self.pre_logits = nn.Identity()\n",
        "            \n",
        "            # automatcially get the intermediate shape\n",
        "            f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim)\n",
        "            num_patches = f_dim * t_dim\n",
        "            self.v.patch_embed.num_patches = num_patches\n",
        "            if verbose == True:\n",
        "                print('frequncey stride={:d}, time stride={:d}'.format(fstride, tstride))\n",
        "                print('number of patches={:d}'.format(num_patches))\n",
        "\n",
        "            # the linear projection layer\n",
        "            new_proj = torch.nn.Conv2d(1, self.original_embedding_dim, kernel_size=(16, 16), stride=(fstride, tstride))\n",
        "            if imagenet_pretrain == True:\n",
        "                new_proj.weight = torch.nn.Parameter(torch.sum(self.v.patch_embed.proj.weight, dim=1).unsqueeze(1))\n",
        "                new_proj.bias = self.v.patch_embed.proj.bias\n",
        "            self.v.patch_embed.proj = new_proj\n",
        "\n",
        "            # the positional embedding\n",
        "            if imagenet_pretrain == True:\n",
        "                # get the positional embedding from deit model, skip the first two tokens (cls token and distillation token), reshape it to original 2D shape (24*24).\n",
        "                new_pos_embed = self.v.pos_embed[:, 2:, :].detach().reshape(1, self.original_num_patches, self.original_embedding_dim).transpose(1, 2).reshape(1, self.original_embedding_dim, self.oringal_hw, self.oringal_hw)\n",
        "                # cut (from middle) or interpolate the second dimension of the positional embedding\n",
        "                if t_dim <= self.oringal_hw:\n",
        "                    new_pos_embed = new_pos_embed[:, :, :, int(self.oringal_hw / 2) - int(t_dim / 2): int(self.oringal_hw / 2) - int(t_dim / 2) + t_dim]\n",
        "                else:\n",
        "                    new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(self.oringal_hw, t_dim), mode='bilinear')\n",
        "                # cut (from middle) or interpolate the first dimension of the positional embedding\n",
        "                if f_dim <= self.oringal_hw:\n",
        "                    new_pos_embed = new_pos_embed[:, :, int(self.oringal_hw / 2) - int(f_dim / 2): int(self.oringal_hw / 2) - int(f_dim / 2) + f_dim, :]\n",
        "                else:\n",
        "                    new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')\n",
        "                # flatten the positional embedding\n",
        "                new_pos_embed = new_pos_embed.reshape(1, self.original_embedding_dim, num_patches).transpose(1,2)\n",
        "                # concatenate the above positional embedding with the cls token and distillation token of the deit model.\n",
        "                self.v.pos_embed = nn.Parameter(torch.cat([self.v.pos_embed[:, :2, :].detach(), new_pos_embed], dim=1))\n",
        "            else:\n",
        "                # if not use imagenet pretrained model, just randomly initialize a learnable positional embedding\n",
        "                # TODO can use sinusoidal positional embedding instead\n",
        "                new_pos_embed = nn.Parameter(torch.zeros(1, self.v.patch_embed.num_patches + 2, self.original_embedding_dim))\n",
        "                self.v.pos_embed = new_pos_embed\n",
        "                trunc_normal_(self.v.pos_embed, std=.02)\n",
        "\n",
        "        # now load a model that is pretrained on both ImageNet and AudioSet\n",
        "        elif audioset_pretrain == True:\n",
        "            if audioset_pretrain == True and imagenet_pretrain == False:\n",
        "                raise ValueError('currently model pretrained on only audioset is not supported, please set imagenet_pretrain = True to use audioset pretrained model.')\n",
        "            if model_size != 'base384':\n",
        "                raise ValueError('currently only has base384 AudioSet pretrained model.')\n",
        "            if os.path.exists('../../pretrained_models/audioset_10_10_0.4593.pth') == False:\n",
        "                # this model performs 0.4593 mAP on the audioset eval set\n",
        "                audioset_mdl_url = 'https://www.dropbox.com/s/cv4knew8mvbrnvq/audioset_0.4593.pth?dl=1'\n",
        "                wget.download(audioset_mdl_url, out='../../pretrained_models/audioset_10_10_0.4593.pth')\n",
        "            sd = torch.load('../../pretrained_models/audioset_10_10_0.4593.pth')\n",
        "            audio_model = ASTModel(representation_size, fstride=10, tstride=10, input_fdim=128, input_tdim=1024, imagenet_pretrain=False, audioset_pretrain=False, model_size='base384', verbose=False)\n",
        "            audio_model = torch.nn.DataParallel(audio_model)\n",
        "            audio_model.load_state_dict(sd, strict=False)\n",
        "            self.v = audio_model.module.v\n",
        "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
        "            # self.pooling_layer = nn.LayerNorm(self.original_embedding_dim)\n",
        "            # original bert do max/mean pooling, idk why author use layernorm?\n",
        "            self.pooling_layer = Reduce('b n e -> b e', reduction='mean')\n",
        "            if representation_size:\n",
        "                self.pre_logits = nn.Sequential(OrderedDict([\n",
        "                    ('fc', nn.Linear(self.original_embedding_dim, representation_size)),\n",
        "                    ('act', nn.Tanh())\n",
        "                ]))\n",
        "            else:\n",
        "                self.pre_logits = nn.Identity()\n",
        "\n",
        "            f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim)\n",
        "            num_patches = f_dim * t_dim\n",
        "            self.v.patch_embed.num_patches = num_patches\n",
        "            if verbose == True:\n",
        "                print('frequncey stride={:d}, time stride={:d}'.format(fstride, tstride))\n",
        "                print('number of patches={:d}'.format(num_patches))\n",
        "\n",
        "            new_pos_embed = self.v.pos_embed[:, 2:, :].detach().reshape(1, 1212, 768).transpose(1, 2).reshape(1, 768, 12, 101)\n",
        "            # if the input sequence length is larger than the original audioset (10s), then cut the positional embedding\n",
        "            if t_dim < 101:\n",
        "                new_pos_embed = new_pos_embed[:, :, :, 50 - int(t_dim/2): 50 - int(t_dim/2) + t_dim]\n",
        "            # otherwise interpolate\n",
        "            else:\n",
        "                new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(12, t_dim), mode='bilinear')\n",
        "            new_pos_embed = new_pos_embed.reshape(1, 768, num_patches).transpose(1, 2)\n",
        "            self.v.pos_embed = nn.Parameter(torch.cat([self.v.pos_embed[:, :2, :].detach(), new_pos_embed], dim=1))\n",
        "\n",
        "        # Convert modulelist to sequential\n",
        "        self.v.blocks = nn.Sequential(*self.v.blocks)\n",
        "        self.output_size = representation_size or self.original_embedding_dim\n",
        "\n",
        "    def get_shape(self, fstride, tstride, input_fdim=128, input_tdim=1024):\n",
        "        test_input = torch.randn(1, 1, input_fdim, input_tdim)\n",
        "        test_proj = nn.Conv2d(1, self.original_embedding_dim, kernel_size=(16, 16), stride=(fstride, tstride))\n",
        "        test_out = test_proj(test_input)\n",
        "        f_dim = test_out.shape[2]\n",
        "        t_dim = test_out.shape[3]\n",
        "        return f_dim, t_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: the input spectrogram, expected shape: (batch_size, num_channel (alway 1), frequency_bins, time_frame_num), e.g., (12, 1, 128, 1024)\n",
        "        :return: prediction\n",
        "        \"\"\"\n",
        "        # expect input x = (batch_size, num_channel (alway 1), frequency_bins, time_frame_num), e.g., (12, 1, 128, 1024)\n",
        "        x = self.v.patch_embed(x)\n",
        "        cls_tokens = self.v.cls_token.expand(x.shape[0], -1, -1)\n",
        "        dist_token = self.v.dist_token.expand(x.shape[0], -1, -1)\n",
        "        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
        "        x = x + self.v.pos_embed\n",
        "        x = self.v.pos_drop(x)\n",
        "        x = self.v.blocks(x)\n",
        "        x = self.v.norm(x)[:,0:2]\n",
        "        x = self.pooling_layer(x)\n",
        "        x = self.pre_logits(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def num_filters(self):\n",
        "        return self.output_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Je1YJibDQ99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4881dec5-d9c9-40a5-a84d-0e65bd50159b"
      },
      "source": [
        "ast_mdl = ASTModel(representation_size=None, \\\n",
        "                   fstride=10, tstride=10, \\\n",
        "                   input_fdim=128, input_tdim=1024, \\\n",
        "                   audioset_pretrain=True, \\\n",
        "                   model_size='base384')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------AST Model Summary---------------\n",
            "ImageNet pretraining: True, AudioSet pretraining: True\n",
            "frequncey stride=10, time stride=10\n",
            "number of patches=1212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3613: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ-sePwC7BDh"
      },
      "source": [
        "# Lightning module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGMCT2ocfb9A"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt9IviIkfqt7"
      },
      "source": [
        "from pytorch_lightning.callbacks import Callback, LearningRateMonitor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "IuxxKOO_FCaj"
      },
      "source": [
        "#@markdown Upload lightning_logs folder to gdrive (**depricated** since we're using Neptune logger)\n",
        "\n",
        "class BackupCallback(Callback):\n",
        "    def _backup(self):\n",
        "        os.system(f\"zip -r ./tmp_lightning_logs_{experiment_id}.zip ./lightning_logs\")\n",
        "        try:\n",
        "            drive.Upload(f\"tmp_lightning_logs_{experiment_id}.zip\", model_zoo)\n",
        "        except:\n",
        "            print(\"Upload failed.\")\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        if (trainer.current_epoch+1)%20 == 0:\n",
        "            self._backup()\n",
        "            print(f\"Lightning logs backuped at epoch {trainer.current_epoch}.\")\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        self._backup()\n",
        "        print(f\"Lightning logs backuped at the end of training.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "dpxqdHn-3mfP"
      },
      "source": [
        "#@markdown Helper function: confusion matrix tensor --> Neptune file\n",
        "from neptune.new.types import File\n",
        "\n",
        "def comfmat_to_neptune_html(confmat):\n",
        "    return File.as_html(pd.DataFrame(confmat.cpu().numpy()))\n",
        "\n",
        "def comfmat_to_neptune_img(confmat):\n",
        "    df = pd.DataFrame(confmat.cpu().numpy().astype(int))\n",
        "    plt.close('all')\n",
        "    fig = plt.figure(figsize = (7,7))\n",
        "    fig.add_subplot(sns.heatmap(df, annot=True, cmap=\"YlGnBu\", fmt=\"d\"))\n",
        "    return File.as_image(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "x1bvgNgkvKzG"
      },
      "source": [
        "#@markdown Logging metrics to Neptune logger\n",
        "from torchmetrics import Accuracy, MetricCollection, Precision, Recall, ConfusionMatrix, AUROC, AverageMeter\n",
        "\n",
        "class LogMetricsNeptune(Callback):\n",
        "    def __init__(self):\n",
        "        self.metrics = MetricCollection([Accuracy(compute_on_step=False), \n",
        "                                         Precision(compute_on_step=False), \n",
        "                                         Recall(compute_on_step=False), \n",
        "                                         AUROC(num_classes=2, pos_label=1, compute_on_step=False)])\n",
        "        self.comfmat = ConfusionMatrix(num_classes=2, compute_on_step=False)\n",
        "        self.avg_loss = AverageMeter()\n",
        "\n",
        "    def _setup(self, trainer, pl_module, stage=None):\n",
        "        # dunno why setup hook not called when I call trainer.test?\n",
        "        device = pl_module.device\n",
        "        self.metrics.to(device)\n",
        "        self.comfmat.to(device)\n",
        "        self.avg_loss.to(device)\n",
        "\n",
        "    def on_fit_start(self, trainer, pl_module):\n",
        "        self._setup(trainer, pl_module, \"fit\")\n",
        "\n",
        "    def on_test_start(self, trainer, pl_module):\n",
        "        self._setup(trainer, pl_module, \"test\")\n",
        "\n",
        "    # def on_pretrain_routine_start(self, trainer, pl_module):\n",
        "    #     device = pl_module.device\n",
        "    #     self.metrics = MetricCollection([Accuracy(compute_on_step=False), \n",
        "    #                                      Precision(compute_on_step=False), \n",
        "    #                                      Recall(compute_on_step=False), \n",
        "    #                                      AUC(reorder=True, compute_on_step=False)]).to(device)\n",
        "    #     self.comfmat = ConfusionMatrix(num_classes=2, compute_on_step=False).to(device)\n",
        "    #     self.avg_loss = AverageMeter().to(device)\n",
        "\n",
        "    def _update_metrics(self, **kwargs):\n",
        "        # Prevent autocast since sometime it turn y to float, cause metric raise error...\n",
        "        probs = kwargs['probs']\n",
        "        targets = kwargs['targets']\n",
        "        loss = kwargs['loss']\n",
        "        with torch.cuda.amp.autocast(False):\n",
        "            self.metrics(probs, targets)\n",
        "            self.comfmat(probs, targets)\n",
        "            self.avg_loss(loss)\n",
        "\n",
        "\n",
        "    def _log_metrics(self, trainer, type: str):\n",
        "        comfmat_file = comfmat_to_neptune_img(self.comfmat.compute())\n",
        "        \n",
        "        if trainer.logger is None:\n",
        "            return\n",
        "        # Catch exception from stopped logger\n",
        "        try:\n",
        "            # Log confusion matrix\n",
        "            trainer.logger.experiment[f'comfmat/{type}/latest'].upload(comfmat_file)\n",
        "            trainer.logger.experiment[f'comfmat/{type}/series'].log(comfmat_file)\n",
        "            \n",
        "            # Log metrics\n",
        "            trainer.logger.experiment[f'metrics/{type}/loss'].log(self.avg_loss.compute())\n",
        "            for key, value in self.metrics.compute().items():\n",
        "                trainer.logger.experiment[f'metrics/{type}/{key}'].log(value)\n",
        "        except Exception as e:\n",
        "            if type(e).__name__ == \"InactiveRunException\":\n",
        "                print(\"Warning: Neptune logger has stopped running. Logging couldn't be done.\")\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "\n",
        "    def _print_metrics(self):\n",
        "        print(\"Loss: \", self.avg_loss.compute().item())\n",
        "        for key, value in self.metrics.compute().items():\n",
        "            print(f\"{key}: {value}\")\n",
        "        \n",
        "\n",
        "    def _reset_metrics(self):\n",
        "        self.comfmat.reset()\n",
        "        self.metrics.reset()\n",
        "        self.avg_loss.reset()\n",
        "\n",
        "\n",
        "    def on_train_batch_end(self, trainer, pl_module, \n",
        "                           outputs, batch, batch_idx, dataloader_idx):\n",
        "        self._update_metrics(probs=outputs[\"probs\"], targets=outputs[\"targets\"], loss=outputs[\"loss\"])\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        self._log_metrics(trainer, \"train\")\n",
        "        self._reset_metrics()\n",
        "\n",
        "    def on_validation_batch_end(self, trainer, pl_module, \n",
        "                           outputs, batch, batch_idx, dataloader_idx):\n",
        "        self._update_metrics(probs=outputs[\"probs\"], targets=outputs[\"targets\"], loss=outputs[\"loss\"])\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        self._log_metrics(trainer, \"val\")\n",
        "        self._reset_metrics()\n",
        "\n",
        "    def on_test_batch_end(self, trainer, pl_module, \n",
        "                           outputs, batch, batch_idx, dataloader_idx):\n",
        "        self._update_metrics(probs=outputs[\"probs\"], targets=outputs[\"targets\"], loss=outputs[\"loss\"])\n",
        "\n",
        "    def on_test_epoch_end(self, trainer, pl_module):\n",
        "        self._log_metrics(trainer, \"test\")\n",
        "        self._print_metrics()\n",
        "        self._reset_metrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3mtpjC95X1Io"
      },
      "source": [
        "#@markdown Save last checkpoint to Neptune logger\n",
        "import glob\n",
        "\n",
        "class SaveCheckpointNeptune(Callback):\n",
        "    def __init__(self, interval: int=1):\n",
        "        self.interval = interval\n",
        "\n",
        "\n",
        "    def _upload_latest_ckp(self, trainer):\n",
        "        if trainer.logger is None:\n",
        "            return\n",
        "        try:\n",
        "            ckp_dir = \"/\".join([trainer.default_root_dir, trainer.logger.name, trainer.logger.version])\n",
        "            ckp_file = glob.glob(ckp_dir+\"/checkpoints/*.ckpt\")[0]\n",
        "            trainer.logger.experiment[f'checkpoints/latest'].upload(ckp_file)\n",
        "            print(f\"{trainer.current_epoch} epoch backuped: {ckp_file}\")\n",
        "        except Exception as e:\n",
        "            if type(e).__name__ == \"InactiveRunException\":\n",
        "                print(\"Warning: Neptune logger has stopped running. Logging couldn't be done.\")\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        if trainer.current_epoch%self.interval != 0 or trainer.current_epoch == 0:\n",
        "            return\n",
        "        self._upload_latest_ckp(trainer)\n",
        "\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        self._upload_latest_ckp(trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OrjbSG6qfnN"
      },
      "source": [
        "## Main module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJggwl5C2OpG"
      },
      "source": [
        "class AICOVIDModule(pl.LightningModule):\n",
        "    def __init__(self, model: nn.Module, \n",
        "                 optim_config: dict,\n",
        "                 task_weight: Union[Tuple[float, Optional[float]], Tuple[float, Optional[float], Optional[float]]]=(1.,1.),\n",
        "                 augment=None):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.model = model\n",
        "        self.augment = augment\n",
        "        self.optim_config = optim_config\n",
        "\n",
        "        # Multi-task heads and losses\n",
        "        try:\n",
        "            num_filters = model.num_filters\n",
        "        except:\n",
        "            raise KeyError(\"Model must have a property named `num_filters` that return the output size of model.\")\n",
        "\n",
        "        # Predict covid task\n",
        "        self.covid_head = nn.Linear(num_filters, 1)\n",
        "        \n",
        "        # Predict gender task\n",
        "        self.gender_head = nn.Linear(num_filters, 2)\n",
        "\n",
        "        # Predict smoker, insomnia, 9 cols from medical, 13 cols from symptom\n",
        "        self.multilabel = nn.Linear(num_filters, 24)\n",
        "        \n",
        "        reduction = optim_config['reduction']\n",
        "        self.covid_loss = nn.BCEWithLogitsLoss(reduction=reduction)\n",
        "        self.gender_loss = nn.CrossEntropyLoss(reduction=reduction)\n",
        "        self.multilabel_loss = nn.BCEWithLogitsLoss(reduction=reduction)\n",
        "\n",
        "        if len(task_weight) == 2:\n",
        "            self.covid_alpha, t = task_weight\n",
        "            self.gender_alpha = t\n",
        "            self.multilabel_alpha = t\n",
        "        else:\n",
        "            self.covid_alpha, self.gender_alpha, self.multilabel_alpha = task_weight\n",
        "\n",
        "\n",
        "    ################################################\n",
        "    # For inference/training forward\n",
        "    ################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Do a forward pass for training/validating, perform feature extract\n",
        "        '''\n",
        "        return self.model(x)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx: int , dataloader_idx: int = None):\n",
        "        '''\n",
        "        Do inference\n",
        "        '''\n",
        "        y_hat = self(batch)\n",
        "        y_hat = self.covid_head(y_hat)\n",
        "        y_hat = torch.sigmoid_(y_hat).squeeze(-1)\n",
        "        \n",
        "        # Nếu muốn lấy class thì tự implement, predict_step chỉ nên trả về prob\n",
        "        \n",
        "        return y_hat\n",
        "\n",
        "\n",
        "    ################################################\n",
        "    # Main function for train/val/test\n",
        "    ################################################\n",
        "    \n",
        "    def loss_fn(self, feats, covid_labels, sex_labels, multilabels):\n",
        "        '''\n",
        "        Calculate loss ~manually since we need to handle autocast~\n",
        "        '''\n",
        "        logit = self.covid_head(feats).squeeze(-1)\n",
        "        covid_loss = self.covid_loss(logit, covid_labels.float())\n",
        "\n",
        "        if self.gender_alpha:\n",
        "            logit = self.gender_head(feats)\n",
        "            gender_loss = self.gender_loss(logit, sex_labels.long())\n",
        "        else:\n",
        "            gender_loss = 0\n",
        "\n",
        "        if self.multilabel_alpha:\n",
        "            # since some samples doesnt have medical metadata, we need to filter out those samples\n",
        "            nonNA_slice = ~torch.any(multilabels.isnan(), dim=-1)\n",
        "            if nonNA_slice.sum() != 0:\n",
        "                logit = self.multilabel(feats)\n",
        "                multilabel_loss = self.multilabel_loss(logit[nonNA_slice], multilabels[nonNA_slice].float())\n",
        "            else:\n",
        "                multilabel_loss = 0\n",
        "        else:\n",
        "            multilabel_loss = 0\n",
        "\n",
        "        loss = self.covid_alpha * covid_loss + self.gender_alpha * gender_loss + self.multilabel_alpha * multilabel_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def _shared_step(self, xs, y_covids, y_sexs, y_multilabels):\n",
        "        '''\n",
        "        Shared step that happened in both train/val step\n",
        "        '''\n",
        "        feats = self(xs)\n",
        "\n",
        "        # sum of multitask loss for a tensor of size (batch x n_output)\n",
        "        loss = self.loss_fn(feats, y_covids, y_sexs, y_multilabels)\n",
        "        \n",
        "        # take logit from covid predict head (main task)\n",
        "        logits = self.covid_head(feats).squeeze(-1)\n",
        "\n",
        "        return loss, logits\n",
        "\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        x, y_covid, y_sex, y_multilabel = train_batch\n",
        "        if self.augment:\n",
        "            x = self.augment(x)\n",
        "        loss, logits = self._shared_step(x, y_covid, y_sex, y_multilabel)\n",
        "        self.log('train/loss_step', loss, on_step=True)        \n",
        "        return {'loss': loss, 'probs': logits.detach(), \"targets\": y_covid}\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        self.print(f\"Epoch {self.current_epoch}: {self.global_step}\")\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        x, y_covid, y_sex, y_multilabel = val_batch\n",
        "        loss, logits = self._shared_step(x, y_covid, y_sex, y_multilabel)\n",
        "        return {'loss': loss, 'probs': logits, \"targets\": y_covid}\n",
        "\n",
        "    \n",
        "    def test_step(self, test_batch, batch_idx):\n",
        "        x, y_covid, y_sex, y_multilabel = test_batch\n",
        "        loss, logits = self._shared_step(x, y_covid, y_sex, y_multilabel)\n",
        "        return {'loss': loss, 'probs': logits, \"targets\": y_covid}\n",
        "\n",
        "\n",
        "    ################################################\n",
        "    # Optimizer configuration\n",
        "    ################################################\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = self.optim_config['optimizer']\n",
        "        lr = self.optim_config['lr']\n",
        "        lrschedule = self.optim_config['scheduler']\n",
        "\n",
        "        ### SET OPTIMIZER\n",
        "\n",
        "        if optimizer['type'] == 'Adam':\n",
        "            self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "        elif optimizer['type'] == 'SGD':\n",
        "            self.optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
        "        else:\n",
        "            raise ValueError(f\"Optimizer not implemented: {optimizer}\")\n",
        "\n",
        "        # Total number of gradient calculations\n",
        "        if isinstance(self.trainer.accumulate_grad_batches, dict):\n",
        "            step_per_epoch = len(self.train_dataloader())\n",
        "            \n",
        "\n",
        "            last_epoch = 0\n",
        "            last_accum = self.trainer.accumulate_grad_batches[0]\n",
        "\n",
        "            grad_update_step = 0\n",
        "\n",
        "            for e, a in sorted(self.trainer.accumulate_grad_batches.items()):\n",
        "                interval = e - last_epoch\n",
        "                grad_update_step += math.ceil(step_per_epoch/last_accum)*interval\n",
        "\n",
        "                last_epoch = e\n",
        "                last_accum = a\n",
        "\n",
        "            interval = self.trainer.max_epochs - last_epoch\n",
        "            grad_update_step += math.ceil(step_per_epoch/last_accum)*interval\n",
        "        else:\n",
        "            grad_update_step = math.ceil( len(self.train_dataloader()) / self.trainer.accumulate_grad_batches ) * self.trainer.max_epochs\n",
        "\n",
        "        ### SET SCHEDULER\n",
        "        \n",
        "        if lrschedule['type'] == \"OneCycleLR\":\n",
        "            # OneCycleLR\n",
        "            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, max_lr=lr, \n",
        "                                                             total_steps=grad_update_step,)\n",
        "        elif lrschedule['type'] == \"CosineAnnealingLR\":\n",
        "            # CosineAnnealing per 10 epoch\n",
        "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=int(10*grad_update_step/self.trainer.max_epochs))\n",
        "        elif lrschedule['type'] == \"None\":\n",
        "            # Set constant scheduler to prevent\n",
        "            self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=lambda epoch: lr)\n",
        "        else:\n",
        "            raise ValueError(f\"Scheduler not implemented: {lrschedule}\")\n",
        "\n",
        "        ### COMPLETE SETUP\n",
        "\n",
        "        if self.scheduler:\n",
        "            sched = {\n",
        "                'scheduler': self.scheduler,\n",
        "                'interval': 'step'\n",
        "            }\n",
        "            return [self.optimizer], [sched]\n",
        "        else:\n",
        "            return self.optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl4ARbbJ7M-A"
      },
      "source": [
        "# Trainer params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "A6ouAXvOHxbd"
      },
      "source": [
        "#@markdown Make a Neptune logger instance `logger(name)`\n",
        "\n",
        "# from pytorch_lightning.loggers import NeptuneLogger\n",
        "\n",
        "# logger = lambda ver: NeptuneLogger(\n",
        "#     api_key=api_token,\n",
        "#     project_name='vulong61/AICOVID', \n",
        "#     experiment_name=f'{experiment_id}_{ver}',  # Optional\n",
        "# )\n",
        "\n",
        "#-------------New from neptune-----------------\n",
        "\n",
        "from neptune.new.integrations.pytorch_lightning import NeptuneLogger\n",
        "\n",
        "logger = lambda ver: NeptuneLogger(\n",
        "    api_key=api_token,\n",
        "    project='vulong61/AICOVID', \n",
        "    name=f'{experiment_id}_{ver}',  # Optional\n",
        "    tags=[],\n",
        "    close_after_fit=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzBCX9xE7OqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "c4c47b7a-2484-490a-feb7-7331c30a478b"
      },
      "source": [
        "#@title Trainer params\n",
        "mixed_precision = True #@param {type:\"boolean\"}\n",
        "swa = False #@param {type:\"boolean\"}\n",
        "max_epochs = 5 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Dataloader params\n",
        "batch_size =  4#@param {type:\"integer\"}\n",
        "grad_accum =  1#@param {type:\"raw\"}\n",
        "\n",
        "#@markdown Logger name on Neptune.AI\n",
        "logger_exp_name = \"exp007\" #@param {type:\"string\"}\n",
        "check_point_interval = 5 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "default_root_dir = \"./checkpoints\"\n",
        "\n",
        "trainer_params = {\n",
        "    \"gpus\": 1,\n",
        "    \"precision\": 16 if mixed_precision else 32,\n",
        "    \"max_epochs\": max_epochs,\n",
        "    \"progress_bar_refresh_rate\": 10,\n",
        "    \"accumulate_grad_batches\": grad_accum,\n",
        "    \"stochastic_weight_avg\": swa,\n",
        "\n",
        "    \"callbacks\": [LogMetricsNeptune(),\n",
        "                  LearningRateMonitor(\"step\"),\n",
        "                  SaveCheckpointNeptune(check_point_interval)],\n",
        "\n",
        "    # flag for debugging\n",
        "    # \"track_grad_norm\": 2, the model is so deep that half of the running time is just for logging this\n",
        "    \"terminate_on_nan\": True,\n",
        "    \"weights_summary\": 'full',\n",
        "    \"log_every_n_steps\": 1,\n",
        "    \"default_root_dir\": default_root_dir,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3yQrcjYYtCeV"
      },
      "source": [
        "#@title Optimizer params\n",
        "lr = 0.0005 #@param {type:\"number\"}\n",
        "optimizer = \"SGD\" #@param [\"SGD\", \"Adam\"]\n",
        "scheduler = \"OneCycleLR\" #@param [\"OneCycleLR\", \"CosineAnnealingLR\", \"None\"]\n",
        "reduction = \"mean\" #@param [\"sum\", \"mean\", \"none\"]\n",
        "optim_config = {\n",
        "    'optimizer': {\"type\": optimizer,\n",
        "                  \"kawrgs\": None},\n",
        "    'scheduler': {\"type\": scheduler,\n",
        "                  \"kawrgs\": None},\n",
        "    'lr': lr,\n",
        "    'reduction': reduction,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kOPNwZBmUX7"
      },
      "source": [
        "# Experiment - Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQHx9xzlRk6R"
      },
      "source": [
        "## Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqpTaQ4jsNAn"
      },
      "source": [
        "log_melspec_transform = nn.Sequential(mel_spectrogram,\n",
        "                                      log_spectrogram)\n",
        "\n",
        "transform0 = nn.Sequential(log_melspec_transform).cuda()\n",
        "transform1 = nn.Sequential(NoiseInject([noise.cuda()], 8),\n",
        "                           log_melspec_transform).cuda()\n",
        "transform2 = nn.Sequential(NoiseInject([noise.cuda()], 16),\n",
        "                           log_melspec_transform).cuda()\n",
        "transform3 = nn.Sequential(RoomReverb([rir.cuda()]), \n",
        "                           NoiseInject([noise.cuda()], 8), \n",
        "                           PhoneSim(),\n",
        "                           log_melspec_transform).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeEpNXQR7QP6"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8JLBFqDhtfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3883586e-6d15-4698-bb95-591015def088"
      },
      "source": [
        "# train_set = AICOVIDDataset('f_pub_train', torch.nn.ModuleList([transform0]), normalize='ast', chunking=(400, 200), val_split=False, split_ratio=val_split, cleanup_after=False)\n",
        "train_set = AICOVIDDataset('f_pub_train', torch.nn.ModuleList([transform0]), normalize='ast', val_split=False, split_ratio=val_split, cleanup_after=False)\n",
        "scaler = StandardScaler(train_set.mean, train_set.std, 0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Archive have already downloaded\n",
            "\n",
            "> Extract complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3603/3603 [00:32<00:00, 110.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> File processing complete\n",
            "\n",
            "> Start normalizing data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3603/3603 [00:15<00:00, 231.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Normalizing data complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUAcf5sR7LuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a22164-a468-4a75-f232-f422c6222432"
      },
      "source": [
        "val_set = AICOVIDDataset('f_pub_train', torch.nn.ModuleList([transform0]), normalize=scaler, chunking=(400, 200), val_split=True, split_ratio=val_split, cleanup_after=False)\n",
        "test_set = AICOVIDDataset('f_pub_train', torch.nn.ModuleList([transform0]), normalize=scaler, val_split=True, split_ratio=val_split)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Archive have already downloaded\n",
            "\n",
            "> Extract complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 901/901 [00:09<00:00, 96.93it/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> File processing complete\n",
            "\n",
            "> Start normalizing data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 901/901 [00:04<00:00, 218.83it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Normalizing data complete\n",
            "> Archive have already downloaded\n",
            "\n",
            "> Extract complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 901/901 [00:07<00:00, 115.61it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> File processing complete\n",
            "\n",
            "> Start normalizing data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 901/901 [00:02<00:00, 368.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Normalizing data complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4tnePIv5-w7"
      },
      "source": [
        "## Sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kGPWgFA-f-l"
      },
      "source": [
        "from math import ceil\n",
        "\n",
        "class ClassBalancedRandomSampler(Sampler):\n",
        "    def __init__(self, index_list_by_class, sampling_type: str='over'):\n",
        "        # Calculating weight for each class\n",
        "        num_samples = [len(l) for l in index_list_by_class]\n",
        "\n",
        "        # Get number of samples per class\n",
        "        if sampling_type == 'under':\n",
        "            # Limit that number by minor class\n",
        "            desired_samples_per_class = min(num_samples)\n",
        "        elif sampling_type == 'over':\n",
        "            # Limit that number by major class\n",
        "            desired_samples_per_class = max(num_samples)\n",
        "\n",
        "            # Duplicate sample in minor class\n",
        "            # Numer of samples per class alway > desired_samples_per_class\n",
        "            for i, index_list in enumerate(index_list_by_class):\n",
        "                rep_times = ceil(desired_samples_per_class/num_samples[i]) - 1\n",
        "                index_list_by_class[i] += rep_times*index_list\n",
        "                num_samples[i] += rep_times*num_samples[i]\n",
        "        else:\n",
        "            raise KeyError(\"sampling_type can only be 'over' (oversampling) or 'under' (undersampling)\")\n",
        "\n",
        "        class_weights = [desired_samples_per_class/n for n in num_samples]\n",
        "\n",
        "        # Replicating class weight for each sample\n",
        "        self.index_map = []\n",
        "        sample_weights = []\n",
        "\n",
        "        for i, class_list in enumerate(index_list_by_class):\n",
        "            self.index_map += class_list\n",
        "            sample_weights += len(class_list)*[class_weights[i]]\n",
        "\n",
        "        self.sampler = WeightedRandomSampler(\n",
        "            weights=sample_weights,\n",
        "            num_samples=len(index_list_by_class)*desired_samples_per_class,\n",
        "            replacement=False\n",
        "        )\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for i in self.sampler:\n",
        "            yield self.index_map[i]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM-M63AGNByi"
      },
      "source": [
        "exploded_df = train_set.meta_df.iloc[train_set.idxs].reset_index()\n",
        "index_list_by_class = [exploded_df.query(\"assessment_result==0\").index.to_list(),exploded_df.query(\"assessment_result==1\").index.to_list()]\n",
        "\n",
        "weighted_sampler = ClassBalancedRandomSampler(index_list_by_class, 'over')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37j76Vm4q9P2"
      },
      "source": [
        "## Collate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-wzTV7BhoHU"
      },
      "source": [
        "cols_to_drop = ['uuid', 'subject_age', 'audio_noise_note', 'cough_intervals', ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpswQ8ayvZOo"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_pad_seq_fn(batch):\n",
        "    # A data tuple has the form:\n",
        "    # spec, covid_label, sex_label, \n",
        "\n",
        "    specs, covids, sexs, multilabels = [], [], [], []\n",
        "\n",
        "    # Gather in lists, and encode labels as indices\n",
        "    for spec, covid, meta in batch:\n",
        "        specs += [spec.permute(2,0,1)]\n",
        "        covids += [covid]\n",
        "        if covid is not None:\n",
        "            meta = meta.drop(cols_to_drop)\n",
        "            meta[meta > 1] = 1\n",
        "            sexs += [torch.tensor(meta['male'])]\n",
        "            meta = meta.drop(['female', 'male'])\n",
        "            multilabels += [torch.tensor(meta)]\n",
        "\n",
        "    # Group the list of tensors into a batched tensor\n",
        "    specs = pad_sequence(specs, batch_first=True).permute(0,2,3,1)\n",
        "    try:\n",
        "      covids = torch.stack(covids)\n",
        "      sexs = torch.stack(sexs)\n",
        "      multilabels = torch.stack(multilabels)\n",
        "      return specs, covids, sexs, multilabels\n",
        "    except:\n",
        "      return specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmd8ZC6kHQlk"
      },
      "source": [
        "def collate_pad_1024_fn(batch):\n",
        "    # A data tuple has the form:\n",
        "    # spec, covid_label, sex_label, \n",
        "\n",
        "    specs, covids, sexs, multilabels = [], [], [], []\n",
        "\n",
        "    # Gather in lists, and encode labels as indices\n",
        "    for spec, covid, meta in batch:\n",
        "        if spec.shape[-1] > 1024:\n",
        "            spec = spec[..., :1024]\n",
        "        elif spec.shape[-1] < 1024:\n",
        "            pad_size = (0, 1024-spec.shape[-1])\n",
        "            spec = torch.nn.functional.pad(spec, pad_size, mode='constant', value=0)\n",
        "\n",
        "        specs += [spec.permute(2,0,1)]\n",
        "        covids += [covid]\n",
        "        if covid is not None:\n",
        "            meta = meta.drop(cols_to_drop)\n",
        "            meta[meta > 1] = 1\n",
        "            sexs += [torch.tensor(meta['male'])]\n",
        "            meta = meta.drop(['female', 'male'])\n",
        "            multilabels += [torch.tensor(meta)]\n",
        "\n",
        "    # Group the list of tensors into a batched tensor\n",
        "    specs = pad_sequence(specs, batch_first=True).permute(0,2,3,1)\n",
        "    try:\n",
        "      covids = torch.stack(covids)\n",
        "      sexs = torch.stack(sexs)\n",
        "      multilabels = torch.stack(multilabels)\n",
        "      return specs, covids, sexs, multilabels\n",
        "    except:\n",
        "      return specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpCUnnvX2Ajc"
      },
      "source": [
        "def collate_fn(batch):\n",
        "    # A data tuple has the form:\n",
        "    # spec, covid_label, sex_label, \n",
        "\n",
        "    specs, covids, sexs, multilabels = [], [], [], []\n",
        "\n",
        "    # Gather in lists, and encode labels as indices\n",
        "    for spec, covid, meta in batch:\n",
        "        specs += [spec]\n",
        "        covids += [covid]\n",
        "        if covid is not None:\n",
        "            meta = meta.drop(cols_to_drop)\n",
        "            meta[meta > 1] = 1\n",
        "            sexs += [torch.tensor(meta['male'])]\n",
        "            meta = meta.drop(['female', 'male'])\n",
        "            multilabels += [torch.tensor(meta)]\n",
        "\n",
        "\n",
        "    # Group the list of tensors into a batched tensor\n",
        "    specs = torch.stack(specs)\n",
        "    try:\n",
        "      covids = torch.stack(covids)\n",
        "      sexs = torch.stack(sexs)\n",
        "      multilabels = torch.stack(multilabels)\n",
        "      return specs, covids, sexs, multilabels\n",
        "    except:\n",
        "      return specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC9H2rfap_hJ"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOg5s4DbLdXZ"
      },
      "source": [
        "num_workers=2\n",
        "pin_memory=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTy3Zayd3H3D"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=batch_size,\n",
        "    sampler=weighted_sampler,\n",
        "    collate_fn=collate_pad_1024_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_pad_1024_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_pad_1024_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA2gBdmlRvMP"
      },
      "source": [
        "# Experiment - Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de8x3e4UM0ZM"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8spWmDjjmcqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be62bb19-9e14-46a6-a7c4-04d751ac869f"
      },
      "source": [
        "exp_logger = logger(logger_exp_name)\n",
        "# Log hyperparam to logger for convinient\n",
        "exp_logger.experiment['hyperparam'] = trainer_params\n",
        "exp_logger.experiment['hyperparam'] = optim_config\n",
        "\n",
        "model = AICOVIDModule(ast_mdl, optim_config=optim_config, task_weight=(1., 0))#, augment=SpecAugment(time_W=100, freq_W=50, T=80))\n",
        "trainer = pl.Trainer(**trainer_params, logger=exp_logger)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://app.neptune.ai/vulong61/AICOVID/e/AIC-168\n",
            "Remember to stop your run once you’ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Using native 16bit precision.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doxcKBBqMBol"
      },
      "source": [
        "Summary model output shape since this will be logged to Neptune too!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKN6ODkUZyRc",
        "outputId": "b6824257-2f8d-4b19-e7ab-f5b637520071"
      },
      "source": [
        "mdl_summary = summary(ast_mdl, (4,1,128,1024))\n",
        "exp_logger.experiment['monitoring/model_summary'] = mdl_summary\n",
        "mdl_summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ASTModel                                 --                        --\n",
              "├─DistilledVisionTransformer: 1          --                        --\n",
              "│    └─PatchEmbed: 2-1                   [4, 1212, 768]            --\n",
              "│    │    └─Conv2d: 3-1                  [4, 768, 12, 101]         197,376\n",
              "│    └─Dropout: 2-2                      [4, 1214, 768]            --\n",
              "│    └─Sequential: 2-3                   [4, 1214, 768]            --\n",
              "│    │    └─Block: 3-2                   [4, 1214, 768]            7,087,872\n",
              "│    │    └─Block: 3-3                   [4, 1214, 768]            7,087,872\n",
              "│    │    └─Block: 3-4                   [4, 1214, 768]            7,087,872\n",
              "│    │    └─Block: 3-5                   [4, 1214, 768]            7,087,872\n",
              "│    │    └─Block: 3-6                   [4, 1214, 768]            7,087,872\n",
              "│    │    └─Block: 3-7                   [4, 1214, 768]            7,087,872\n",
              "│    │    └─Block: 3-8                   [4, 1214, 768]            7,087,872\n",
              "│    │    └─Block: 3-9                   [4, 1214, 768]            7,087,872\n",
              "│    │    └─Block: 3-10                  [4, 1214, 768]            7,087,872\n",
              "│    │    └─Block: 3-11                  [4, 1214, 768]            7,087,872\n",
              "│    │    └─Block: 3-12                  [4, 1214, 768]            7,087,872\n",
              "│    │    └─Block: 3-13                  [4, 1214, 768]            7,087,872\n",
              "│    └─LayerNorm: 2-4                    [4, 1214, 768]            1,536\n",
              "├─Reduce: 1-1                            [4, 768]                  --\n",
              "├─Identity: 1-2                          [4, 768]                  --\n",
              "==========================================================================================\n",
              "Total params: 85,253,376\n",
              "Trainable params: 85,253,376\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.30\n",
              "==========================================================================================\n",
              "Input size (MB): 2.10\n",
              "Forward/backward pass size (MB): 3997.88\n",
              "Params size (MB): 341.01\n",
              "Estimated Total Size (MB): 4340.99\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUZlB5UMtBf"
      },
      "source": [
        "Print gpu device info too!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5UW9uwTMmRD"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "exp_logger.experiment['monitoring/gpu_info'] = subprocess.check_output(\"nvidia-smi\", shell=True, text=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xcTzY1smd1H"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e41deeeafe184838bb2ec973db7cbbc5",
            "a3b0e98c25ce4dea9f362f4fee26dea6",
            "0db17309bedf4e5598ae0b03b63124c7",
            "c1f94ff477ce4cc3a0fde6c4c437f983",
            "d95ed8bbb98d49dbb741fb3610f8b728",
            "2e38e8f06d5d4331aaa3ccbd62607509",
            "5f878bc609a6427da8de0eeacfe87b3c",
            "40c6457b6fdb4b55bcc5aebf4e5af277",
            "53010b9b5f5245f1a16670e02e3912bf",
            "1fb73726d1a94c8abf028a062ce0b59e",
            "8b8c66bbf7b54d3596ad8c8cf81f2398",
            "a90b8a5f7bf54c55b8c9325b6912f729",
            "2dcc3c0527e747dfa72f637a9ce79ee2",
            "cf4b8dd1db5440328bec8d372fd47b94",
            "f629115e3ec5447ca0b54f9405468346",
            "65473740184c43e99bd19be545b7a289",
            "5f9946e3486b4542a755e13cf9b0cbd4",
            "6715d44595944dbfb782204157f8660f",
            "ff2fd454537a4ec6a3e254f7abb071af",
            "a86e998231e64c5a9f118d420c3779ea",
            "c229aa1f15f34e35a643823aecc3b97b",
            "6b6262d4367047d6ac0da033ac0a1a6d",
            "132677ffe928494ca33d9b79e884deb4",
            "5846efb3da154389a8102d78c92ae70f",
            "9082004366e349e9a2cde95d0d660900",
            "496d17ee22ac48509be7b3add78a9a9d",
            "8838006f7d40462f9b04fff49d749a58",
            "f52406a6383c4ac38bbcf7e2bb39af36",
            "814ef1fb39a9481d9bd2def3b2c9d4cc",
            "342dee2157054769a73c7234f8ba4a3f",
            "41708a6514c4434080817c95dd59ac4e",
            "3abfe0105196434a88e448290873df80",
            "bf70183e25e84eddb1ceecc6bdb04371",
            "9e75d977db5547e18b255ea58f095881",
            "fed530a8bf7d41d08e86ad39d7a79f74",
            "4c78bd036e90432a98af36565cffb61e",
            "7f489d2a582c46f4a2e169fd9067d2ac",
            "b84c62cc88fe43c4ac6c10df9e6ff935",
            "faa0fd793f5b45d5ab96c898eee10089",
            "c610a7a12e634cde91f27a9078fe8dff",
            "207bda3136d74165bf00f0f4354692f9",
            "7c12847484b7424993a407673761b0a5",
            "4ba25f3d53fd4977a6a4affde5247553",
            "fc5d7c8118884f97a50e291f599045e8",
            "3137096a5b914d3094d0fa8c51229c1c",
            "a5ced09cb6e34a10ae661fd129c100b1",
            "fa0e0f69e5664cc1906aecf2cc560789",
            "2a81388b57b44c9498dbfd50a45b9f47",
            "5ff99ee3cd094b489805f86860a3b123",
            "c6a310dc7e264316822593e19bd6460d",
            "741d70206e57469d991aa4cdeef21739",
            "11d0ac63d255413ebbb8c8441a653931",
            "3d5937bff7e041f3ab0666a736c088a0",
            "44e9b3011b15466e8c503f3cbf5891ce",
            "02be64c09e004b3787f54330eeb03c4d",
            "a1783b9cfb284459a7815f17aba7bd51",
            "bebee48f0307449f885b96d8b15c491a",
            "ac923c349ae9483da061d446140f4982",
            "14c77ead3e064186a408fc616265cb56",
            "055fba5107514a91980df672e1537732",
            "4857d62b473b4bc1803c4dee97718d93",
            "83dc4fb29c3142908fcbc677a593cb6e",
            "b94ef357e6ef4601b806d84f8dd1822b",
            "cd45aca19e584b57b9fe4021e9a5ef33",
            "e4b2df485a404d558453ada063ad16a6",
            "3a25db867d394c29a86175c22c04e50a",
            "827745ee04c14cb3b5e39873e203d913",
            "c6e9fdb7492f4a489d2659ad0f939d84",
            "3fc60d8c61ba4c9dbb567e5cc6e8942a",
            "386f449a143f44c6a481b52e47dfdf14",
            "cc276e6206474021b89edd1e8633eb8a",
            "6e1f3d119a4f41ec8cf9129e786990d2",
            "50aad611d9a144bfb140363e28afec32",
            "88fe6b1b88f24b79852633fbf84a4d5b",
            "8b11b378154c4abb9dd60c87e68c946f",
            "fda36c32f8a3405cb55b02325d509545",
            "55fa166a78e440aeb23607b88ba9697a"
          ]
        },
        "id": "UtkN__wPmcqM",
        "outputId": "4b00595f-e4a6-48c9-a8fb-1b3ca5fd3d95"
      },
      "source": [
        "# trainer.fit(model, train_loader, val_loader)\n",
        "trainer.fit(model, train_loader, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "    | Name                             | Type                       | Params\n",
            "----------------------------------------------------------------------------------\n",
            "0   | model                            | ASTModel                   | 87.7 M\n",
            "1   | model.v                          | DistilledVisionTransformer | 87.7 M\n",
            "2   | model.v.patch_embed              | PatchEmbed                 | 197 K \n",
            "3   | model.v.patch_embed.proj         | Conv2d                     | 197 K \n",
            "4   | model.v.pos_drop                 | Dropout                    | 0     \n",
            "5   | model.v.blocks                   | Sequential                 | 85.1 M\n",
            "6   | model.v.blocks.0                 | Block                      | 7.1 M \n",
            "7   | model.v.blocks.0.norm1           | LayerNorm                  | 1.5 K \n",
            "8   | model.v.blocks.0.attn            | Attention                  | 2.4 M \n",
            "9   | model.v.blocks.0.attn.qkv        | Linear                     | 1.8 M \n",
            "10  | model.v.blocks.0.attn.attn_drop  | Dropout                    | 0     \n",
            "11  | model.v.blocks.0.attn.proj       | Linear                     | 590 K \n",
            "12  | model.v.blocks.0.attn.proj_drop  | Dropout                    | 0     \n",
            "13  | model.v.blocks.0.drop_path       | Identity                   | 0     \n",
            "14  | model.v.blocks.0.norm2           | LayerNorm                  | 1.5 K \n",
            "15  | model.v.blocks.0.mlp             | Mlp                        | 4.7 M \n",
            "16  | model.v.blocks.0.mlp.fc1         | Linear                     | 2.4 M \n",
            "17  | model.v.blocks.0.mlp.act         | GELU                       | 0     \n",
            "18  | model.v.blocks.0.mlp.fc2         | Linear                     | 2.4 M \n",
            "19  | model.v.blocks.0.mlp.drop        | Dropout                    | 0     \n",
            "20  | model.v.blocks.1                 | Block                      | 7.1 M \n",
            "21  | model.v.blocks.1.norm1           | LayerNorm                  | 1.5 K \n",
            "22  | model.v.blocks.1.attn            | Attention                  | 2.4 M \n",
            "23  | model.v.blocks.1.attn.qkv        | Linear                     | 1.8 M \n",
            "24  | model.v.blocks.1.attn.attn_drop  | Dropout                    | 0     \n",
            "25  | model.v.blocks.1.attn.proj       | Linear                     | 590 K \n",
            "26  | model.v.blocks.1.attn.proj_drop  | Dropout                    | 0     \n",
            "27  | model.v.blocks.1.drop_path       | Identity                   | 0     \n",
            "28  | model.v.blocks.1.norm2           | LayerNorm                  | 1.5 K \n",
            "29  | model.v.blocks.1.mlp             | Mlp                        | 4.7 M \n",
            "30  | model.v.blocks.1.mlp.fc1         | Linear                     | 2.4 M \n",
            "31  | model.v.blocks.1.mlp.act         | GELU                       | 0     \n",
            "32  | model.v.blocks.1.mlp.fc2         | Linear                     | 2.4 M \n",
            "33  | model.v.blocks.1.mlp.drop        | Dropout                    | 0     \n",
            "34  | model.v.blocks.2                 | Block                      | 7.1 M \n",
            "35  | model.v.blocks.2.norm1           | LayerNorm                  | 1.5 K \n",
            "36  | model.v.blocks.2.attn            | Attention                  | 2.4 M \n",
            "37  | model.v.blocks.2.attn.qkv        | Linear                     | 1.8 M \n",
            "38  | model.v.blocks.2.attn.attn_drop  | Dropout                    | 0     \n",
            "39  | model.v.blocks.2.attn.proj       | Linear                     | 590 K \n",
            "40  | model.v.blocks.2.attn.proj_drop  | Dropout                    | 0     \n",
            "41  | model.v.blocks.2.drop_path       | Identity                   | 0     \n",
            "42  | model.v.blocks.2.norm2           | LayerNorm                  | 1.5 K \n",
            "43  | model.v.blocks.2.mlp             | Mlp                        | 4.7 M \n",
            "44  | model.v.blocks.2.mlp.fc1         | Linear                     | 2.4 M \n",
            "45  | model.v.blocks.2.mlp.act         | GELU                       | 0     \n",
            "46  | model.v.blocks.2.mlp.fc2         | Linear                     | 2.4 M \n",
            "47  | model.v.blocks.2.mlp.drop        | Dropout                    | 0     \n",
            "48  | model.v.blocks.3                 | Block                      | 7.1 M \n",
            "49  | model.v.blocks.3.norm1           | LayerNorm                  | 1.5 K \n",
            "50  | model.v.blocks.3.attn            | Attention                  | 2.4 M \n",
            "51  | model.v.blocks.3.attn.qkv        | Linear                     | 1.8 M \n",
            "52  | model.v.blocks.3.attn.attn_drop  | Dropout                    | 0     \n",
            "53  | model.v.blocks.3.attn.proj       | Linear                     | 590 K \n",
            "54  | model.v.blocks.3.attn.proj_drop  | Dropout                    | 0     \n",
            "55  | model.v.blocks.3.drop_path       | Identity                   | 0     \n",
            "56  | model.v.blocks.3.norm2           | LayerNorm                  | 1.5 K \n",
            "57  | model.v.blocks.3.mlp             | Mlp                        | 4.7 M \n",
            "58  | model.v.blocks.3.mlp.fc1         | Linear                     | 2.4 M \n",
            "59  | model.v.blocks.3.mlp.act         | GELU                       | 0     \n",
            "60  | model.v.blocks.3.mlp.fc2         | Linear                     | 2.4 M \n",
            "61  | model.v.blocks.3.mlp.drop        | Dropout                    | 0     \n",
            "62  | model.v.blocks.4                 | Block                      | 7.1 M \n",
            "63  | model.v.blocks.4.norm1           | LayerNorm                  | 1.5 K \n",
            "64  | model.v.blocks.4.attn            | Attention                  | 2.4 M \n",
            "65  | model.v.blocks.4.attn.qkv        | Linear                     | 1.8 M \n",
            "66  | model.v.blocks.4.attn.attn_drop  | Dropout                    | 0     \n",
            "67  | model.v.blocks.4.attn.proj       | Linear                     | 590 K \n",
            "68  | model.v.blocks.4.attn.proj_drop  | Dropout                    | 0     \n",
            "69  | model.v.blocks.4.drop_path       | Identity                   | 0     \n",
            "70  | model.v.blocks.4.norm2           | LayerNorm                  | 1.5 K \n",
            "71  | model.v.blocks.4.mlp             | Mlp                        | 4.7 M \n",
            "72  | model.v.blocks.4.mlp.fc1         | Linear                     | 2.4 M \n",
            "73  | model.v.blocks.4.mlp.act         | GELU                       | 0     \n",
            "74  | model.v.blocks.4.mlp.fc2         | Linear                     | 2.4 M \n",
            "75  | model.v.blocks.4.mlp.drop        | Dropout                    | 0     \n",
            "76  | model.v.blocks.5                 | Block                      | 7.1 M \n",
            "77  | model.v.blocks.5.norm1           | LayerNorm                  | 1.5 K \n",
            "78  | model.v.blocks.5.attn            | Attention                  | 2.4 M \n",
            "79  | model.v.blocks.5.attn.qkv        | Linear                     | 1.8 M \n",
            "80  | model.v.blocks.5.attn.attn_drop  | Dropout                    | 0     \n",
            "81  | model.v.blocks.5.attn.proj       | Linear                     | 590 K \n",
            "82  | model.v.blocks.5.attn.proj_drop  | Dropout                    | 0     \n",
            "83  | model.v.blocks.5.drop_path       | Identity                   | 0     \n",
            "84  | model.v.blocks.5.norm2           | LayerNorm                  | 1.5 K \n",
            "85  | model.v.blocks.5.mlp             | Mlp                        | 4.7 M \n",
            "86  | model.v.blocks.5.mlp.fc1         | Linear                     | 2.4 M \n",
            "87  | model.v.blocks.5.mlp.act         | GELU                       | 0     \n",
            "88  | model.v.blocks.5.mlp.fc2         | Linear                     | 2.4 M \n",
            "89  | model.v.blocks.5.mlp.drop        | Dropout                    | 0     \n",
            "90  | model.v.blocks.6                 | Block                      | 7.1 M \n",
            "91  | model.v.blocks.6.norm1           | LayerNorm                  | 1.5 K \n",
            "92  | model.v.blocks.6.attn            | Attention                  | 2.4 M \n",
            "93  | model.v.blocks.6.attn.qkv        | Linear                     | 1.8 M \n",
            "94  | model.v.blocks.6.attn.attn_drop  | Dropout                    | 0     \n",
            "95  | model.v.blocks.6.attn.proj       | Linear                     | 590 K \n",
            "96  | model.v.blocks.6.attn.proj_drop  | Dropout                    | 0     \n",
            "97  | model.v.blocks.6.drop_path       | Identity                   | 0     \n",
            "98  | model.v.blocks.6.norm2           | LayerNorm                  | 1.5 K \n",
            "99  | model.v.blocks.6.mlp             | Mlp                        | 4.7 M \n",
            "100 | model.v.blocks.6.mlp.fc1         | Linear                     | 2.4 M \n",
            "101 | model.v.blocks.6.mlp.act         | GELU                       | 0     \n",
            "102 | model.v.blocks.6.mlp.fc2         | Linear                     | 2.4 M \n",
            "103 | model.v.blocks.6.mlp.drop        | Dropout                    | 0     \n",
            "104 | model.v.blocks.7                 | Block                      | 7.1 M \n",
            "105 | model.v.blocks.7.norm1           | LayerNorm                  | 1.5 K \n",
            "106 | model.v.blocks.7.attn            | Attention                  | 2.4 M \n",
            "107 | model.v.blocks.7.attn.qkv        | Linear                     | 1.8 M \n",
            "108 | model.v.blocks.7.attn.attn_drop  | Dropout                    | 0     \n",
            "109 | model.v.blocks.7.attn.proj       | Linear                     | 590 K \n",
            "110 | model.v.blocks.7.attn.proj_drop  | Dropout                    | 0     \n",
            "111 | model.v.blocks.7.drop_path       | Identity                   | 0     \n",
            "112 | model.v.blocks.7.norm2           | LayerNorm                  | 1.5 K \n",
            "113 | model.v.blocks.7.mlp             | Mlp                        | 4.7 M \n",
            "114 | model.v.blocks.7.mlp.fc1         | Linear                     | 2.4 M \n",
            "115 | model.v.blocks.7.mlp.act         | GELU                       | 0     \n",
            "116 | model.v.blocks.7.mlp.fc2         | Linear                     | 2.4 M \n",
            "117 | model.v.blocks.7.mlp.drop        | Dropout                    | 0     \n",
            "118 | model.v.blocks.8                 | Block                      | 7.1 M \n",
            "119 | model.v.blocks.8.norm1           | LayerNorm                  | 1.5 K \n",
            "120 | model.v.blocks.8.attn            | Attention                  | 2.4 M \n",
            "121 | model.v.blocks.8.attn.qkv        | Linear                     | 1.8 M \n",
            "122 | model.v.blocks.8.attn.attn_drop  | Dropout                    | 0     \n",
            "123 | model.v.blocks.8.attn.proj       | Linear                     | 590 K \n",
            "124 | model.v.blocks.8.attn.proj_drop  | Dropout                    | 0     \n",
            "125 | model.v.blocks.8.drop_path       | Identity                   | 0     \n",
            "126 | model.v.blocks.8.norm2           | LayerNorm                  | 1.5 K \n",
            "127 | model.v.blocks.8.mlp             | Mlp                        | 4.7 M \n",
            "128 | model.v.blocks.8.mlp.fc1         | Linear                     | 2.4 M \n",
            "129 | model.v.blocks.8.mlp.act         | GELU                       | 0     \n",
            "130 | model.v.blocks.8.mlp.fc2         | Linear                     | 2.4 M \n",
            "131 | model.v.blocks.8.mlp.drop        | Dropout                    | 0     \n",
            "132 | model.v.blocks.9                 | Block                      | 7.1 M \n",
            "133 | model.v.blocks.9.norm1           | LayerNorm                  | 1.5 K \n",
            "134 | model.v.blocks.9.attn            | Attention                  | 2.4 M \n",
            "135 | model.v.blocks.9.attn.qkv        | Linear                     | 1.8 M \n",
            "136 | model.v.blocks.9.attn.attn_drop  | Dropout                    | 0     \n",
            "137 | model.v.blocks.9.attn.proj       | Linear                     | 590 K \n",
            "138 | model.v.blocks.9.attn.proj_drop  | Dropout                    | 0     \n",
            "139 | model.v.blocks.9.drop_path       | Identity                   | 0     \n",
            "140 | model.v.blocks.9.norm2           | LayerNorm                  | 1.5 K \n",
            "141 | model.v.blocks.9.mlp             | Mlp                        | 4.7 M \n",
            "142 | model.v.blocks.9.mlp.fc1         | Linear                     | 2.4 M \n",
            "143 | model.v.blocks.9.mlp.act         | GELU                       | 0     \n",
            "144 | model.v.blocks.9.mlp.fc2         | Linear                     | 2.4 M \n",
            "145 | model.v.blocks.9.mlp.drop        | Dropout                    | 0     \n",
            "146 | model.v.blocks.10                | Block                      | 7.1 M \n",
            "147 | model.v.blocks.10.norm1          | LayerNorm                  | 1.5 K \n",
            "148 | model.v.blocks.10.attn           | Attention                  | 2.4 M \n",
            "149 | model.v.blocks.10.attn.qkv       | Linear                     | 1.8 M \n",
            "150 | model.v.blocks.10.attn.attn_drop | Dropout                    | 0     \n",
            "151 | model.v.blocks.10.attn.proj      | Linear                     | 590 K \n",
            "152 | model.v.blocks.10.attn.proj_drop | Dropout                    | 0     \n",
            "153 | model.v.blocks.10.drop_path      | Identity                   | 0     \n",
            "154 | model.v.blocks.10.norm2          | LayerNorm                  | 1.5 K \n",
            "155 | model.v.blocks.10.mlp            | Mlp                        | 4.7 M \n",
            "156 | model.v.blocks.10.mlp.fc1        | Linear                     | 2.4 M \n",
            "157 | model.v.blocks.10.mlp.act        | GELU                       | 0     \n",
            "158 | model.v.blocks.10.mlp.fc2        | Linear                     | 2.4 M \n",
            "159 | model.v.blocks.10.mlp.drop       | Dropout                    | 0     \n",
            "160 | model.v.blocks.11                | Block                      | 7.1 M \n",
            "161 | model.v.blocks.11.norm1          | LayerNorm                  | 1.5 K \n",
            "162 | model.v.blocks.11.attn           | Attention                  | 2.4 M \n",
            "163 | model.v.blocks.11.attn.qkv       | Linear                     | 1.8 M \n",
            "164 | model.v.blocks.11.attn.attn_drop | Dropout                    | 0     \n",
            "165 | model.v.blocks.11.attn.proj      | Linear                     | 590 K \n",
            "166 | model.v.blocks.11.attn.proj_drop | Dropout                    | 0     \n",
            "167 | model.v.blocks.11.drop_path      | Identity                   | 0     \n",
            "168 | model.v.blocks.11.norm2          | LayerNorm                  | 1.5 K \n",
            "169 | model.v.blocks.11.mlp            | Mlp                        | 4.7 M \n",
            "170 | model.v.blocks.11.mlp.fc1        | Linear                     | 2.4 M \n",
            "171 | model.v.blocks.11.mlp.act        | GELU                       | 0     \n",
            "172 | model.v.blocks.11.mlp.fc2        | Linear                     | 2.4 M \n",
            "173 | model.v.blocks.11.mlp.drop       | Dropout                    | 0     \n",
            "174 | model.v.norm                     | LayerNorm                  | 1.5 K \n",
            "175 | model.v.pre_logits               | Identity                   | 0     \n",
            "176 | model.v.head                     | Linear                     | 769 K \n",
            "177 | model.v.head_dist                | Linear                     | 769 K \n",
            "178 | model.pooling_layer              | Reduce                     | 0     \n",
            "179 | model.pre_logits                 | Identity                   | 0     \n",
            "180 | covid_head                       | Linear                     | 769   \n",
            "181 | gender_head                      | Linear                     | 1.5 K \n",
            "182 | multilabel                       | Linear                     | 18.5 K\n",
            "183 | covid_loss                       | BCEWithLogitsLoss          | 0     \n",
            "184 | gender_loss                      | CrossEntropyLoss           | 0     \n",
            "185 | multilabel_loss                  | BCEWithLogitsLoss          | 0     \n",
            "----------------------------------------------------------------------------------\n",
            "87.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "87.7 M    Total params\n",
            "350.984   Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e41deeeafe184838bb2ec973db7cbbc5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a90b8a5f7bf54c55b8c9325b6912f729",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "132677ffe928494ca33d9b79e884deb4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: 1017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e75d977db5547e18b255ea58f095881",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2: 1526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3137096a5b914d3094d0fa8c51229c1c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3: 2035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1783b9cfb284459a7815f17aba7bd51",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4: 2544\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "827745ee04c14cb3b5e39873e203d913",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Validating: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "4 epoch backuped: checkpoints/NeptuneLogger/AIC-167/checkpoints/epoch=4-step=2544.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8CPhdRxwVZA"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKqwC_YUISVL",
        "outputId": "76d9cbea-462d-40b5-e664-678324fa6628"
      },
      "source": [
        "!gdown --id 1WqIhJUf0K96XTP5GFYGnQri4Oo1tuweD"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WqIhJUf0K96XTP5GFYGnQri4Oo1tuweD\n",
            "To: /content/latest.ckpt\n",
            "696MB [00:03, 228MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9Lbc6aiNZEh"
      },
      "source": [
        "model = AICOVIDModule(ast_mdl, optim_config=optim_config, task_weight=(0.7, 0.3))#, augment=SpecAugment(time_W=100, freq_W=50, T=80))\n",
        "model = model.load_from_checkpoint(\"latest.ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMgzKaTjPCLn",
        "outputId": "ecb0c209-7885-49b9-844e-e798b43a372f"
      },
      "source": [
        "trainer = pl.Trainer(gpus=1, precision=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Using native 16bit precision.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQMU5EfwvpE9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647,
          "referenced_widgets": [
            "c9d24eac1eb54255936581839da2116c",
            "0eab31b0acd548239fd9114909b9f341",
            "f6810927e7034862a5218e8a96894b0c",
            "1d6aa6d40a104e10ad3351aed28c21c9",
            "7ef0beeee1f2445d93b9494a8b20bb2c",
            "feb6ec6ea2ee4880848c8f2a3aef93db",
            "c53150e315b744709245335a28523327",
            "45c32ab6ac114147abc8147bff6e9c2f",
            "422e9c86cad7486095b9adc8412c2c4c",
            "6e79b5f223324e2f8e6c458346d9cafb",
            "f180749a46ba4ce7971535882323a513"
          ]
        },
        "outputId": "c5dc0814-52d9-44cb-a943-845b0bdee4d3"
      },
      "source": [
        "trainer.test(model, test_dataloaders=test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9d24eac1eb54255936581839da2116c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.31098073720932007\n",
            "Accuracy: 0.9567147493362427\n",
            "Precision: 0.868852436542511\n",
            "Recall: 0.8217054009437561\n",
            "AUROC: 0.9758304357528687\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHfFgV0uJL84"
      },
      "source": [
        "## Stop online logger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhu6ypKHJPAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752dc1e2-acba-46d8-d838-b3f91314b82b"
      },
      "source": [
        "exp_logger.experiment.stop()\n",
        "\n",
        "# Mình không cài logger trong lightning module nhưng pl họ tự gọi log khi trainer có logger\n",
        "# do đó cần xóa logger đi để tránh lỗi khi đã ngưng logger\n",
        "trainer.logger=None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Waiting for the remaining 1 operations to synchronize with Neptune. Do not kill this process.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All 1 operations synced, thanks for waiting!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NdDA6uC13XV"
      },
      "source": [
        "# Evaluating model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQtRaoeOwVDP"
      },
      "source": [
        "## Visualize misclassified samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsU1QJa8zSl_"
      },
      "source": [
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdXrW8PC1qUN"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g50Y8yRZw6JT"
      },
      "source": [
        "## Public test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbEpXGUpFhF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cd17b1-9243-4e4b-b022-14495d2bd37f"
      },
      "source": [
        "final_public_set = AICOVIDDataset('f_pub_test', torch.nn.ModuleList([transform0]), normalize=scaler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Archive download complete\n",
            "\n",
            "> Extract complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1233/1233 [00:10<00:00, 119.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> File processing complete\n",
            "\n",
            "> Start normalizing data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1233/1233 [00:04<00:00, 279.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Normalizing data complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNR8gns5FhF3"
      },
      "source": [
        "final_public_loader = torch.utils.data.DataLoader(\n",
        "    final_public_set,\n",
        "    collate_fn=collate_pad_1024_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8vo4LuEFlWI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "792954b1312a4cd29172456711454406",
            "723166e73bbd4cf6bdad6dfdf36f5a89",
            "8bee8d0e6a454c8e99b44b5ab86f057f",
            "42568b86016f44219ad2595f2ed9d373",
            "96f737bbf6cb4bfb926856c83df54490",
            "48bf5fc3c8e84debb985569c3e04578a",
            "cdf7d041c6204973bfc2c35783300756",
            "04d1e7e4403c4c8abf8f9b61cc45e781",
            "14e84a178f5844a6888e4570894f7805",
            "13752e22304f49609d33ab7e7a85ae46",
            "e7e34a185e7947c09b1af66b89d42ea8"
          ]
        },
        "outputId": "2105f240-5504-4752-a296-b307b448f35b"
      },
      "source": [
        "preds = trainer.predict(dataloaders=final_public_loader)\n",
        "preds = torch.cat(preds)\n",
        "preds = preds.cpu().numpy()\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "792954b1312a4cd29172456711454406",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.707e-02, 3.250e-04, 1.550e-06, ..., 7.651e-01, 8.675e-03,\n",
              "       4.768e-07], dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjnNXL5xItCh"
      },
      "source": [
        "## Private test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV9J9C3lIsyv",
        "outputId": "1ac0e79e-e51d-441d-c76f-d93a36c33923"
      },
      "source": [
        "final_private_set = AICOVIDDataset('f_pri_test', torch.nn.ModuleList([transform0]), normalize=scaler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Archive download complete\n",
            "\n",
            "> Extract complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1627/1627 [00:10<00:00, 152.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> File processing complete\n",
            "\n",
            "> Start normalizing data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1627/1627 [00:07<00:00, 212.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Normalizing data complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEcuQmPbSzeV"
      },
      "source": [
        "final_private_loader = torch.utils.data.DataLoader(\n",
        "    final_private_set,\n",
        "    collate_fn=collate_pad_1024_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "d9cb414045074fd38fe7c7333af0bc50",
            "5169e58afbe44779b04d95ddb0f37416",
            "680630f6acc6434d8e405faaf91207e9",
            "9ff49d936bf14af78ec51e79337e90ea",
            "4a13acecf50d4fa0a1d0618457dac651",
            "64464c43ebe7493b9a0249e2b7e523b7",
            "84cd5c45e05f47e590a36e0ef38a990f",
            "b9d3ef45d653408e86fa9d7a3bb7ba07",
            "1b880147565f49e0b48252e1965882fd",
            "e950ff58b5274be78253b836157bb69b",
            "b73517d9f8ca44328da72c7fd17bac31"
          ]
        },
        "id": "eFkoHj34S2wW",
        "outputId": "1b104486-a8ec-4b50-b3cf-8051b0dbf0b6"
      },
      "source": [
        "private_preds = trainer.predict(dataloaders=final_private_loader)\n",
        "private_preds = torch.cat(private_preds)\n",
        "private_preds = private_preds.cpu().numpy()\n",
        "private_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9cb414045074fd38fe7c7333af0bc50",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.636e-03, 6.557e-07, 4.888e-06, ..., 5.688e-03, 2.199e-03,\n",
              "       3.102e-04], dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mlQ9N2J1x21"
      },
      "source": [
        "# Lưu kết quả"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2K9aUYb9WzP"
      },
      "source": [
        "# Tải file ngay tại notebook\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQMWT6nXWebS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f2433849-d95e-4c7f-d7be-26046daaa3c6"
      },
      "source": [
        "#@markdown Lưu lại public test submission lên Google Drive\n",
        "submit_df = pd.DataFrame({'uuid': final_public_set.meta_df['uuid'],\n",
        "                          'assessment_result': preds})\n",
        "submit_df.to_csv('results.csv', index=False)\n",
        "\n",
        "# Nén file\n",
        "os.system(f'zip -j ./{zip_name}.zip ./results.csv')\n",
        "\n",
        "drive.Upload(zip_name+'.zip', submission_folder)\n",
        "\n",
        "files.download(zip_name+'.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_3dfd0156-d1a6-4777-b41d-0aafc9641d28\", \"Torch_ver009.zip\", 30878)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv4lQXEsrep-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f588b266-3d50-41be-d4f5-833dc1f439bf"
      },
      "source": [
        "#@markdown Lưu lại private test submission lên Google Drive\n",
        "submit_df = pd.DataFrame({'uuid': final_private_set.meta_df['uuid'],\n",
        "                          'assessment_result': private_preds})\n",
        "submit_df.to_csv('results.csv', index=False)\n",
        "\n",
        "# Nén file\n",
        "os.system(f'zip -j ./{zip_name}_private_test.zip ./results.csv')\n",
        "\n",
        "drive.Upload(zip_name+'_private_test.zip', submission_folder)\n",
        "\n",
        "files.download(zip_name+'_private_test.zip')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_343d5319-b756-414a-ab7f-edc7d85c891c\", \"Torch_ver009_private_test.zip\", 40662)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Rb7KoY9Mi4Oj"
      },
      "source": [
        "#@markdown Lưu lại model lên Google Drive\n",
        "if train_mode:\n",
        "  os.system('mkdir trained_models')\n",
        "  compressed_name = f'{zip_name}_model.zip'\n",
        "  torch.save(model.state_dict(), './trained_models/model_weights.pth')\n",
        "  \n",
        "  os.system(f'zip -j ./{compressed_name} ./trained_models/*')\n",
        "  drive.Upload(compressed_name, model_zoo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHzHpd7InP8M",
        "cellView": "form"
      },
      "source": [
        "#@markdown Load model lưu sẵn\n",
        "if not train_mode:\n",
        "  drive.Download(f'{zip_name}_model.zip', model_zoo)\n",
        "  os.system(f'unzip -o {zip_name}_model.zip')\n",
        "  model.load_state_dict(torch.load('model_weights.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}