{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[Torch009_base_local] AICOVID_115M.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KkxxsDa8r0ql",
        "g2Lc0HIA2ZjG"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlozg/aicovid/blob/main/%5BTorch009_base_local%5D_AICOVID_115M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-YXyY9kYZcG",
        "outputId": "5ac37b7e-af33-4046-a05f-75d0c3cc7dfc"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Aug 20 21:45:10 2021       \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 470.63.01    CUDA Version: 11.4     |\r\n",
            "|-------------------------------+----------------------+----------------------+\r\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
            "|                               |                      |               MIG M. |\r\n",
            "|===============================+======================+======================|\r\n",
            "|   0  NVIDIA GeForce ...  On   | 00000000:2D:00.0  On |                  N/A |\r\n",
            "|  0%   43C    P8    18W / 170W |    448MiB / 12045MiB |      0%      Default |\r\n",
            "|                               |                      |                  N/A |\r\n",
            "+-------------------------------+----------------------+----------------------+\r\n",
            "                                                                               \r\n",
            "+-----------------------------------------------------------------------------+\r\n",
            "| Processes:                                                                  |\r\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
            "|        ID   ID                                                   Usage      |\r\n",
            "|=============================================================================|\r\n",
            "|    0   N/A  N/A      1072      G   /usr/lib/xorg/Xorg                 35MiB |\r\n",
            "|    0   N/A  N/A      1773      G   /usr/lib/xorg/Xorg                 42MiB |\r\n",
            "|    0   N/A  N/A      4323      G   /opt/zoom/zoom                     44MiB |\r\n",
            "|    0   N/A  N/A     14457      G   ...mviewer/tv_bin/TeamViewer       11MiB |\r\n",
            "|    0   N/A  N/A     15550      G   /usr/lib/xorg/Xorg                 79MiB |\r\n",
            "|    0   N/A  N/A     15683      G   /usr/bin/gnome-shell               79MiB |\r\n",
            "|    0   N/A  N/A     15734      G   ...mviewer/tv_bin/TeamViewer        6MiB |\r\n",
            "|    0   N/A  N/A     17639      G   ...AAAAAAAAA= --shared-files       59MiB |\r\n",
            "+-----------------------------------------------------------------------------+\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYEmHeR7z_l1"
      },
      "source": [
        "Th√≠ nghi·ªám tr∆∞·ªõc m√¨nh ƒë√£ th·ª±c hi·ªán tinh ch·ªânh engineering kh√° nhi·ªÅu, ƒë·∫∑c bi·ªát l√† vi·ªác t·∫°o ra class dataset ho√†n ch·ªânh c≈©ng nh∆∞ t·∫°o ra sampler ph·ª•c v·ª• vi·ªác oversampling/undersampling. B√™n c·∫°nh ƒë√≥ m√¨nh c√≤n gi·∫£i quy·∫øt ƒë∆∞·ª£c v·∫•n ƒë·ªÅ chunking g√¢y b√πng n·ªï data v√† c·∫£i thi·ªán l·∫°i lightning module ƒë·ªÉ c√≥ th·ªÉ th·ª±c hi·ªán multi-task learning.\n",
        "\n",
        "C√°c v·∫•n ƒë·ªÅ t·ªìn ƒë·ªçng cho t·ªõi hi·ªán t·∫°i:\n",
        "- Tinh ch·ªânh l·∫°i code ƒë·ªÉ ho·∫°t ƒë·ªông ƒë∆∞·ª£c v·ªõi lightning 1.4.0\n",
        "\n",
        "Trong notebook n√†y, tr·ªçng t√¢m m√¨nh s·∫Ω th·ª≠ xoay quanh AST. S·ªü dƒ© m√¨nh chuy·ªÉn qua m·ªôt phi√™n b·∫£n th√≠ nghi·ªám m·ªõi v√¨ m√¨nh nh·∫≠n th·∫•y r·∫±ng transformer c√≥ c√°ch s·ª≠ d·ª•ng v·ªõi sequence kh√°c v·ªõi CNN n√™n t·∫°o phi√™n b·∫£n m·ªõi ƒë·ªÉ c√≥ th·ªÉ d·ªÖ d√†ng qu·∫£n l√Ω, c≈©ng nh∆∞ trong n√†y m√¨nh hy v·ªçng c√≥ th·ªÉ h·ªçc h·ªèi v√† hi·ªÉu r√µ h∆°n v·ªÅ vision transformer.\n",
        "\n",
        "exp000: Th·ª≠ pretrain AST tr√™n audioset. --> Ch·ªâ ch·∫°y ƒë∆∞·ª£c batch size l√† 3. R·∫•t ch·∫≠m, memory ti√™u t·ªën r·∫•t l·ªõn.\n",
        "\n",
        "exp001: Tinh ch·ªânh l·∫°i, remove b·ªõt c√°c th√†nh ph·∫ßn ƒë√£ ƒë∆∞·ª£c handle b·ªüi lightning, lo·∫°i b·ªè MLP head v√¨ c√°i n√†y task dependent.\n",
        "\n",
        "exp001-exp003_db: train model th·∫•t b·∫°i, kh√¥ng c√≥ d·∫•u hi·ªáu c·∫£i thi·ªán c·ªßa model khi lo·∫°i b·ªè ƒëi 1 l·ªõp linear gi·ªØa cls token v√† linear t·ª´ng task. ƒê·ªÅ xu·∫•t 2 h∆∞·ªõng: (1) th√™m 1 l·ªõp gi·ªØa nh∆∞ng nh·∫π h∆°n (exp000 d√πng 527); (2) train single task. B√™n c·∫°nh ƒë√≥ m√¨nh ƒë·ªçc paper th√¨ c≈©ng b·ªã kh√≥ hi·ªÉu khi t√°c gi·∫£ l·∫°i mix cls v·ªõi dist cls token trong qu√° tr√¨nh train, trong khi suppose l√† dist cls token ch·ªâ d√πng khi c√≥ teacher?\n",
        "\n",
        "***PH√ÅT HI·ªÜN NGUY√äN NH√ÇN TRAIN KH√îNG ƒê∆Ø·ª¢C: MODEL KH√îNG LOAD ƒê∆Ø·ª¢C PRETRAINED WEIGHT***\n",
        "\n",
        "exp003: fix bug th√†nh c√¥ng. --> 0.752\n",
        "\n",
        "exp004: \n",
        "- Th·ª≠ accumulate gradient batch 16 ƒë·ªÉ ƒë∆∞·ª£c batchsize 64. S·ªë l∆∞·ª£ng epoch d√πng ƒë·ªÉ train c·∫ßn cƒÉn c·ª© theo t√¨nh h√¨nh fit c·ªßa exp003 (ti√™u chu·∫©n l√† g·∫•p 16 l·∫ßn, nh∆∞ng theo b√™n how to train resnet th√¨ batchsize l·ªõn c·∫ßn √≠t epoch h·ªôi t·ª• h∆°n)? ‚úÖ\n",
        "- Ch·ªânh t·ªâ l·ªá loss cho c√°c task ph·ª• v√¨ theo quan s√°t gradient th√¨ th·∫•y ch·ªß y·∫øu kh√≥ khƒÉn v√¨ ph·∫£i t·ªëi ∆∞u gradient cho task ph·ª• l√† ch√≠nh, th·∫≠m ch√≠ c√≤n d·∫´n t·ªõi performance tr√™n task ch√≠nh gi·∫£m s√∫t. ‚úÖ\n",
        "- Ch·ªânh l·∫°i model ƒë·ªÉ cho ph√©p inference tr√™n length b·∫•t k·ª≥. \n",
        "- Th·ª≠ ch·ªâ classify v·ªõi cls token üîÅ\n",
        "\n",
        "exp005:\n",
        "\n",
        "exp006:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsOJoIodiHt1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "e5fb319b-1e8e-47c1-fb89-380a2448e5da"
      },
      "source": [
        "#@title L·∫•y x√°c th·ª±c google ƒë·ªÉ upload/download file\n",
        "#@markdown Vui l√≤ng b·∫•m v√†o link khi ƒë∆∞·ª£c y√™u c·∫ßu v√† l·∫•y m√£ ƒë·ªÉ nh·∫≠p v√†o\n",
        "\n",
        "# X√°c th·ª±c google ƒë·ªÉ upload/download qua google drive\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "class GDrive():\n",
        "    def __init__(self, auth_type: str='colab'):\n",
        "        self._gauth = GoogleAuth()\n",
        "        self.auth_type = auth_type\n",
        "        self._get_creds()\n",
        "        self._drive = GoogleDrive(self._gauth)\n",
        "\n",
        "    def _get_creds(self):\n",
        "        if self.auth_type == 'colab':\n",
        "            raise NotImplementedError()\n",
        "        elif self.auth_type == 'local':\n",
        "            self._gauth.LocalWebserverAuth()\n",
        "        else:\n",
        "            raise NotImplementedError()\n",
        "\n",
        "    def Refresh_Auth(self):\n",
        "        self._get_creds()\n",
        "\n",
        "    def SearchInFolder(self, parent_id, file_name):\n",
        "        self.Refresh_Auth()\n",
        "        return self._drive.ListFile({'q': f\"'{parent_id}' in parents and title = '{file_name}'\"}).GetList()\n",
        "\n",
        "    def CreateFile(self, file_name=None, parent_id=None):\n",
        "        self.Refresh_Auth()\n",
        "        file = self._drive.CreateFile({'title': file_name, \n",
        "                                       'parents': [{'id': parent_id}]})\n",
        "        return file\n",
        "\n",
        "    def Upload(self, file_path, parent_id, file_name=None):\n",
        "        if file_name == None:\n",
        "          file_name = file_path.split('/')[-1]\n",
        "        # Ki·ªÉm tra file t·ªìn t·∫°i\n",
        "        file_list = self.SearchInFolder(parent_id, file_name)\n",
        "        if len(file_list) > 1:\n",
        "          for file in file_list:\n",
        "            print('title: %s, id: %s' % (file['title'], file['id']))\n",
        "          raise NameError('More than 1 file with same name exist, please resolve this')\n",
        "        \n",
        "        elif len(file_list) == 0:\n",
        "          # File ch∆∞a c√≥ th√¨ t·∫°o m·ªõi\n",
        "          file = self.CreateFile(file_name, parent_id)\n",
        "        else:\n",
        "          # T·ªìn t·∫°i duy nh·∫•t 1 file\n",
        "          file = file_list[0]\n",
        "        \n",
        "        file.SetContentFile(file_path)\n",
        "        file.Upload()\n",
        "\n",
        "    def Download(self, file_name, parent_id):\n",
        "        # Ki·ªÉm tra file t·ªìn t·∫°i\n",
        "        file_list = self.SearchInFolder(parent_id, file_name)\n",
        "        if len(file_list) > 1:\n",
        "            for file in file_list:\n",
        "                print('title: %s, id: %s' % (file['title'], file['id']))\n",
        "            raise NameError('More than 1 file with same name exist, please resolve this')\n",
        "        elif len(file_list) == 0:\n",
        "            raise NameError(f'File named {file_name} not exist')\n",
        "        else:\n",
        "            # T·ªìn t·∫°i duy nh·∫•t 1 file\n",
        "            file = file_list[0]\n",
        "        \n",
        "        file.GetContentFile(file_name)\n",
        "\n",
        "drive = GDrive('local')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your browser has been opened to visit:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=324036170913-094orce5eji9sr78pstqsi3e6opo5jnp.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=online&response_type=code\n",
            "\n",
            "Opening in existing browser session.\n",
            "Authentication successful.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "U8N-dhNNq152"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.path.exists(\"tmp.tmp\"):\n",
        "    #@title Nh·∫≠p Neptune API token\n",
        "    api_token = getpass('Enter your private Neptune API token: ')\n",
        "    with open('tmp.tmp', 'w') as tmp:\n",
        "        tmp.write(api_token)\n",
        "else:\n",
        "    with open('tmp.tmp', 'r') as tmp:\n",
        "        api_token = tmp.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_pyzy0LjMrg"
      },
      "source": [
        "# Detect COVID-19 patients via forced-cough cell phone recording\n",
        "\n",
        "- **B√†i to√°n**: Nh·∫≠n di·ªán ng∆∞·ªùi nhi·ªÖm COVID-19 qua ti·∫øng ho √©p bu·ªôc\n",
        "    - **Input**: ƒêo·∫°n ghi √¢m ti·∫øng ho, tu·ªïi v√† gi·ªõi t√≠nh\n",
        "    - **Output**: Ph√¢n lo·∫°i ng∆∞·ªùi nhi·ªÖm b·ªánh hay kh√¥ng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_YA074tx3l"
      },
      "source": [
        "## T√¨m hi·ªÉu b√†i to√°n \n",
        "Qua paper (https://dspace.mit.edu/bitstream/handle/1721.1/128954/09208795.pdf?sequence=1&isAllowed=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02xm0kpbQBgJ"
      },
      "source": [
        "## ƒê·ªçc papers\n",
        "[1] Kranthi Kumar Lella and Alphonse Pja (2021), *Automatic diagnosis of COVID-19 disease using deep convolutional neural network with multi-feature channel from respiratory sound data: Cough, voice, and breath*, access via: https://www.sciencedirect.com/science/article/pii/S1110016821003859\n",
        "\n",
        "- Ngu·ªìn tham kh·∫£o t·ªët cho c√°c paper c√≥ li√™n quan l√†m c√πng ch·ªß ƒë·ªÅ.\n",
        "- Ch·ªâ ra c√°c paper tr∆∞·ªõc ƒë√≥ kh√¥ng th√†nh c√¥ng l·∫Øm.\n",
        "> From all these background work senses, there is **no accurate model** for diagnosing COVID-19 disease symptom\n",
        "- Ch·ªâ ra r·∫±ng h·∫ßu h·∫øt c√°c dataset b·ªã redundancy (1 speaker t·∫°o nhi·ªÅu m·∫´u).\n",
        "- D√πng 4 lo·∫°i augment: time stretch, shift pitch, dynamic range (n√¥m na l√† c√¢n b·∫±ng volume), background noise inject.\n",
        "- D√πng 3 channel: DAE (remove background noise), GFCC (short respiratory feature) v√† IMFCC (rich respiratory feature) -> Model c√≥ th·ª±c s·ª± d√πng h·∫øt c·∫£ 3 channel?\n",
        "- Ph·∫ßn n√≥i v·ªÅ implement h∆°i messed up (text m√¥ t·∫£ ki·∫øn tr√∫c 1 ƒë∆∞·ªùng h√¨nh minh h·ªça m·ªôt n·∫ªo?)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pbmNRtmnFNl"
      },
      "source": [
        "# C√°c bi·∫øn thi·∫øt l·∫≠p cho th·ª≠ nghi·ªám"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "T9Pxvi0cclld"
      },
      "source": [
        "# N·∫øu mu·ªën train m√¥ h√¨nh th√¨ set th√†nh True\n",
        "experiment_id = '009' #@param {type:\"string\"}\n",
        "val_split = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.05}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPKjksovwzjL"
      },
      "source": [
        "# ID c·ªßa folder l∆∞u model tr√™n drive\n",
        "model_zoo = 'secret'\n",
        "# ID c·ªßa folder ch·ª©a submission\n",
        "submission_folder = 'secret'\n",
        "# T√™n c·ªßa file n√©n ƒë·ªÉ n·ªôp\n",
        "zip_name = f'Torch_ver{experiment_id}'\n",
        "# ID c·ªßa folder ch·ª©a data ƒë√£ preprocess\n",
        "datadump_folder = 'secret'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6trLD9GlZeY"
      },
      "source": [
        "# Setup\n",
        "Import th∆∞ vi·ªán, t·∫£i data, ƒë·ªçc data, t·∫°o helper function,..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ewK6TTR-tdL"
      },
      "source": [
        "## Import th∆∞ vi·ªán"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zceUdpcYV4aK",
        "outputId": "eef5724f-5703-491f-961e-469c995d348f"
      },
      "source": [
        "# Qu·∫£n l√Ω file, folder\n",
        "import os\n",
        "\n",
        "# Hi·ªán audio nghe th·ª≠\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio, display\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler, Sampler\n",
        "\n",
        "# X·ª≠ l√Ω audio\n",
        "import torchaudio\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "pl.utilities.seed.seed_everything(seed=1)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GxCO0fvq1yr"
      },
      "source": [
        "## Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "YjCQwg-opB0L"
      },
      "source": [
        "#@markdown ## C√°c h√†m v·ªè b·ªçc cho ƒë·ªçc file\n",
        "#@markdown `read_audio(path)`: v·ªè b·ªçc cho `torchaudio.load(path)`.<br>\n",
        "#@markdown `read_resample_audio(path)`: ch·ªâ tr·∫£ v·ªÅ wave v√¨ sample rate ƒë√£ ƒë∆∞·ª£c c·ªë ƒë·ªãnh.\n",
        "\n",
        "'''\n",
        "  Read audio from given path and return (wave, sample_rate)\n",
        "'''\n",
        "def read_audio(full_audio_path):\n",
        "  return torchaudio.load(full_audio_path)\n",
        "\n",
        "'''\n",
        "  Read audio from given path, then resample if sample rate is not matched \n",
        "  and return wave.\n",
        "\n",
        "  Tips: \n",
        "    you should provide resampler from torchaudio.transform\n",
        "    when batch resampling with same params since this can\n",
        "    give a huge speed up.\n",
        "'''\n",
        "def read_resample_audio(\n",
        "    full_audio_path, resample,\n",
        "    resampler=None\n",
        "):\n",
        "  wave, sr = torchaudio.load(full_audio_path)\n",
        "  if resampler is not None:\n",
        "      wave = resampler(wave)\n",
        "  elif sr != resample:\n",
        "      wave = torchaudio.functional.resample(wave, sr, resample)\n",
        "  return wave"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx7B78dVp8r_"
      },
      "source": [
        "class AudioChunking(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 chunk_size: int=400,\n",
        "                 chunk_step: int=200,\n",
        "                 idx_instead: bool=False) -> None:\n",
        "        super(AudioChunking, self).__init__()\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_step = chunk_step\n",
        "        self.idx_instead = idx_instead\n",
        "        \n",
        "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
        "        spec_len = spec.shape[-1]\n",
        "        pad_size = self.chunk_size - spec_len%self.chunk_size\n",
        "        pad_size = (pad_size//2, pad_size//2+pad_size%2)\n",
        "        padded_spec = torch.nn.functional.pad(spec, pad_size, mode='constant', value=0)\n",
        "        \n",
        "        if self.idx_instead:\n",
        "            spec_len = padded_spec.shape[-1]\n",
        "            chunk_idxs = [(i, i+self.chunk_size-1) for i in range(0,spec_len-self.chunk_size+1,self.chunk_step)]\n",
        "            return padded_spec, chunk_idxs\n",
        "        else:\n",
        "            chunks = padded_spec.unfold(-1, self.chunk_size, self.chunk_step).permute(2,0,1,3)\n",
        "            return chunks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWl97B56jd2B"
      },
      "source": [
        "## check_integrity.py\n",
        "from typing import Optional, Any\n",
        "import hashlib\n",
        "import os\n",
        "\n",
        "def calculate_md5(fpath: str, chunk_size: int = 1024 * 1024) -> str:\n",
        "    md5 = hashlib.md5()\n",
        "    with open(fpath, 'rb') as f:\n",
        "        for chunk in iter(lambda: f.read(chunk_size), b''):\n",
        "            md5.update(chunk)\n",
        "    return md5.hexdigest()\n",
        "\n",
        "\n",
        "def check_md5(fpath: str, md5: str, **kwargs: Any) -> bool:\n",
        "    return md5 == calculate_md5(fpath, **kwargs)\n",
        "\n",
        "\n",
        "def check_integrity(fpath: str, md5: Optional[str] = None) -> bool:\n",
        "    if not os.path.isfile(fpath):\n",
        "        return False\n",
        "    if md5 is None:\n",
        "        return True\n",
        "    return check_md5(fpath, md5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqDYmGGjjiwV"
      },
      "source": [
        "from urllib.parse import urlparse\n",
        "from typing import Optional\n",
        "import re\n",
        "\n",
        "def _get_google_drive_file_id(url: str) -> Optional[str]:\n",
        "    # Src: pytorch/vision/utils\n",
        "    parts = urlparse(url)\n",
        "\n",
        "    if re.match(r\"(drive|docs)[.]google[.]com\", parts.netloc) is None:\n",
        "        return None\n",
        "\n",
        "    match = re.match(r\"/file/d/(?P<id>[^/]*)\", parts.path)\n",
        "    if match is None:\n",
        "        return None\n",
        "\n",
        "    return match.group(\"id\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "uhmXygRTh_Dy"
      },
      "source": [
        "#@markdown `StandardScaler(mean, std)`\n",
        "class StandardScaler(nn.Module):\n",
        "    def __init__(self, mean=None, std=None, target_std_scale=1.0) -> None:\n",
        "        super(StandardScaler, self).__init__()\n",
        "        \n",
        "        # Set property for query, can't change inner scaler if change these value\n",
        "        self.mean = mean\n",
        "        self.std = std/target_std_scale\n",
        "\n",
        "        if mean is None:\n",
        "            if std is None:\n",
        "                  self.scaler = lambda spec: (spec-spec.mean)/spec.std\n",
        "            else:\n",
        "                  self.scaler = lambda spec: (spec-spec.mean)/std\n",
        "        elif std is None:\n",
        "            self.scaler = lambda spec: (spec-mean)/spec.std\n",
        "        else:\n",
        "            self.scaler = lambda spec: (spec-mean)/std\n",
        "        \n",
        "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
        "        return self.scaler(spec).nan_to_num(posinf=0.0, neginf=0.0)\n",
        "\n",
        "#@markdown `MinMaxScaler(min, max)`\n",
        "class MinMaxScaler(nn.Module):\n",
        "    def __init__(self, min=None, max=None) -> None:\n",
        "        super(MinMaxScaler, self).__init__()\n",
        "        if min:\n",
        "            self._min = lambda x: min\n",
        "        else:\n",
        "            self._min = lambda x: x.min()\n",
        "        if max:\n",
        "            self._max = lambda x: max\n",
        "        else:\n",
        "            self._max = lambda x: x.max()\n",
        "        \n",
        "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
        "        return ((spec-self._min(spec))/(self._max(spec)-self._min(spec))).nan_to_num(posinf=0.0, neginf=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkGwlGUh6iM0"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "from tqdm.notebook import tqdm\n",
        "import tempfile, shutil\n",
        "import weakref\n",
        "import pickle\n",
        "import warnings\n",
        "import ast\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class AICOVIDDataset(Dataset):\n",
        "    '''\n",
        "    AICOVID dataset made easy\n",
        "    '''\n",
        "\n",
        "    available_splits = [\"w_pub_train\", \"w_pub_test\", \"w_pri_test\", \"f_pub_train\", \"f_pub_test\", \"f_pri_test\"]\n",
        "\n",
        "    official_urls = {\n",
        "        \"w_pub_train\": \"https://drive.google.com/file/d/1MPhz3zYl2yefCq-J5XySbFJt99BfKIZD/view\",\n",
        "        \"w_pub_test\": \"https://drive.google.com/file/d/1UrMudzopA3CyR1Ih2J63Kfi2mY_0uhRK/view\",\n",
        "        \"w_pri_test\": \"https://drive.google.com/file/d/1hP8rHwJ_bz3J1T4MtEEp53ZBe9fdFKrW/view\",\n",
        "        \"f_pub_train\": \"https://drive.google.com/file/d/1Oq9UgA9cEGMNRGvF7oNKkFOg6udsDprl/view\",\n",
        "        \"f_pub_test\": \"https://drive.google.com/file/d/159SghfGeqVj3AfgTRZXsAAAj0-3ogccX/view\",\n",
        "        \"f_pri_test\": None\n",
        "    }\n",
        "\n",
        "    mirrored_urls = {\n",
        "        \"w_pub_train\": \"https://drive.google.com/file/d/1hoGLxjLmPY-pX-jSVGIaWIZhovQBMKU1/view\",\n",
        "        \"w_pub_test\": \"https://drive.google.com/file/d/1X7vOjHos9f9w48-iTWyu5JElFqCjcH_R/view\",\n",
        "        \"w_pri_test\": \"https://drive.google.com/file/d/1Ec64sSm2dZqe3da_LVyE_jUBD0DnLyqB/view\",\n",
        "        \"f_pub_train\": \"https://drive.google.com/file/d/1HoRJllAfYNeBPoCz2nXkf7lQ3raPcFYf/view\",\n",
        "        \"f_pub_test\": \"https://drive.google.com/file/d/1w5N5prH-uWqLvoSZnuY8TIqm_BBgN2ND/view\",\n",
        "        \"f_pri_test\": None\n",
        "    }\n",
        "\n",
        "    resources = {\n",
        "        \"w_pub_train\": (\"aicv115m_public_train.zip\", None),\n",
        "        \"w_pub_test\": (\"aicv115m_public_test.zip\", None),\n",
        "        \"w_pri_test\": (\"aicv115m_private_test.zip\", None),\n",
        "        \"f_pub_train\": (\"aicv115m_final_public_train.zip\", None),\n",
        "        \"f_pub_test\": (\"aicv115m_final_public_test.zip\", None),\n",
        "        \"f_pri_test\": None\n",
        "    }\n",
        "\n",
        "    audio_paths = {\n",
        "        \"w_pub_train\": 'aicv115m_public_train/train_audio_files_8k/',\n",
        "        \"w_pub_test\": 'aicv115m_public_test/public_test_audio_files_8k/',\n",
        "        \"w_pri_test\": 'aicv115m_private_test/private_test_audio_files_8k/',\n",
        "        \"f_pub_train\": 'aicv115m_final_public_train/public_train_audio_files/',\n",
        "        \"f_pub_test\": 'aicv115m_final_public_test/public_test_audio_files/',\n",
        "        \"f_pri_test\": None\n",
        "    }\n",
        "\n",
        "    ############\n",
        "    #   init\n",
        "    ############\n",
        "\n",
        "    def __init__(self, \n",
        "                 split: Optional[str]=None,\n",
        "                 audio_transforms: Optional[nn.ModuleList]=None, \n",
        "                 normalize: Optional[Union[str, nn.Module]]=None,\n",
        "                 chunking: Optional[Tuple[int, int]]=None,\n",
        "                 val_split: Optional[bool]=None,\n",
        "                 split_ratio: float=0.8,\n",
        "                 cleanup_after: bool=True) -> None:\n",
        "        \n",
        "        # Dataset statistic: mean, std, mean by freq band, std by freq band\n",
        "        if split is None: return  # Allow empty dataset for loading from gdrive later\n",
        "\n",
        "        if split not in self.available_splits:\n",
        "            raise NameError(f\"{split} is not a valid split, please check again!\")\n",
        "\n",
        "        self.split = split\n",
        "        self.download()\n",
        "\n",
        "        self.meta_df = self.extract_archive()\n",
        "\n",
        "        if val_split is not None:\n",
        "            idx_train, idx_val = train_test_split(self.meta_df.index, train_size=split_ratio, random_state=1)\n",
        "            self.meta_df = self.meta_df.iloc[idx_val if val_split else idx_train]\n",
        "\n",
        "        # Create temporary folder to dump preprocessed data\n",
        "        self._temp_folder = tempfile.mkdtemp()\n",
        "        self._finalizer = weakref.finalize(self, shutil.rmtree, self._temp_folder)\n",
        "\n",
        "        self.file_paths = []\n",
        "        self.idxs = []\n",
        "        self.chunk_idxs = None\n",
        "        \n",
        "        self.mean = []\n",
        "        self.std = []\n",
        "  \n",
        "        self.process_files(audio_transforms, chunking, normalize)\n",
        "\n",
        "        if normalize == 'ast':\n",
        "            self.scaler = StandardScaler(self.mean, self.std, 0.5)\n",
        "        elif normalize == 'by_freq_band':\n",
        "            self.mean = torch.tensor(self.mean).unsqueeze(-1)\n",
        "            self.std = torch.tensor(self.std).unsqueeze(-1)\n",
        "            self.scaler = StandardScaler(self.mean, self.std)\n",
        "        elif isinstance(normalize, StandardScaler):\n",
        "            self.scaler = normalize\n",
        "            self.mean = normalize.mean\n",
        "            self.std = normalize.std\n",
        "        elif normalize is None:\n",
        "            self.scaler = lambda x: x\n",
        "            print(\"This dataset is not normalized, be careful!\")\n",
        "        else:\n",
        "            raise KeyError(\"Invalid 'normalize' value\")\n",
        "\n",
        "        self.normalize_dataset()\n",
        "        \n",
        "        if cleanup_after:\n",
        "            self.cleanup_extract()\n",
        "\n",
        "\n",
        "    ################################\n",
        "    #   download/extract/cleanup\n",
        "    ################################\n",
        "\n",
        "    def _check_exists(self) -> bool:\n",
        "        return check_integrity(*self.resources[self.split])\n",
        "\n",
        "\n",
        "    def download(self) -> None:\n",
        "        if self._check_exists():\n",
        "            print(\"> Archive have already downloaded\")\n",
        "            return\n",
        "        file_id = _get_google_drive_file_id(self.official_urls[self.split])\n",
        "        os.system(f\"gdown --id {file_id}\")\n",
        "        print(\"\\n> Archive download complete\")\n",
        "\n",
        "\n",
        "    def extract_archive(self) -> pd.DataFrame:\n",
        "        file_name, _ = self.resources[self.split]\n",
        "        os.system(f\"unzip -n -q {file_name}\")\n",
        "        print(\"\\n> Extract complete\")\n",
        "\n",
        "        # split standardize (some split have different folder organize style)\n",
        "        if self.split == \"w_pub_train\":\n",
        "            os.system(\"unzip -n -q aicv115m_public_train/train_audio_files_8k.zip -d ./aicv115m_public_train\")\n",
        "            meta = pd.read_csv('aicv115m_public_train/metadata_train_challenge.csv').drop(columns=[\"file_path\"])\n",
        "        elif self.split == \"w_pub_test\":\n",
        "            os.system(\"unzip -n -q aicv115m_public_test/public_test_audio_files_8k.zip -d /aicv115m_public_test\")\n",
        "            meta = pd.read_csv('aicv115m_public_test/metadata_public_test.csv').drop(columns=[\"file_path\"])\n",
        "        elif self.split == \"w_pri_test\":\n",
        "            meta = pd.read_csv('aicv115m_private_test/metadata_private_test.csv').drop(columns=[\"file_path\"])\n",
        "        elif self.split == \"f_pub_train\":\n",
        "            meta = pd.read_csv('aicv115m_final_public_train/public_train_metadata.csv')\n",
        "            med_meta = pd.read_csv(\"aicv115m_final_public_train/public_train_medical_condition.csv\")\n",
        "            meta = meta.merge(med_meta, how=\"left\", on=\"uuid\")\n",
        "            meta = self._process_final_meta(meta)\n",
        "        elif self.split == \"f_pub_test\":\n",
        "            meta = pd.read_csv('aicv115m_final_public_test/public_test_sample_submission.csv').drop(columns=[\"assessment_result\"])\n",
        "        elif self.split == \"f_pri_test\":\n",
        "            raise NotImplementedError()\n",
        "\n",
        "        return meta\n",
        "\n",
        "\n",
        "    def _process_final_meta(self, meta):\n",
        "        # Convert string in list/dict format to real list/dict object\n",
        "        str_to_obj = lambda x: ast.literal_eval(x)\n",
        "        col_tobe_processed = ['cough_intervals', 'symptoms_status_choice', 'medical_condition_choice',]\n",
        "        for col in col_tobe_processed:\n",
        "            meta[col] = meta[col].map(str_to_obj, na_action='ignore')\n",
        "\n",
        "        # Process list type columns and categorical columns\n",
        "        medical_condition_choice_df = pd.get_dummies(meta['medical_condition_choice'].apply(pd.Series).stack()).sum(level=0)\n",
        "        medical_condition_choice_df = medical_condition_choice_df.drop(columns=['No'])\n",
        "        symptoms_status_choice_df = pd.get_dummies(meta['symptoms_status_choice'].apply(pd.Series).stack()).sum(level=0)\n",
        "        symptoms_status_choice_df = symptoms_status_choice_df.drop(columns=['No'])\n",
        "        sex_dummies = pd.get_dummies(meta['subject_gender'])\n",
        "        meta = meta.join([sex_dummies, medical_condition_choice_df, symptoms_status_choice_df])\n",
        "        meta.drop(columns=['subject_gender', 'symptoms_status_choice','medical_condition_choice'], inplace=True)\n",
        "\n",
        "        # Convert to ordinal values\n",
        "        age_map = {'group_0_2': 1, \n",
        "                  'group_3_5': 2,\n",
        "                  'group_6_13': 3,\n",
        "                  'group_14_18': 4,\n",
        "                  'group_19_33': 5,\n",
        "                  'group_34_48': 6,\n",
        "                  'group_49_64': 7,\n",
        "                  'group_65_78': 8,\n",
        "                  'group_79_98': 9\n",
        "                  }\n",
        "\n",
        "        smoke_map = {\n",
        "            'never': 0,\n",
        "            'ex': 1,\n",
        "            'ltOnce': 2,\n",
        "            '1to10': 3,\n",
        "            '11to20': 4,\n",
        "            '21+': 5,\n",
        "            'ecig': 6\n",
        "        }\n",
        "\n",
        "        insomnia_map = {\n",
        "            'No': 0,\n",
        "            'Onceper2Weeks': 1,\n",
        "            '2to3': 2,\n",
        "            '1': 3,\n",
        "            '4+': 4\n",
        "        }\n",
        "\n",
        "        meta = meta.replace({'subject_age': age_map, \n",
        "                             'smoke_status_choice': smoke_map, \n",
        "                             'insomnia_status_choice': insomnia_map})\n",
        "        \n",
        "        return meta\n",
        "\n",
        "\n",
        "    def cleanup_extract(self) -> None:\n",
        "        file_name, _ = self.resources[self.split]\n",
        "        folder_name = file_name[:-4]  # Remove .zip part\n",
        "        shutil.rmtree(folder_name)\n",
        "\n",
        "\n",
        "    ##################\n",
        "    #   read audio\n",
        "    ##################\n",
        "\n",
        "    def process_files(self,\n",
        "                      audio_transforms: torch.nn.ModuleList=None, \n",
        "                      chunking: Optional[Tuple[int, int]]=None,\n",
        "                      normalize: Optional[Union[str, nn.Module]]=None):\n",
        "      \n",
        "        # Join audio path with file name for reading\n",
        "        audio_path = self.audio_paths[self.split]\n",
        "        audio_files = audio_path + self.meta_df['uuid'] + '.wav'\n",
        "\n",
        "        # Make chunker\n",
        "        if chunking:\n",
        "            self.chunk_idxs = []\n",
        "            chunking = AudioChunking(*chunking, idx_instead=True)\n",
        "\n",
        "        # Specify special case for accumulate statistic\n",
        "        if normalize == 'by_freq_band':\n",
        "            # Only reduce last dimension when calculating statistic\n",
        "            accum_dim = -1\n",
        "        else:\n",
        "            # Reduce whole tensor\n",
        "            accum_dim = None\n",
        "\n",
        "        for id, file in enumerate(tqdm(audio_files)):\n",
        "            # Read audio and perform transformations\n",
        "            specs = self._read_spec_audio(file, audio_transforms)\n",
        "\n",
        "            # Accumulate mean, std of the audio\n",
        "            self._accumulate_stats(specs, accum_dim)\n",
        "\n",
        "            if chunking:\n",
        "                for spec in specs:\n",
        "                    new_spec, chunk_idxs = chunking(spec)\n",
        "                    paths = self._dump_to_disk([new_spec])\n",
        "                    \n",
        "                    self.file_paths += paths*len(chunk_idxs)\n",
        "                    self.idxs += [id]*len(chunk_idxs)\n",
        "                    self.chunk_idxs += chunk_idxs\n",
        "            else:\n",
        "                paths = self._dump_to_disk(specs)\n",
        "                self.file_paths += paths\n",
        "                self.idxs += [id]*len(paths)\n",
        "\n",
        "        self._finalize_stats()\n",
        "\n",
        "        print(\"\\n> File processing complete\")\n",
        "\n",
        "        # Pickle for backup later\n",
        "        with open(f\"{self._temp_folder}/meta_df.pkl\",'wb') as tmp:\n",
        "            pickle.dump(self.meta_df, tmp)\n",
        "        with open(f\"{self._temp_folder}/file_paths.pkl\",'wb') as tmp:\n",
        "            pickle.dump(self.file_paths, tmp)\n",
        "        with open(f\"{self._temp_folder}/idxs.pkl\",'wb') as tmp:\n",
        "            pickle.dump(self.idxs, tmp)\n",
        "        with open(f\"{self._temp_folder}/chunk_idxs.pkl\",'wb') as tmp:\n",
        "            if self.chunk_idxs is None:\n",
        "                pickle.dump(\"None\", tmp)\n",
        "            else:\n",
        "                pickle.dump(self.chunk_idxs, tmp)\n",
        "\n",
        "\n",
        "    def _read_spec_audio(self, \n",
        "                         file: str,\n",
        "                         transforms: torch.nn.ModuleList=None) -> list:\n",
        "        wave = read_resample_audio(file, 8000).cuda()\n",
        "        if transforms:\n",
        "            specs = [trans(wave) for trans in transforms]\n",
        "        else:\n",
        "            specs = [wave]\n",
        "        return specs\n",
        "\n",
        "    def _dump_to_disk(self, specs: list or torch.Tensor) -> list:\n",
        "        file_paths = []\n",
        "        for spec in specs:\n",
        "            fd, path = tempfile.mkstemp(suffix=\".pt\", dir=self._temp_folder)\n",
        "            with os.fdopen(fd, 'wb') as tmp:\n",
        "                # Clone to prevent view preserving of PyTorch\n",
        "                # also moving tensor to cpu so when load up\n",
        "                # pytorch will not moving them to gpu bebforehand!\n",
        "                torch.save(spec.cpu(), tmp)\n",
        "            file_paths.append(path)\n",
        "        return file_paths\n",
        "\n",
        "    def _accumulate_stats(self, specs, dim=None):\n",
        "        if dim:\n",
        "            for spec in specs:\n",
        "                self.mean.append(spec.mean(dim=dim))\n",
        "                self.std.append(spec.std(dim=dim))\n",
        "        else:\n",
        "            for spec in specs:\n",
        "                self.mean.append(spec.mean().view(1))\n",
        "                self.std.append(spec.std().view(1))\n",
        "\n",
        "    def _finalize_stats(self):\n",
        "        self.mean = torch.cat(self.mean).mean(dim=-1).cpu()\n",
        "        self.std = torch.cat(self.std).mean(dim=-1).cpu()\n",
        "\n",
        "    def normalize_dataset(self):\n",
        "        print(\"\\n> Start normalizing data\")\n",
        "        for file_path in tqdm(np.unique(self.file_paths)):\n",
        "            spec = torch.load(file_path)\n",
        "            spec = self.scaler(spec)\n",
        "            with open(file_path, 'wb') as tmp:\n",
        "                torch.save(spec.cpu(), tmp)\n",
        "        print(\"\\n> Normalizing data complete\")\n",
        "\n",
        "\n",
        "    ###################\n",
        "    #   backup/load\n",
        "    ###################\n",
        "\n",
        "    def backup_to_drive(self, folder_id: str, upload_name: str):\n",
        "        if self.meta_df is None:\n",
        "            raise NameError(\"Cannot backup an empty dataset.\")\n",
        "        \n",
        "        os.system(f'zip -j ./{upload_name} {self._temp_folder}/*')\n",
        "        drive.Upload(upload_name, folder_id)\n",
        "        os.remove(upload_name)\n",
        "\n",
        "\n",
        "    def load_from_drive(self, folder_id: str, backuped_name: str):\n",
        "        drive.Download(backuped_name, folder_id)\n",
        "        os.system(f'unzip -o {backuped_name} -d {self._temp_folder}')\n",
        "        os.remove(backuped_name)\n",
        "        with open(f\"{self._temp_folder}/meta_df.pkl\",'rb') as tmp:\n",
        "            self.meta_df = pickle.load(tmp)\n",
        "        with open(f\"{self._temp_folder}/idxs.pkl\",'rb') as tmp:\n",
        "            self.idxs = pickle.load(tmp)\n",
        "        with open(f\"{self._temp_folder}/file_paths.pkl\",'rb') as tmp:\n",
        "            self.file_paths = pickle.load(tmp)\n",
        "        with open(f\"{self._temp_folder}/chunk_idxs.pkl\",'rb') as tmp:\n",
        "            self.chunk_idxs = pickle.load(tmp)\n",
        "            if self.chunk_idxs == \"None\":\n",
        "                self.chunk_idxs = None\n",
        "\n",
        "        # Replace old tmp dir with current tmp dir\n",
        "        for i, path in enumerate(self.file_paths):\n",
        "            self.file_paths[i] = self._temp_folder+'/'+path.split('/')[-1]\n",
        "\n",
        "    \n",
        "    ################\n",
        "    #   getitem\n",
        "    ################\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        spec = torch.load(self.file_paths[idx])\n",
        "        if self.chunk_idxs:\n",
        "            start, end = self.chunk_idxs[idx]\n",
        "            spec = spec[..., start:end]\n",
        "\n",
        "        meta = self.meta_df.iloc[self.idxs[idx]]\n",
        "       \n",
        "        label = meta.get('assessment_result')\n",
        "        if label is not None:\n",
        "            label = torch.tensor(label)\n",
        "            meta = meta.drop('assessment_result')\n",
        "\n",
        "        return spec, label, meta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTp2e79LSHVx"
      },
      "source": [
        "# H√†m x·ª≠ l√Ω √¢m thanh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEboAF063rLi"
      },
      "source": [
        "### Audio features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPA3iLpQ1fhs"
      },
      "source": [
        "# Spectrogram transformation\n",
        "n_fft = 2048\n",
        "win_length = 250\n",
        "hop_length = 100\n",
        "n_mels = 128\n",
        "n_mfcc = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "iuHhNXmvCYuR"
      },
      "source": [
        "#@markdown `spectrogram(waveform)` --> spec \n",
        "spectrogram = torchaudio.transforms.Spectrogram(\n",
        "    n_fft=n_fft,\n",
        "    win_length=win_length,\n",
        "    hop_length=hop_length,\n",
        "    center=True,\n",
        "    normalized=True,\n",
        "    pad_mode=\"reflect\",\n",
        "    power=2.0,\n",
        ")\n",
        "\n",
        "#@markdown `mel_spectrogram(waveform)` --> mel_spec \n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=8000,\n",
        "    n_fft=n_fft,\n",
        "    win_length=win_length,\n",
        "    hop_length=hop_length,\n",
        "    center=True,\n",
        "    pad_mode=\"reflect\",\n",
        "    power=2.0,\n",
        "    #norm='slaney',\n",
        "    onesided=True,\n",
        "    normalized=True,\n",
        "    n_mels=n_mels,\n",
        "    mel_scale=\"htk\",\n",
        ")\n",
        "\n",
        "#@markdown `log_spectrogram(spec)` --> log(spec)\n",
        "log_spectrogram = torchaudio.transforms.AmplitudeToDB(\n",
        "    stype='power',\n",
        "    top_db=80\n",
        ")\n",
        "\n",
        "#@markdown `mfcc_transform(waveform)` --> mfcc\n",
        "mfcc_transform = torchaudio.transforms.MFCC(\n",
        "    sample_rate=8000,\n",
        "    n_mfcc=n_mfcc,\n",
        "    log_mels=False,\n",
        "    melkwargs={\n",
        "      'n_fft': n_fft,\n",
        "      'n_mels': n_mels,\n",
        "      'hop_length': hop_length,\n",
        "      'win_length': win_length,\n",
        "    }\n",
        ")\n",
        "\n",
        "#@markdown `delta_transform(spec)` --> delta 1\n",
        "delta_transform = torchaudio.transforms.ComputeDeltas(\n",
        "    win_length = 5, \n",
        "    mode = 'replicate'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkxxsDa8r0ql"
      },
      "source": [
        "### Augmentation cho audio\n",
        "Bao g·ªìm: th√™m noise (nhi·ªÅu m·ª©c ƒë·ªô), SpecAugment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "JK5OCYJfpYz6"
      },
      "source": [
        "#@markdown `SpecAugment(time_W=50, freq_W=50, T=80, F=80)`\n",
        "def _h_poly(t):\n",
        "    tt = t.unsqueeze(-2)**torch.arange(4, device=t.device).view(-1,1)\n",
        "    A = torch.tensor([\n",
        "        [1, 0, -3, 2],\n",
        "        [0, 1, -2, 1],\n",
        "        [0, 0, 3, -2],\n",
        "        [0, 0, -1, 1]\n",
        "    ], dtype=t.dtype, device=t.device)\n",
        "    return A @ tt\n",
        "\n",
        "\n",
        "def _cspline_interpolate(x, y, xs):\n",
        "    '''\n",
        "    Input x and y must be of shape (batch, n) or (n)\n",
        "    '''\n",
        "    m = (y[..., 1:] - y[..., :-1]) / (x[..., 1:] - x[..., :-1])\n",
        "    m = torch.cat([m[...,[0]], (m[...,1:] + m[...,:-1]) / 2, m[...,[-1]]], -1)\n",
        "    idxs = torch.searchsorted(x[..., 1:], xs)\n",
        "    dx = (x.take_along_dim(idxs+1, dim=-1) - x.take_along_dim(idxs, dim=-1))\n",
        "    hh = _h_poly((xs - x.take_along_dim(idxs, dim=-1)) / dx)\n",
        "    return hh[...,0,:] * y.take_along_dim(idxs, dim=-1) \\\n",
        "        + hh[...,1,:] * m.take_along_dim(idxs, dim=-1) * dx \\\n",
        "        + hh[...,2,:] * y.take_along_dim(idxs+1, dim=-1) \\\n",
        "        + hh[...,3,:] * m.take_along_dim(idxs+1, dim=-1) * dx\n",
        "        \n",
        "\n",
        "class SpecAugment(torch.nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      time_W: int = 0,\n",
        "      freq_W: int = 0,\n",
        "      T: int = 0,\n",
        "      F: int = 0,\n",
        "      mT: int = 1,\n",
        "      mF: int = 1\n",
        "  ) -> None:\n",
        "      super(SpecAugment, self).__init__()\n",
        "      self.identity_fn = lambda x: x\n",
        "      self.time_W = time_W\n",
        "      self.freq_W = freq_W\n",
        "      if time_W==0 and freq_W==0:\n",
        "          self.cum_warping = lambda x: x\n",
        "      elif time_W!=0 and freq_W==0:\n",
        "          self.cum_warping = self.time_warping\n",
        "      elif time_W==0 and freq_W!=0:\n",
        "          self.cum_warping = self.freq_warping\n",
        "      else:\n",
        "          self.cum_warping = self.time_freq_warping\n",
        "      self.time_masking = torchaudio.transforms.TimeMasking(time_mask_param=T) if T>0 else self.identity_fn\n",
        "      self.freq_masking = torchaudio.transforms.FrequencyMasking(freq_mask_param=F) if F>0 else self.identity_fn\n",
        "\n",
        "\n",
        "  def _get_warping_flow(self,\n",
        "                        warp_p: torch.Tensor,\n",
        "                        warp_d: torch.Tensor,\n",
        "                        interp_len: int) -> torch.Tensor:\n",
        "      '''\n",
        "      Get interpolated flow\n",
        "      Warning: This function doesn't check for batch size match between warp_p and warp_d\n",
        "      '''\n",
        "      device = warp_p.device\n",
        "      batch_size = warp_p.shape[0]\n",
        "\n",
        "      src_control_points = torch.stack([torch.tensor([0], device=device).expand(batch_size),\n",
        "                                        warp_p, torch.tensor([interp_len-1], device=device).expand(batch_size)], dim=1)\n",
        "      dest_control_points = torch.stack([torch.tensor([-1.], device=device).expand(batch_size),\n",
        "                                        (warp_p-warp_d)*2/(interp_len-1)-1, torch.tensor([1], device=device).expand(batch_size)], dim=1)\n",
        "\n",
        "      # Interpolate from 3 points to interp_len points\n",
        "      src_interp_points = torch.linspace(0, interp_len-1, interp_len, device=device).unsqueeze(0).expand(batch_size, -1)\n",
        "      dest_interp_points = _cspline_interpolate(src_control_points, dest_control_points, src_interp_points)\n",
        "\n",
        "      return dest_interp_points\n",
        "\n",
        "\n",
        "  def freq_warping(self, specs: torch.Tensor) -> torch.Tensor:\n",
        "      '''\n",
        "      Frequency warping augmentation, only return interpolated flow\n",
        "\n",
        "      param:\n",
        "        specs: spectrogram of size (batch, channel, freq_bin, length)\n",
        "      '''\n",
        "      W = self.freq_W\n",
        "      device = specs.device\n",
        "      batch_size, _, num_freqs, num_frames = specs.shape\n",
        "\n",
        "      warp_p = torch.randint(W, num_freqs - W, (batch_size,), device=device)\n",
        "\n",
        "      # Uniform distribution from (0,W) with chance to be up to W negative\n",
        "      warp_d = torch.randint(-W, W, (batch_size,), device=device)\n",
        "      \n",
        "      dest_freq_points = self._get_warping_flow(warp_p, warp_d, num_freqs)\n",
        "      dest_frame_points = torch.linspace(-1, 1, num_frames, device=device)\n",
        "\n",
        "      grid = torch.cat(\n",
        "          (dest_frame_points.view(-1,1).expand(batch_size,num_freqs,-1,-1),\n",
        "          dest_freq_points.view(batch_size,-1,1,1).expand(-1,-1,num_frames,-1)), dim=-1)\n",
        "\n",
        "      return torch.nn.functional.grid_sample(specs, grid, align_corners=True)\n",
        "\n",
        "\n",
        "  def time_warping(self, specs: torch.Tensor) -> torch.Tensor:\n",
        "      '''\n",
        "      Time warping augmentation, only return interpolated flow\n",
        "\n",
        "      param:\n",
        "        specs: spectrogram of size (batch, channel, freq_bin, length)\n",
        "      '''\n",
        "      W = self.time_W\n",
        "      device = specs.device\n",
        "      batch_size, _, num_freqs, num_frames = specs.shape\n",
        "\n",
        "      warp_p = torch.randint(W, num_frames - W, (batch_size,), device=device)\n",
        "\n",
        "      # Uniform distribution from (0,W) with chance to be up to W negative\n",
        "      warp_d = torch.randint(-W, W, (batch_size,), device=device)\n",
        "\n",
        "      # Interpolate from 3 points to num_frames points\n",
        "      dest_frame_points = self._get_warping_flow(warp_p, warp_d, num_frames)\n",
        "      dest_freq_points = torch.linspace(-1, 1, num_freqs, device=device)\n",
        "\n",
        "      grid = torch.cat(\n",
        "          (dest_frame_points.view(batch_size,1,-1,1).expand(-1,num_freqs,-1,-1),\n",
        "          dest_freq_points.view(-1,1,1).expand(batch_size,-1,num_frames,-1)), dim=-1)\n",
        "\n",
        "      return torch.nn.functional.grid_sample(specs, grid, align_corners=True)\n",
        "\n",
        "\n",
        "  def time_freq_warping(self,specs: torch.Tensor) -> torch.Tensor:\n",
        "      '''\n",
        "      Doing both time warping and frequency warping augmentation\n",
        "\n",
        "      param:\n",
        "        specs: spectrogram of size (batch, channel, freq_bin, length)\n",
        "        W: strength of warp\n",
        "      '''\n",
        "      device = specs.device\n",
        "      batch_size, _, num_freqs, num_frames = specs.shape\n",
        "\n",
        "      time_warp_p = torch.randint(self.time_W, num_frames - self.time_W, (batch_size,), device=device)\n",
        "      freq_warp_p = torch.randint(self.freq_W, num_freqs - self.freq_W, (batch_size,), device=device)\n",
        "\n",
        "      # Uniform distribution from (0,W) with chance to be up to W negative\n",
        "      time_warp_d = torch.randint(-self.time_W, self.time_W, (batch_size,), device=device)\n",
        "      freq_warp_d = torch.randint(-self.freq_W, self.freq_W, (batch_size,), device=device)\n",
        "\n",
        "      # Interpolate l√™n theo k√≠ch th∆∞·ªõc spec\n",
        "      dest_freq_points = self._get_warping_flow(freq_warp_p, freq_warp_d, num_freqs)\n",
        "      dest_frame_points = self._get_warping_flow(time_warp_p, time_warp_d, num_frames)\n",
        "\n",
        "      grid = torch.cat(\n",
        "          (dest_frame_points.view(batch_size,1,-1,1).expand(-1,num_freqs,-1,-1),\n",
        "          dest_freq_points.view(batch_size,-1,1,1).expand(-1,-1,num_frames,-1)), dim=-1)\n",
        "\n",
        "      return torch.nn.functional.grid_sample(specs, grid, align_corners=True)\n",
        "\n",
        "\n",
        "  def forward(self, specs: torch.Tensor) -> torch.Tensor:\n",
        "      aug_specs = self.cum_warping(specs)\n",
        "      aug_specs = self.time_masking(aug_specs)\n",
        "      aug_specs = self.freq_masking(aug_specs)\n",
        "      return aug_specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "fOlyVYDtuJDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0511e0dd-240a-47ac-ebba-5b595ce26334"
      },
      "source": [
        "#@markdown T·∫£i noise audio\n",
        "import requests\n",
        "\n",
        "!mkdir _sample_data\n",
        "SAMPLE_NOISE_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav\"\n",
        "SAMPLE_NOISE_PATH = os.path.join('_sample_data', \"bg.wav\")\n",
        "SAMPLE_RIR_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav\"\n",
        "SAMPLE_RIR_PATH = os.path.join('_sample_data', \"rir.wav\")\n",
        "\n",
        "def _fetch_data():\n",
        "  uri = [\n",
        "    (SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH),\n",
        "    (SAMPLE_RIR_URL, SAMPLE_RIR_PATH)\n",
        "  ]\n",
        "  for url, path in uri:\n",
        "    with open(path, 'wb') as file_:\n",
        "      file_.write(requests.get(url).content)\n",
        "\n",
        "_fetch_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‚Äò_sample_data‚Äô: File exists\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcKSZU1F4rAK"
      },
      "source": [
        "def _get_sample(path, resample=None):\n",
        "  effects = [\n",
        "    [\"remix\", \"1\"]\n",
        "  ]\n",
        "  if resample:\n",
        "    effects.extend([\n",
        "      [\"lowpass\", f\"{resample // 2}\"],\n",
        "      [\"rate\", f'{resample}'],\n",
        "    ])\n",
        "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
        "\n",
        "def get_noise_sample(*, resample=None):\n",
        "  return _get_sample(SAMPLE_NOISE_PATH, resample=resample)\n",
        "\n",
        "def get_rir_sample(*, resample=None, processed=False):\n",
        "  rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
        "  if not processed:\n",
        "    return rir_raw, sample_rate\n",
        "  rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
        "  rir = rir / torch.norm(rir, p=2)\n",
        "  rir = torch.flip(rir, [1])\n",
        "  return rir, sample_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "BEH8Qh2SqH6c"
      },
      "source": [
        "import math\n",
        "\n",
        "#@markdown `RoomReverb`, `NoiseInject`, `PhoneSim`\n",
        "class RoomReverb(torch.nn.Module):\n",
        "    def __init__(self, rir_list):\n",
        "        super(RoomReverb, self).__init__()\n",
        "        self.rirs = rir_list\n",
        "\n",
        "    def _get_rir(self):\n",
        "        if type(self.rirs) is list:\n",
        "            return random.choice(self.rirs)\n",
        "        else: \n",
        "            return next(self.rirs)\n",
        "\n",
        "    def forward(self, wave: torch.Tensor):\n",
        "        rir = self._get_rir()\n",
        "        _wave = torch.nn.functional.pad(wave, (rir.shape[-1]-1, 0))\n",
        "        _wave = torch.nn.functional.conv1d(_wave[None, ...], rir[None, ...])[0]\n",
        "        return _wave\n",
        "\n",
        "\n",
        "class NoiseInject(torch.nn.Module):\n",
        "    def __init__(self, noise_list, snr_db):\n",
        "        super(NoiseInject, self).__init__()\n",
        "        self.noises = noise_list\n",
        "        self.snr_db = snr_db\n",
        "\n",
        "    def _get_noise(self):\n",
        "        if type(self.noises) is list:\n",
        "            return random.choice(self.noises)\n",
        "        else: \n",
        "            return next(self.noises)\n",
        "\n",
        "    def forward(self, wave: torch.Tensor):\n",
        "        noise = self._get_noise()\n",
        "        _noise = noise.repeat(1, 1 + wave.shape[-1] // noise.shape[-1])[..., :wave.shape[-1]]\n",
        "        scale = math.exp(self.snr_db / 10) * _noise.norm(p=2) / wave.norm(p=2)\n",
        "        _wave = (scale * wave + _noise) / 2\n",
        "        return _wave\n",
        "\n",
        "\n",
        "class PhoneSim(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PhoneSim, self).__init__()\n",
        "\n",
        "    def forward(self, wave: torch.Tensor):\n",
        "        device = wave.device\n",
        "        _wave = wave.cpu()\n",
        "        _wave, _ = torchaudio.sox_effects.apply_effects_tensor(\n",
        "          _wave, 8000,\n",
        "          effects=[[\"lowpass\", \"4000\"],\n",
        "                   [\"compand\", \"0.02,0.05\", \"-60,-60,-30,-10,-20,-8,-5,-8,-2,-8\", \"-8\", \"-7\", \"0.05\"]]\n",
        "        )\n",
        "        _wave = torchaudio.functional.apply_codec(_wave, 8000, format=\"gsm\")\n",
        "        return _wave.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6qT41qMqY10"
      },
      "source": [
        "rir, _ = get_rir_sample(resample=8000, processed=True)\n",
        "noise, _ = get_noise_sample(resample=8000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Lc0HIA2ZjG"
      },
      "source": [
        "## C√°c h√†m b·ªï tr·ª£ tr·ª±c quan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "jQCI3iYC5fVe"
      },
      "source": [
        "#@markdown V·∫Ω specgram `plot_specgram(wave, sr, title, xlim, ylim)`\n",
        "#@markdown (specgram ch·ªâ ƒë∆°n gi·∫£n l√† apply discrete-time Fourier transform)\n",
        "\n",
        "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
        "  # Tensor --> Numpy\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
        "\n",
        "  figure, axes = plt.subplots(num_channels, 1)\n",
        "  if num_channels == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "  # Plot specgram for each channel\n",
        "  for c in range(num_channels):\n",
        "    axes[c].specgram(waveform[c], Fs=sample_rate)\n",
        "    if num_channels > 1:\n",
        "      axes[c].set_ylabel(f'Channel {c+1}')\n",
        "    if xlim:\n",
        "      axes[c].set_xlim(xlim)\n",
        "  figure.suptitle(title)\n",
        "  plt.show(block=False)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown V·∫Ω waveform `plot_waveform(wave, sr, title, xlim, ylim)`\n",
        "\n",
        "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n",
        "  # Tensor --> Numpy\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
        "\n",
        "  figure, axes = plt.subplots(num_channels, 1)\n",
        "  if num_channels == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "  # Plot waveform for each channel\n",
        "  for c in range(num_channels):\n",
        "    axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
        "    axes[c].grid(True)\n",
        "    if num_channels > 1:\n",
        "      axes[c].set_ylabel(f'Channel {c+1}')\n",
        "    if xlim:\n",
        "      axes[c].set_xlim(xlim)\n",
        "    if ylim:\n",
        "      axes[c].set_ylim(ylim)\n",
        "  figure.suptitle(title)\n",
        "  plt.show(block=False)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown V·∫Ω spectrogram `plot_spectrogram(spec, axs, title, ylabel, aspect, xmax)`\n",
        "\n",
        "def plot_spectrogram(spec, fig=None, axs=None, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n",
        "  if axs is None:\n",
        "    fig, axs = plt.subplots(1, 1)\n",
        "  axs.set_title(title or 'Spectrogram (db)')\n",
        "  axs.set_ylabel(ylabel)\n",
        "  axs.set_xlabel('frame')\n",
        "  im = axs.imshow(log_spectrogram(spec), origin='lower', aspect=aspect)\n",
        "  if xmax:\n",
        "    axs.set_xlim((0, xmax))\n",
        "  fig.colorbar(im, ax=axs)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown Hi·ªÉn th·ªã audio box `play_audio(wave, sr)`\n",
        "\n",
        "def play_audio(waveform, sample_rate):\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  if num_channels == 1:\n",
        "    display(Audio(waveform[0], rate=sample_rate))\n",
        "  elif num_channels == 2:\n",
        "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
        "  else:\n",
        "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y9lvxslO4sU"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaOs5PBXAil-"
      },
      "source": [
        "## AST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A5-qarJKfUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7c44f1-6f92-4ffe-ec7b-43323be7b6ce"
      },
      "source": [
        "!mkdir 'ast/pretrained_models'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‚Äòast/pretrained_models‚Äô: File exists\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P6qyQBXUFkW"
      },
      "source": [
        "import timm\n",
        "from timm.models.layers import to_2tuple,trunc_normal_\n",
        "import wget\n",
        "from einops.layers.torch import Reduce\n",
        "from collections import OrderedDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hmN3pAlThLh"
      },
      "source": [
        "# override the timm package to relax the input shape constraint.\n",
        "class PatchEmbed(nn.Module):\n",
        "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
        "        super().__init__()\n",
        "\n",
        "        img_size = to_2tuple(img_size)\n",
        "        patch_size = to_2tuple(patch_size)\n",
        "        num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x).flatten(2).transpose(1, 2)\n",
        "        return x\n",
        "\n",
        "class ASTModel(nn.Module):\n",
        "    \"\"\"\n",
        "    The AST model.\n",
        "    :param representation_size: the representation dimension\n",
        "    :param fstride: the stride of patch spliting on the frequency dimension, for 16*16 patchs, fstride=16 means no overlap, fstride=10 means overlap of 6\n",
        "    :param tstride: the stride of patch spliting on the time dimension, for 16*16 patchs, tstride=16 means no overlap, tstride=10 means overlap of 6\n",
        "    :param input_fdim: the number of frequency bins of the input spectrogram\n",
        "    :param input_tdim: the number of time frames of the input spectrogram\n",
        "    :param imagenet_pretrain: if use ImageNet pretrained model\n",
        "    :param audioset_pretrain: if use full AudioSet and ImageNet pretrained model\n",
        "    :param model_size: the model size of AST, should be in [tiny224, small224, base224, base384], base224 and base 384 are same model, but are trained differently during ImageNet pretraining.\n",
        "    \"\"\"\n",
        "    def __init__(self, representation_size=None, fstride=10, tstride=10, input_fdim=128, input_tdim=1024, imagenet_pretrain=True, audioset_pretrain=False, model_size='base384', verbose=True):\n",
        "\n",
        "        super(ASTModel, self).__init__()\n",
        "        assert timm.__version__ == '0.4.5', 'Please use timm == 0.4.5, the code might not be compatible with newer versions.'\n",
        "\n",
        "        if verbose == True:\n",
        "            print('---------------AST Model Summary---------------')\n",
        "            print('ImageNet pretraining: {:s}, AudioSet pretraining: {:s}'.format(str(imagenet_pretrain),str(audioset_pretrain)))\n",
        "        # override timm input shape restriction\n",
        "        timm.models.vision_transformer.PatchEmbed = PatchEmbed\n",
        "\n",
        "        # if AudioSet pretraining is not used (but ImageNet pretraining may still apply)\n",
        "        if audioset_pretrain == False:\n",
        "            if model_size == 'tiny224':\n",
        "                self.v = timm.create_model('vit_deit_tiny_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
        "            elif model_size == 'small224':\n",
        "                self.v = timm.create_model('vit_deit_small_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
        "            elif model_size == 'base224':\n",
        "                self.v = timm.create_model('vit_deit_base_distilled_patch16_224', pretrained=imagenet_pretrain)\n",
        "            elif model_size == 'base384':\n",
        "                self.v = timm.create_model('vit_deit_base_distilled_patch16_384', pretrained=imagenet_pretrain)\n",
        "            else:\n",
        "                raise Exception('Model size must be one of tiny224, small224, base224, base384.')\n",
        "            self.original_num_patches = self.v.patch_embed.num_patches\n",
        "            self.oringal_hw = int(self.original_num_patches ** 0.5)\n",
        "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
        "            # self.pooling_layer = nn.LayerNorm(self.original_embedding_dim)\n",
        "            # original bert do max/mean pooling, idk why author use layernorm?\n",
        "            self.pooling_layer = Reduce('b n e -> b e', reduction='mean')\n",
        "            \n",
        "            if representation_size:\n",
        "                self.pre_logits = nn.Sequential(OrderedDict([\n",
        "                    ('fc', nn.Linear(self.original_embedding_dim, representation_size)),\n",
        "                    ('act', nn.Tanh())\n",
        "                ]))\n",
        "            else:\n",
        "                self.pre_logits = nn.Identity()\n",
        "            \n",
        "            # automatcially get the intermediate shape\n",
        "            f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim)\n",
        "            num_patches = f_dim * t_dim\n",
        "            self.v.patch_embed.num_patches = num_patches\n",
        "            if verbose == True:\n",
        "                print('frequncey stride={:d}, time stride={:d}'.format(fstride, tstride))\n",
        "                print('number of patches={:d}'.format(num_patches))\n",
        "\n",
        "            # the linear projection layer\n",
        "            new_proj = torch.nn.Conv2d(1, self.original_embedding_dim, kernel_size=(16, 16), stride=(fstride, tstride))\n",
        "            if imagenet_pretrain == True:\n",
        "                new_proj.weight = torch.nn.Parameter(torch.sum(self.v.patch_embed.proj.weight, dim=1).unsqueeze(1))\n",
        "                new_proj.bias = self.v.patch_embed.proj.bias\n",
        "            self.v.patch_embed.proj = new_proj\n",
        "\n",
        "            # the positional embedding\n",
        "            if imagenet_pretrain == True:\n",
        "                # get the positional embedding from deit model, skip the first two tokens (cls token and distillation token), reshape it to original 2D shape (24*24).\n",
        "                new_pos_embed = self.v.pos_embed[:, 2:, :].detach().reshape(1, self.original_num_patches, self.original_embedding_dim).transpose(1, 2).reshape(1, self.original_embedding_dim, self.oringal_hw, self.oringal_hw)\n",
        "                # cut (from middle) or interpolate the second dimension of the positional embedding\n",
        "                if t_dim <= self.oringal_hw:\n",
        "                    new_pos_embed = new_pos_embed[:, :, :, int(self.oringal_hw / 2) - int(t_dim / 2): int(self.oringal_hw / 2) - int(t_dim / 2) + t_dim]\n",
        "                else:\n",
        "                    new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(self.oringal_hw, t_dim), mode='bilinear')\n",
        "                # cut (from middle) or interpolate the first dimension of the positional embedding\n",
        "                if f_dim <= self.oringal_hw:\n",
        "                    new_pos_embed = new_pos_embed[:, :, int(self.oringal_hw / 2) - int(f_dim / 2): int(self.oringal_hw / 2) - int(f_dim / 2) + f_dim, :]\n",
        "                else:\n",
        "                    new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(f_dim, t_dim), mode='bilinear')\n",
        "                # flatten the positional embedding\n",
        "                new_pos_embed = new_pos_embed.reshape(1, self.original_embedding_dim, num_patches).transpose(1,2)\n",
        "                # concatenate the above positional embedding with the cls token and distillation token of the deit model.\n",
        "                self.v.pos_embed = nn.Parameter(torch.cat([self.v.pos_embed[:, :2, :].detach(), new_pos_embed], dim=1))\n",
        "            else:\n",
        "                # if not use imagenet pretrained model, just randomly initialize a learnable positional embedding\n",
        "                # TODO can use sinusoidal positional embedding instead\n",
        "                new_pos_embed = nn.Parameter(torch.zeros(1, self.v.patch_embed.num_patches + 2, self.original_embedding_dim))\n",
        "                self.v.pos_embed = new_pos_embed\n",
        "                trunc_normal_(self.v.pos_embed, std=.02)\n",
        "\n",
        "        # now load a model that is pretrained on both ImageNet and AudioSet\n",
        "        elif audioset_pretrain == True:\n",
        "            if audioset_pretrain == True and imagenet_pretrain == False:\n",
        "                raise ValueError('currently model pretrained on only audioset is not supported, please set imagenet_pretrain = True to use audioset pretrained model.')\n",
        "            if model_size != 'base384':\n",
        "                raise ValueError('currently only has base384 AudioSet pretrained model.')\n",
        "            if os.path.exists('ast/pretrained_models/audioset_10_10_0.4593.pth') == False:\n",
        "                # this model performs 0.4593 mAP on the audioset eval set\n",
        "                audioset_mdl_url = 'https://www.dropbox.com/s/cv4knew8mvbrnvq/audioset_0.4593.pth?dl=1'\n",
        "                wget.download(audioset_mdl_url, out='ast/pretrained_models/audioset_10_10_0.4593.pth')\n",
        "            sd = torch.load('ast/pretrained_models/audioset_10_10_0.4593.pth')\n",
        "            audio_model = ASTModel(representation_size, fstride=10, tstride=10, input_fdim=128, input_tdim=1024, imagenet_pretrain=False, audioset_pretrain=False, model_size='base384', verbose=False)\n",
        "            audio_model = torch.nn.DataParallel(audio_model)\n",
        "            audio_model.load_state_dict(sd, strict=False)\n",
        "            self.v = audio_model.module.v\n",
        "            self.original_embedding_dim = self.v.pos_embed.shape[2]\n",
        "            # self.pooling_layer = nn.LayerNorm(self.original_embedding_dim)\n",
        "            # original bert do max/mean pooling, idk why author use layernorm?\n",
        "            self.pooling_layer = Reduce('b n e -> b e', reduction='mean')\n",
        "            if representation_size:\n",
        "                self.pre_logits = nn.Sequential(OrderedDict([\n",
        "                    ('fc', nn.Linear(self.original_embedding_dim, representation_size)),\n",
        "                    ('act', nn.Tanh())\n",
        "                ]))\n",
        "            else:\n",
        "                self.pre_logits = nn.Identity()\n",
        "\n",
        "            f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim)\n",
        "            num_patches = f_dim * t_dim\n",
        "            self.v.patch_embed.num_patches = num_patches\n",
        "            if verbose == True:\n",
        "                print('frequncey stride={:d}, time stride={:d}'.format(fstride, tstride))\n",
        "                print('number of patches={:d}'.format(num_patches))\n",
        "\n",
        "            new_pos_embed = self.v.pos_embed[:, 2:, :].detach().reshape(1, 1212, 768).transpose(1, 2).reshape(1, 768, 12, 101)\n",
        "            # if the input sequence length is larger than the original audioset (10s), then cut the positional embedding\n",
        "            if t_dim < 101:\n",
        "                new_pos_embed = new_pos_embed[:, :, :, 50 - int(t_dim/2): 50 - int(t_dim/2) + t_dim]\n",
        "            # otherwise interpolate\n",
        "            else:\n",
        "                new_pos_embed = torch.nn.functional.interpolate(new_pos_embed, size=(12, t_dim), mode='bilinear')\n",
        "            new_pos_embed = new_pos_embed.reshape(1, 768, num_patches).transpose(1, 2)\n",
        "            self.v.pos_embed = nn.Parameter(torch.cat([self.v.pos_embed[:, :2, :].detach(), new_pos_embed], dim=1))\n",
        "\n",
        "        # Convert modulelist to sequential\n",
        "        self.v.blocks = nn.Sequential(*self.v.blocks)\n",
        "        self.output_size = representation_size or self.original_embedding_dim\n",
        "\n",
        "    def get_shape(self, fstride, tstride, input_fdim=128, input_tdim=1024):\n",
        "        test_input = torch.randn(1, 1, input_fdim, input_tdim)\n",
        "        test_proj = nn.Conv2d(1, self.original_embedding_dim, kernel_size=(16, 16), stride=(fstride, tstride))\n",
        "        test_out = test_proj(test_input)\n",
        "        f_dim = test_out.shape[2]\n",
        "        t_dim = test_out.shape[3]\n",
        "        return f_dim, t_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x: the input spectrogram, expected shape: (batch_size, num_channel (alway 1), frequency_bins, time_frame_num), e.g., (12, 1, 128, 1024)\n",
        "        :return: prediction\n",
        "        \"\"\"\n",
        "        # expect input x = (batch_size, num_channel (alway 1), frequency_bins, time_frame_num), e.g., (12, 1, 128, 1024)\n",
        "        x = self.v.patch_embed(x)\n",
        "        cls_tokens = self.v.cls_token.expand(x.shape[0], -1, -1)\n",
        "        dist_token = self.v.dist_token.expand(x.shape[0], -1, -1)\n",
        "        x = torch.cat((cls_tokens, dist_token, x), dim=1)\n",
        "        x = x + self.v.pos_embed\n",
        "        x = self.v.pos_drop(x)\n",
        "        x = self.v.blocks(x)\n",
        "        x = self.v.norm(x)[:,0:2]\n",
        "        x = self.pooling_layer(x)\n",
        "        x = self.pre_logits(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def num_filters(self):\n",
        "        return self.output_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Je1YJibDQ99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98fbbe76-531a-4284-fb04-59b18a2e9d83"
      },
      "source": [
        "ast_mdl = ASTModel(representation_size=None, \\\n",
        "                   fstride=10, tstride=10, \\\n",
        "                   input_fdim=128, input_tdim=1024, \\\n",
        "                   audioset_pretrain=True, \\\n",
        "                   model_size='base384')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------AST Model Summary---------------\n",
            "ImageNet pretraining: True, AudioSet pretraining: True\n",
            "frequncey stride=10, time stride=10\n",
            "number of patches=1212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/long/anaconda3/envs/cuda-38/lib/python3.8/site-packages/torch/nn/functional.py:3609: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  warnings.warn(\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ-sePwC7BDh"
      },
      "source": [
        "# Lightning module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGMCT2ocfb9A"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt9IviIkfqt7"
      },
      "source": [
        "from pytorch_lightning.callbacks import Callback, LearningRateMonitor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuxxKOO_FCaj",
        "cellView": "form"
      },
      "source": [
        "#@markdown Upload lightning_logs folder to gdrive (**depricated** since we're using Neptune logger)\n",
        "\n",
        "class BackupCallback(Callback):\n",
        "    def _backup(self):\n",
        "        os.system(f\"zip -r ./tmp_lightning_logs_{experiment_id}.zip ./lightning_logs\")\n",
        "        try:\n",
        "            drive.Upload(f\"tmp_lightning_logs_{experiment_id}.zip\", model_zoo)\n",
        "        except:\n",
        "            print(\"Upload failed.\")\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        if (trainer.current_epoch+1)%20 == 0:\n",
        "            self._backup()\n",
        "            print(f\"Lightning logs backuped at epoch {trainer.current_epoch}.\")\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        self._backup()\n",
        "        print(f\"Lightning logs backuped at the end of training.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpxqdHn-3mfP",
        "cellView": "form"
      },
      "source": [
        "#@markdown Helper function: confusion matrix tensor --> Neptune file\n",
        "from neptune.new.types import File\n",
        "\n",
        "def comfmat_to_neptune_html(confmat):\n",
        "    return File.as_html(pd.DataFrame(confmat.cpu().numpy()))\n",
        "\n",
        "def comfmat_to_neptune_img(confmat):\n",
        "    df = pd.DataFrame(confmat.cpu().numpy().astype(int))\n",
        "    plt.close('all')\n",
        "    fig = plt.figure(figsize = (7,7))\n",
        "    fig.add_subplot(sns.heatmap(df, annot=True, cmap=\"YlGnBu\", fmt=\"d\"))\n",
        "    return File.as_image(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1bvgNgkvKzG",
        "cellView": "form"
      },
      "source": [
        "#@markdown Logging metrics to Neptune logger\n",
        "from torchmetrics import Accuracy, MetricCollection, Precision, Recall, ConfusionMatrix, AUROC, AverageMeter\n",
        "\n",
        "class LogMetricsNeptune(Callback):\n",
        "    def __init__(self):\n",
        "        self.metrics = MetricCollection([Accuracy(compute_on_step=False), \n",
        "                                         Precision(compute_on_step=False), \n",
        "                                         Recall(compute_on_step=False), \n",
        "                                         AUROC(num_classes=2, pos_label=1, compute_on_step=False)])\n",
        "        self.comfmat = ConfusionMatrix(num_classes=2, compute_on_step=False)\n",
        "        self.avg_loss = AverageMeter()\n",
        "\n",
        "    def _setup(self, trainer, pl_module, stage=None):\n",
        "        # dunno why setup hook not called when I call trainer.test?\n",
        "        device = pl_module.device\n",
        "        self.metrics.to(device)\n",
        "        self.comfmat.to(device)\n",
        "        self.avg_loss.to(device)\n",
        "\n",
        "    def on_fit_start(self, trainer, pl_module):\n",
        "        self._setup(trainer, pl_module, \"fit\")\n",
        "\n",
        "    def on_test_start(self, trainer, pl_module):\n",
        "        self._setup(trainer, pl_module, \"test\")\n",
        "\n",
        "    # def on_pretrain_routine_start(self, trainer, pl_module):\n",
        "    #     device = pl_module.device\n",
        "    #     self.metrics = MetricCollection([Accuracy(compute_on_step=False), \n",
        "    #                                      Precision(compute_on_step=False), \n",
        "    #                                      Recall(compute_on_step=False), \n",
        "    #                                      AUC(reorder=True, compute_on_step=False)]).to(device)\n",
        "    #     self.comfmat = ConfusionMatrix(num_classes=2, compute_on_step=False).to(device)\n",
        "    #     self.avg_loss = AverageMeter().to(device)\n",
        "\n",
        "    def _update_metrics(self, **kwargs):\n",
        "        # Prevent autocast since sometime it turn y to float, cause metric raise error...\n",
        "        probs = kwargs['probs']\n",
        "        targets = kwargs['targets']\n",
        "        loss = kwargs['loss']\n",
        "        with torch.cuda.amp.autocast(False):\n",
        "            self.metrics(probs, targets)\n",
        "            self.comfmat(probs, targets)\n",
        "            self.avg_loss(loss)\n",
        "\n",
        "\n",
        "    def _log_metrics(self, trainer, type: str):\n",
        "        comfmat_file = comfmat_to_neptune_img(self.comfmat.compute())\n",
        "        \n",
        "        if trainer.logger is None:\n",
        "            return\n",
        "        # Catch exception from stopped logger\n",
        "        try:\n",
        "            # Log confusion matrix\n",
        "            trainer.logger.experiment[f'comfmat/{type}/latest'].upload(comfmat_file)\n",
        "            trainer.logger.experiment[f'comfmat/{type}/series'].log(comfmat_file)\n",
        "            \n",
        "            # Log metrics\n",
        "            trainer.logger.experiment[f'metrics/{type}/loss'].log(self.avg_loss.compute())\n",
        "            for key, value in self.metrics.compute().items():\n",
        "                trainer.logger.experiment[f'metrics/{type}/{key}'].log(value)\n",
        "        except Exception as e:\n",
        "            if type(e).__name__ == \"InactiveRunException\":\n",
        "                print(\"Warning: Neptune logger has stopped running. Logging couldn't be done.\")\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "\n",
        "    def _print_metrics(self):\n",
        "        print(\"Loss: \", self.avg_loss.compute().item())\n",
        "        for key, value in self.metrics.compute().items():\n",
        "            print(f\"{key}: {value}\")\n",
        "        \n",
        "\n",
        "    def _reset_metrics(self):\n",
        "        self.comfmat.reset()\n",
        "        self.metrics.reset()\n",
        "        self.avg_loss.reset()\n",
        "\n",
        "\n",
        "    def on_train_batch_end(self, trainer, pl_module, \n",
        "                           outputs, batch, batch_idx, dataloader_idx):\n",
        "        self._update_metrics(probs=outputs[\"probs\"], targets=outputs[\"targets\"], loss=outputs[\"loss\"])\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        self._log_metrics(trainer, \"train\")\n",
        "        self._reset_metrics()\n",
        "\n",
        "    def on_validation_batch_end(self, trainer, pl_module, \n",
        "                           outputs, batch, batch_idx, dataloader_idx):\n",
        "        self._update_metrics(probs=outputs[\"probs\"], targets=outputs[\"targets\"], loss=outputs[\"loss\"])\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        self._log_metrics(trainer, \"val\")\n",
        "        self._reset_metrics()\n",
        "\n",
        "    def on_test_batch_end(self, trainer, pl_module, \n",
        "                           outputs, batch, batch_idx, dataloader_idx):\n",
        "        self._update_metrics(probs=outputs[\"probs\"], targets=outputs[\"targets\"], loss=outputs[\"loss\"])\n",
        "\n",
        "    def on_test_epoch_end(self, trainer, pl_module):\n",
        "        self._log_metrics(trainer, \"test\")\n",
        "        self._print_metrics()\n",
        "        self._reset_metrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mtpjC95X1Io",
        "cellView": "form"
      },
      "source": [
        "#@markdown Save last checkpoint to Neptune logger\n",
        "import glob\n",
        "\n",
        "class SaveCheckpointNeptune(Callback):\n",
        "    def __init__(self, interval: int=1):\n",
        "        self.interval = interval\n",
        "\n",
        "\n",
        "    def _upload_latest_ckp(self, trainer):\n",
        "        if trainer.logger is None:\n",
        "            return\n",
        "        try:\n",
        "            ckp_dir = \"/\".join([trainer.default_root_dir, trainer.logger.name, trainer.logger.version])\n",
        "            ckp_file = glob.glob(ckp_dir+\"/checkpoints/*.ckpt\")[0]\n",
        "            trainer.logger.experiment[f'checkpoints/latest'].upload(ckp_file)\n",
        "            print(f\"{trainer.current_epoch} epoch backuped: {ckp_file}\")\n",
        "        except Exception as e:\n",
        "            if type(e).__name__ == \"InactiveRunException\":\n",
        "                print(\"Warning: Neptune logger has stopped running. Logging couldn't be done.\")\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        if trainer.current_epoch%self.interval != 0 or trainer.current_epoch == 0:\n",
        "            return\n",
        "        self._upload_latest_ckp(trainer)\n",
        "\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        self._upload_latest_ckp(trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OrjbSG6qfnN"
      },
      "source": [
        "## Main module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJggwl5C2OpG"
      },
      "source": [
        "class AICOVIDModule(pl.LightningModule):\n",
        "    def __init__(self, model: nn.Module, \n",
        "                 optim_config: dict,\n",
        "                 task_weight: Union[Tuple[float, Optional[float]], Tuple[float, Optional[float], Optional[float]]]=(1.,1.),\n",
        "                 augment=None):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.model = model\n",
        "        self.augment = augment\n",
        "        self.optim_config = optim_config\n",
        "\n",
        "        # Multi-task heads and losses\n",
        "        try:\n",
        "            num_filters = model.num_filters\n",
        "        except:\n",
        "            raise KeyError(\"Model must have a property named `num_filters` that return the output size of model.\")\n",
        "\n",
        "        # Predict covid task\n",
        "        self.covid_head = nn.Linear(num_filters, 1)\n",
        "        \n",
        "        # Predict gender task\n",
        "        self.gender_head = nn.Linear(num_filters, 2)\n",
        "\n",
        "        # Predict smoker, insomnia, 9 cols from medical, 13 cols from symptom\n",
        "        self.multilabel = nn.Linear(num_filters, 24)\n",
        "        \n",
        "        reduction = optim_config['reduction']\n",
        "        self.covid_loss = nn.BCEWithLogitsLoss(reduction=reduction)\n",
        "        self.gender_loss = nn.CrossEntropyLoss(reduction=reduction)\n",
        "        self.multilabel_loss = nn.BCEWithLogitsLoss(reduction=reduction)\n",
        "\n",
        "        if len(task_weight) == 2:\n",
        "            self.covid_alpha, t = task_weight\n",
        "            self.gender_alpha = t\n",
        "            self.multilabel_alpha = t\n",
        "        else:\n",
        "            self.covid_alpha, self.gender_alpha, self.multilabel_alpha = task_weight\n",
        "\n",
        "\n",
        "    ################################################\n",
        "    # For inference/training forward\n",
        "    ################################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Do a forward pass for training/validating, perform feature extract\n",
        "        '''\n",
        "        return self.model(x)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx: int , dataloader_idx: int = None):\n",
        "        '''\n",
        "        Do inference\n",
        "        '''\n",
        "        y_hat = self(batch)\n",
        "        y_hat = self.covid_head(y_hat)\n",
        "        y_hat = torch.sigmoid_(y_hat).squeeze(-1)\n",
        "        \n",
        "        # N·∫øu mu·ªën l·∫•y class th√¨ t·ª± implement, predict_step ch·ªâ n√™n tr·∫£ v·ªÅ prob\n",
        "        \n",
        "        return y_hat\n",
        "\n",
        "\n",
        "    ################################################\n",
        "    # Main function for train/val/test\n",
        "    ################################################\n",
        "    \n",
        "    def loss_fn(self, feats, covid_labels, sex_labels, multilabels):\n",
        "        '''\n",
        "        Calculate loss ~manually since we need to handle autocast~\n",
        "        '''\n",
        "        logit = self.covid_head(feats).squeeze(-1)\n",
        "        covid_loss = self.covid_loss(logit, covid_labels.float())\n",
        "\n",
        "        if self.gender_alpha:\n",
        "            logit = self.gender_head(feats)\n",
        "            gender_loss = self.gender_loss(logit, sex_labels.long())\n",
        "        else:\n",
        "            gender_loss = 0\n",
        "\n",
        "        if self.multilabel_alpha:\n",
        "            # since some samples doesnt have medical metadata, we need to filter out those samples\n",
        "            nonNA_slice = ~torch.any(multilabels.isnan(), dim=-1)\n",
        "            if nonNA_slice.sum() != 0:\n",
        "                logit = self.multilabel(feats)\n",
        "                multilabel_loss = self.multilabel_loss(logit[nonNA_slice], multilabels[nonNA_slice].float())\n",
        "            else:\n",
        "                multilabel_loss = 0\n",
        "        else:\n",
        "            multilabel_loss = 0\n",
        "\n",
        "        loss = self.covid_alpha * covid_loss + self.gender_alpha * gender_loss + self.multilabel_alpha * multilabel_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def _shared_step(self, xs, y_covids, y_sexs, y_multilabels):\n",
        "        '''\n",
        "        Shared step that happened in both train/val step\n",
        "        '''\n",
        "        feats = self(xs)\n",
        "\n",
        "        # sum of multitask loss for a tensor of size (batch x n_output)\n",
        "        loss = self.loss_fn(feats, y_covids, y_sexs, y_multilabels)\n",
        "        \n",
        "        # take logit from covid predict head (main task)\n",
        "        logits = self.covid_head(feats).squeeze(-1)\n",
        "\n",
        "        return loss, logits\n",
        "\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        x, y_covid, y_sex, y_multilabel = train_batch\n",
        "        if self.augment:\n",
        "            x = self.augment(x)\n",
        "        loss, logits = self._shared_step(x, y_covid, y_sex, y_multilabel)\n",
        "        self.log('train/loss_step', loss, on_step=True)        \n",
        "        return {'loss': loss, 'probs': logits.detach(), \"targets\": y_covid}\n",
        "\n",
        "    \n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        x, y_covid, y_sex, y_multilabel = val_batch\n",
        "        loss, logits = self._shared_step(x, y_covid, y_sex, y_multilabel)\n",
        "        return {'loss': loss, 'probs': logits, \"targets\": y_covid}\n",
        "\n",
        "    \n",
        "    def test_step(self, test_batch, batch_idx):\n",
        "        x, y_covid, y_sex, y_multilabel = test_batch\n",
        "        loss, logits = self._shared_step(x, y_covid, y_sex, y_multilabel)\n",
        "        return {'loss': loss, 'probs': logits, \"targets\": y_covid}\n",
        "\n",
        "\n",
        "    ################################################\n",
        "    # Optimizer configuration\n",
        "    ################################################\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = self.optim_config['optimizer']\n",
        "        lr = self.optim_config['lr']\n",
        "        lrschedule = self.optim_config['scheduler']\n",
        "\n",
        "        ### SET OPTIMIZER\n",
        "\n",
        "        if optimizer['type'] == 'Adam':\n",
        "            self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "        elif optimizer['type'] == 'SGD':\n",
        "            self.optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
        "        else:\n",
        "            raise ValueError(f\"Optimizer not implemented: {optimizer}\")\n",
        "\n",
        "        # Total number of gradient calculations\n",
        "        if isinstance(self.trainer.accumulate_grad_batches, dict):\n",
        "            step_per_epoch = len(self.train_dataloader())\n",
        "            \n",
        "\n",
        "            last_epoch = 0\n",
        "            last_accum = self.trainer.accumulate_grad_batches[0]\n",
        "\n",
        "            grad_update_step = 0\n",
        "\n",
        "            for e, a in sorted(self.trainer.accumulate_grad_batches.items()):\n",
        "                interval = e - last_epoch\n",
        "                grad_update_step += math.ceil(step_per_epoch/last_accum)*interval\n",
        "\n",
        "                last_epoch = e\n",
        "                last_accum = a\n",
        "\n",
        "            interval = self.trainer.max_epochs - last_epoch\n",
        "            grad_update_step += math.ceil(step_per_epoch/last_accum)*interval\n",
        "        else:\n",
        "            grad_update_step = math.ceil( len(self.train_dataloader()) / self.trainer.accumulate_grad_batches ) * self.trainer.max_epochs\n",
        "\n",
        "        ### SET SCHEDULER\n",
        "        \n",
        "        if lrschedule['type'] == \"OneCycleLR\":\n",
        "            # OneCycleLR\n",
        "            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, max_lr=lr, \n",
        "                                                             total_steps=grad_update_step,)\n",
        "        elif lrschedule['type'] == \"CosineAnnealingLR\":\n",
        "            # CosineAnnealing per 10 epoch\n",
        "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=int(10*grad_update_step/self.trainer.max_epochs))\n",
        "        elif lrschedule['type'] == \"None\":\n",
        "            # Set constant scheduler to prevent\n",
        "            self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=lambda epoch: lr)\n",
        "        else:\n",
        "            raise ValueError(f\"Scheduler not implemented: {lrschedule}\")\n",
        "\n",
        "        ### COMPLETE SETUP\n",
        "\n",
        "        if self.scheduler:\n",
        "            sched = {\n",
        "                'scheduler': self.scheduler,\n",
        "                'interval': 'step'\n",
        "            }\n",
        "            return [self.optimizer], [sched]\n",
        "        else:\n",
        "            return self.optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl4ARbbJ7M-A"
      },
      "source": [
        "# Trainer params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "A6ouAXvOHxbd"
      },
      "source": [
        "#@markdown Make a Neptune logger instance `logger(name)`\n",
        "\n",
        "# from pytorch_lightning.loggers import NeptuneLogger\n",
        "\n",
        "# logger = lambda ver: NeptuneLogger(\n",
        "#     api_key=api_token,\n",
        "#     project_name='vulong61/AICOVID', \n",
        "#     experiment_name=f'{experiment_id}_{ver}',  # Optional\n",
        "# )\n",
        "\n",
        "#-------------New from neptune-----------------\n",
        "\n",
        "from neptune.new.integrations.pytorch_lightning import NeptuneLogger\n",
        "\n",
        "logger = lambda ver: NeptuneLogger(\n",
        "    api_key=api_token,\n",
        "    project='vulong61/AICOVID', \n",
        "    name=f'{experiment_id}_{ver}',  # Optional\n",
        "    tags=[],\n",
        "    close_after_fit=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzBCX9xE7OqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "f982672b-65f9-4c6b-bc36-d0bb1dc5b225"
      },
      "source": [
        "#@title Trainer params\n",
        "mixed_precision = True #@param {type:\"boolean\"}\n",
        "swa = False #@param {type:\"boolean\"}\n",
        "max_epochs = 15 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Dataloader params\n",
        "batch_size =  3#@param {type:\"integer\"}\n",
        "grad_accum =  {1: 4, 3: 16, 6: 32, 10: 64}#@param {type:\"raw\"}\n",
        "\n",
        "#@markdown Logger name on Neptune.AI\n",
        "logger_exp_name = \"exp007\" #@param {type:\"string\"}\n",
        "check_point_interval = 5 #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "default_root_dir = \"./checkpoints\"\n",
        "\n",
        "trainer_params = {\n",
        "    \"gpus\": 1,\n",
        "    \"precision\": 16 if mixed_precision else 32,\n",
        "    \"max_epochs\": max_epochs,\n",
        "    \"progress_bar_refresh_rate\": 10,\n",
        "    \"accumulate_grad_batches\": grad_accum,\n",
        "    \"stochastic_weight_avg\": swa,\n",
        "\n",
        "    \"callbacks\": [LogMetricsNeptune(),\n",
        "                  LearningRateMonitor(\"step\"),\n",
        "                  SaveCheckpointNeptune(check_point_interval)],\n",
        "\n",
        "    # flag for debugging\n",
        "    # \"track_grad_norm\": 2, the model is so deep that half of the running time is just for logging this\n",
        "    \"terminate_on_nan\": True,\n",
        "    \"weights_summary\": 'full',\n",
        "    \"log_every_n_steps\": 2,\n",
        "    \"default_root_dir\": default_root_dir,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/long/anaconda3/envs/cuda-38/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3yQrcjYYtCeV"
      },
      "source": [
        "#@title Optimizer params\n",
        "lr = 0.0005 #@param {type:\"number\"}\n",
        "optimizer = \"SGD\" #@param [\"SGD\", \"Adam\"]\n",
        "scheduler = \"OneCycleLR\" #@param [\"OneCycleLR\", \"CosineAnnealingLR\", \"None\"]\n",
        "reduction = \"mean\" #@param [\"sum\", \"mean\", \"none\"]\n",
        "optim_config = {\n",
        "    'optimizer': {\"type\": optimizer,\n",
        "                  \"kawrgs\": None},\n",
        "    'scheduler': {\"type\": scheduler,\n",
        "                  \"kawrgs\": None},\n",
        "    'lr': lr,\n",
        "    'reduction': reduction,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kOPNwZBmUX7"
      },
      "source": [
        "# Experiment - Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQHx9xzlRk6R"
      },
      "source": [
        "## Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqpTaQ4jsNAn"
      },
      "source": [
        "log_melspec_transform = nn.Sequential(mel_spectrogram,\n",
        "                                      log_spectrogram)\n",
        "\n",
        "transform0 = nn.Sequential(log_melspec_transform).cuda()\n",
        "transform1 = nn.Sequential(NoiseInject([noise.cuda()], 8),\n",
        "                           log_melspec_transform).cuda()\n",
        "transform2 = nn.Sequential(NoiseInject([noise.cuda()], 16),\n",
        "                           log_melspec_transform).cuda()\n",
        "transform3 = nn.Sequential(RoomReverb([rir.cuda()]), \n",
        "                           NoiseInject([noise.cuda()], 8), \n",
        "                           PhoneSim(),\n",
        "                           log_melspec_transform).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeEpNXQR7QP6"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8JLBFqDhtfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa12f70f-61e4-4f9c-fd04-79c2e9525069"
      },
      "source": [
        "# train_set = AICOVIDDataset('f_pub_train', torch.nn.ModuleList([transform0]), normalize='ast', chunking=(400, 200), val_split=False, split_ratio=val_split, cleanup_after=False)\n",
        "train_set = AICOVIDDataset('f_pub_train', torch.nn.ModuleList([transform0]), normalize='ast', val_split=False, split_ratio=val_split, cleanup_after=False)\n",
        "scaler = StandardScaler(train_set.mean, train_set.std, 0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Archive have already downloaded\n",
            "\n",
            "> Extract complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_21443/2611580008.py:171: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
            "  medical_condition_choice_df = pd.get_dummies(meta['medical_condition_choice'].apply(pd.Series).stack()).sum(level=0)\n",
            "/tmp/ipykernel_21443/2611580008.py:173: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
            "  symptoms_status_choice_df = pd.get_dummies(meta['symptoms_status_choice'].apply(pd.Series).stack()).sum(level=0)\n",
            "\n",
            "  0%|                                                  | 0/3603 [00:00<?, ?it/s]\u001b[A\n",
            "  0%|                                          | 1/3603 [00:00<59:36,  1.01it/s]\u001b[A\n",
            "  0%|‚ñè                                        | 14/3603 [00:01<03:29, 17.11it/s]\u001b[A\n",
            "  1%|‚ñé                                        | 28/3603 [00:01<01:40, 35.51it/s]\u001b[A\n",
            "  1%|‚ñç                                        | 40/3603 [00:01<01:10, 50.42it/s]\u001b[A\n",
            "  2%|‚ñã                                        | 56/3603 [00:01<00:49, 71.88it/s]\u001b[A\n",
            "  2%|‚ñä                                        | 69/3603 [00:01<00:43, 81.50it/s]\u001b[A\n",
            "  2%|‚ñâ                                        | 85/3603 [00:01<00:36, 97.14it/s]\u001b[A\n",
            "  3%|‚ñà                                       | 99/3603 [00:01<00:32, 107.08it/s]\u001b[A\n",
            "  3%|‚ñà‚ñè                                     | 113/3603 [00:01<00:31, 112.39it/s]\u001b[A\n",
            "  4%|‚ñà‚ñç                                     | 129/3603 [00:01<00:27, 124.38it/s]\u001b[A\n",
            "  4%|‚ñà‚ñå                                     | 143/3603 [00:02<00:28, 121.06it/s]\u001b[A\n",
            "  4%|‚ñà‚ñã                                     | 157/3603 [00:02<00:28, 121.55it/s]\u001b[A\n",
            "  5%|‚ñà‚ñä                                     | 170/3603 [00:02<00:28, 122.10it/s]\u001b[A\n",
            "  5%|‚ñà‚ñâ                                     | 183/3603 [00:02<00:28, 121.87it/s]\u001b[A\n",
            "  5%|‚ñà‚ñà                                     | 196/3603 [00:02<00:27, 122.77it/s]\u001b[A\n",
            "  6%|‚ñà‚ñà‚ñé                                    | 211/3603 [00:02<00:26, 127.40it/s]\u001b[A\n",
            "  6%|‚ñà‚ñà‚ñç                                    | 224/3603 [00:02<00:27, 122.76it/s]\u001b[A\n",
            "  7%|‚ñà‚ñà‚ñå                                    | 237/3603 [00:02<00:29, 114.67it/s]\u001b[A\n",
            "  7%|‚ñà‚ñà‚ñã                                    | 250/3603 [00:02<00:28, 116.97it/s]\u001b[A\n",
            "  7%|‚ñà‚ñà‚ñä                                    | 262/3603 [00:03<00:30, 108.81it/s]\u001b[A\n",
            "  8%|‚ñà‚ñà‚ñâ                                    | 275/3603 [00:03<00:29, 114.11it/s]\u001b[A\n",
            "  8%|‚ñà‚ñà‚ñà                                    | 287/3603 [00:03<00:29, 113.57it/s]\u001b[A\n",
            "  8%|‚ñà‚ñà‚ñà‚ñè                                   | 299/3603 [00:03<00:30, 107.41it/s]\u001b[A\n",
            "  9%|‚ñà‚ñà‚ñà‚ñç                                   | 315/3603 [00:03<00:27, 121.38it/s]\u001b[A\n",
            "  9%|‚ñà‚ñà‚ñà‚ñå                                   | 331/3603 [00:03<00:25, 129.39it/s]\u001b[A\n",
            " 10%|‚ñà‚ñà‚ñà‚ñã                                   | 346/3603 [00:03<00:24, 134.18it/s]\u001b[A\n",
            " 10%|‚ñà‚ñà‚ñà‚ñâ                                   | 360/3603 [00:03<00:25, 129.41it/s]\u001b[A\n",
            " 10%|‚ñà‚ñà‚ñà‚ñà                                   | 374/3603 [00:03<00:26, 122.69it/s]\u001b[A\n",
            " 11%|‚ñà‚ñà‚ñà‚ñà‚ñè                                  | 390/3603 [00:04<00:24, 129.06it/s]\u001b[A\n",
            " 11%|‚ñà‚ñà‚ñà‚ñà‚ñé                                  | 404/3603 [00:04<00:27, 117.32it/s]\u001b[A\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 417/3603 [00:04<00:28, 111.49it/s]\u001b[A\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñã                                  | 429/3603 [00:04<00:28, 111.86it/s]\u001b[A\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñä                                  | 441/3603 [00:04<00:28, 112.14it/s]\u001b[A\n",
            " 13%|‚ñà‚ñà‚ñà‚ñà‚ñâ                                  | 453/3603 [00:04<00:27, 113.71it/s]\u001b[A\n",
            " 13%|‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 465/3603 [00:04<00:27, 113.04it/s]\u001b[A\n",
            " 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 477/3603 [00:04<00:29, 107.62it/s]\u001b[A\n",
            " 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                 | 488/3603 [00:05<00:30, 103.38it/s]\u001b[A\n",
            " 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 501/3603 [00:05<00:28, 109.77it/s]\u001b[A\n",
            " 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 516/3603 [00:05<00:25, 119.04it/s]\u001b[A\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 529/3603 [00:05<00:26, 117.40it/s]\u001b[A\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                                 | 545/3603 [00:05<00:23, 128.13it/s]\u001b[A\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 558/3603 [00:05<00:24, 125.36it/s]\u001b[A\n",
            " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 575/3603 [00:05<00:22, 136.88it/s]\u001b[A\n",
            " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                | 589/3603 [00:05<00:22, 132.49it/s]\u001b[A\n",
            " 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                | 603/3603 [00:05<00:24, 122.57it/s]\u001b[A\n",
            " 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 616/3603 [00:06<00:25, 117.14it/s]\u001b[A\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 632/3603 [00:06<00:23, 126.87it/s]\u001b[A\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                | 647/3603 [00:06<00:22, 131.38it/s]\u001b[A\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 662/3603 [00:06<00:22, 133.38it/s]\u001b[A\n",
            " 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                               | 676/3603 [00:06<00:22, 132.03it/s]\u001b[A\n",
            " 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                               | 691/3603 [00:06<00:21, 136.54it/s]\u001b[A\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 708/3603 [00:06<00:19, 144.78it/s]\u001b[A\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                               | 723/3603 [00:06<00:20, 143.72it/s]\u001b[A\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                               | 738/3603 [00:06<00:21, 134.09it/s]\u001b[A\n",
            " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 752/3603 [00:07<00:22, 127.84it/s]\u001b[A\n",
            " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 765/3603 [00:07<00:23, 118.75it/s]\u001b[A\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                              | 778/3603 [00:07<00:24, 115.21it/s]\u001b[A\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                              | 793/3603 [00:07<00:22, 123.36it/s]\u001b[A\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 808/3603 [00:07<00:21, 130.24it/s]\u001b[A\n",
            " 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 822/3603 [00:07<00:21, 130.00it/s]\u001b[A\n",
            " 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                              | 840/3603 [00:07<00:19, 143.72it/s]\u001b[A\n",
            " 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 855/3603 [00:07<00:19, 139.27it/s]\u001b[A\n",
            " 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 871/3603 [00:07<00:18, 143.85it/s]\u001b[A\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                             | 886/3603 [00:08<00:19, 141.97it/s]\u001b[A\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 901/3603 [00:08<00:19, 141.61it/s]\u001b[A\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 916/3603 [00:08<00:19, 135.35it/s]\u001b[A\n",
            " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                             | 930/3603 [00:08<00:20, 128.64it/s]\u001b[A\n",
            " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 946/3603 [00:08<00:19, 136.80it/s]\u001b[A\n",
            " 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 966/3603 [00:08<00:17, 149.76it/s]\u001b[A\n",
            " 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                            | 982/3603 [00:08<00:18, 139.60it/s]\u001b[A\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                            | 997/3603 [00:08<00:18, 138.98it/s]\u001b[A\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 1012/3603 [00:09<00:21, 118.88it/s]\u001b[A\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 1025/3603 [00:09<00:21, 118.05it/s]\u001b[A\n",
            " 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 1039/3603 [00:09<00:21, 121.27it/s]\u001b[A\n",
            " 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                           | 1052/3603 [00:09<00:21, 118.32it/s]\u001b[A\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                          | 1065/3603 [00:09<00:23, 108.47it/s]\u001b[A\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 1078/3603 [00:09<00:22, 113.51it/s]\u001b[A\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                          | 1091/3603 [00:09<00:21, 115.22it/s]\u001b[A\n",
            " 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 1105/3603 [00:09<00:20, 121.25it/s]\u001b[A\n",
            " 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 1121/3603 [00:09<00:19, 125.91it/s]\u001b[A\n",
            " 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 1134/3603 [00:10<00:20, 119.75it/s]\u001b[A\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 1147/3603 [00:10<00:21, 115.82it/s]\u001b[A\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                         | 1159/3603 [00:10<00:20, 116.41it/s]\u001b[A\n",
            " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 1172/3603 [00:10<00:20, 120.14it/s]\u001b[A\n",
            " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1185/3603 [00:10<00:20, 116.07it/s]\u001b[A\n",
            " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 1197/3603 [00:10<00:21, 113.20it/s]\u001b[A\n",
            " 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 1209/3603 [00:10<00:21, 112.94it/s]\u001b[A\n",
            " 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 1221/3603 [00:10<00:21, 109.96it/s]\u001b[A\n",
            " 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 1233/3603 [00:10<00:21, 112.27it/s]\u001b[A\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 1245/3603 [00:11<00:22, 107.17it/s]\u001b[A\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 1256/3603 [00:11<00:22, 106.28it/s]\u001b[A\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                        | 1267/3603 [00:11<00:22, 105.95it/s]\u001b[A\n",
            " 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                        | 1280/3603 [00:11<00:20, 111.42it/s]\u001b[A\n",
            " 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 1295/3603 [00:11<00:19, 120.87it/s]\u001b[A\n",
            " 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 1308/3603 [00:11<00:18, 121.81it/s]\u001b[A\n",
            " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 1321/3603 [00:11<00:19, 118.13it/s]\u001b[A\n",
            " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 1336/3603 [00:11<00:17, 126.79it/s]\u001b[A\n",
            " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 1349/3603 [00:11<00:18, 121.31it/s]\u001b[A\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 1362/3603 [00:12<00:19, 117.87it/s]\u001b[A\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                       | 1374/3603 [00:12<00:20, 106.94it/s]\u001b[A\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 1387/3603 [00:12<00:20, 110.71it/s]\u001b[A\n",
            " 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 1400/3603 [00:12<00:19, 115.03it/s]\u001b[A\n",
            " 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 1417/3603 [00:12<00:16, 129.24it/s]\u001b[A\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 1432/3603 [00:12<00:16, 133.89it/s]\u001b[A\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 1446/3603 [00:12<00:16, 133.05it/s]\u001b[A\n",
            " 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                      | 1460/3603 [00:12<00:17, 123.84it/s]\u001b[A\n",
            " 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 1474/3603 [00:12<00:17, 123.58it/s]\u001b[A\n",
            " 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 1487/3603 [00:13<00:17, 122.89it/s]\u001b[A\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 1500/3603 [00:13<00:17, 122.28it/s]\u001b[A\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                      | 1517/3603 [00:13<00:15, 133.38it/s]\u001b[A\n",
            " 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 1536/3603 [00:13<00:13, 149.10it/s]\u001b[A\n",
            " 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 1552/3603 [00:13<00:14, 141.27it/s]\u001b[A\n",
            " 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 1569/3603 [00:13<00:13, 148.07it/s]\u001b[A\n",
            " 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                     | 1584/3603 [00:13<00:14, 140.18it/s]\u001b[A\n",
            " 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 1602/3603 [00:13<00:13, 147.23it/s]\u001b[A\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 1623/3603 [00:13<00:12, 159.55it/s]\u001b[A\n",
            " 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                    | 1640/3603 [00:14<00:13, 145.70it/s]\u001b[A\n",
            " 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 1656/3603 [00:14<00:13, 147.30it/s]\u001b[A\n",
            " 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 1672/3603 [00:14<00:13, 147.12it/s]\u001b[A\n",
            " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                    | 1687/3603 [00:14<00:14, 133.26it/s]\u001b[A\n",
            " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 1701/3603 [00:14<00:15, 121.87it/s]\u001b[A\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 1715/3603 [00:14<00:15, 125.80it/s]\u001b[A\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                   | 1728/3603 [00:14<00:15, 124.28it/s]\u001b[A\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 1743/3603 [00:14<00:14, 129.00it/s]\u001b[A\n",
            " 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 1757/3603 [00:15<00:15, 120.99it/s]\u001b[A\n",
            " 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 1770/3603 [00:15<00:15, 120.67it/s]\u001b[A\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 1784/3603 [00:15<00:14, 124.22it/s]\u001b[A\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 1799/3603 [00:15<00:13, 130.31it/s]\u001b[A\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 1814/3603 [00:15<00:13, 135.20it/s]\u001b[A\n",
            " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                  | 1829/3603 [00:15<00:12, 138.62it/s]\u001b[A\n",
            " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 1843/3603 [00:15<00:13, 132.51it/s]\u001b[A\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 1858/3603 [00:15<00:12, 137.30it/s]\u001b[A\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 1872/3603 [00:15<00:13, 132.31it/s]\u001b[A\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                  | 1887/3603 [00:15<00:12, 136.70it/s]\u001b[A\n",
            " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 1901/3603 [00:16<00:13, 128.97it/s]\u001b[A\n",
            " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 1915/3603 [00:16<00:13, 128.18it/s]\u001b[A\n",
            " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 1928/3603 [00:16<00:13, 125.74it/s]\u001b[A\n",
            " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                 | 1941/3603 [00:16<00:13, 123.92it/s]\u001b[A\n",
            " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                 | 1954/3603 [00:16<00:13, 124.37it/s]\u001b[A\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 1967/3603 [00:16<00:13, 121.63it/s]\u001b[A\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 1980/3603 [00:16<00:13, 122.87it/s]\u001b[A\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                 | 1993/3603 [00:16<00:13, 122.45it/s]\u001b[A\n",
            " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 2008/3603 [00:16<00:12, 127.85it/s]\u001b[A\n",
            " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 2023/3603 [00:17<00:11, 132.63it/s]\u001b[A\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                | 2039/3603 [00:17<00:11, 139.22it/s]\u001b[A\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 2055/3603 [00:17<00:10, 143.56it/s]\u001b[A\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 2070/3603 [00:17<00:11, 133.27it/s]\u001b[A\n",
            " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 2084/3603 [00:17<00:11, 127.70it/s]\u001b[A\n",
            " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè               | 2098/3603 [00:17<00:11, 126.37it/s]\u001b[A\n",
            " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 2112/3603 [00:17<00:11, 128.10it/s]\u001b[A\n",
            " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç               | 2125/3603 [00:17<00:11, 126.44it/s]\u001b[A\n",
            " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 2138/3603 [00:17<00:12, 121.10it/s]\u001b[A\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 2151/3603 [00:18<00:12, 113.78it/s]\u001b[A\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä               | 2167/3603 [00:18<00:11, 124.81it/s]\u001b[A\n",
            " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 2180/3603 [00:18<00:11, 125.24it/s]\u001b[A\n",
            " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 2194/3603 [00:18<00:11, 125.09it/s]\u001b[A\n",
            " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 2207/3603 [00:18<00:11, 122.71it/s]\u001b[A\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç              | 2220/3603 [00:18<00:11, 119.48it/s]\u001b[A\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 2235/3603 [00:18<00:10, 127.39it/s]\u001b[A\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã              | 2249/3603 [00:18<00:10, 130.48it/s]\u001b[A\n",
            " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä              | 2263/3603 [00:18<00:10, 128.56it/s]\u001b[A\n",
            " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 2278/3603 [00:19<00:10, 130.77it/s]\u001b[A\n",
            " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 2292/3603 [00:19<00:10, 127.32it/s]\u001b[A\n",
            " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 2307/3603 [00:19<00:09, 133.42it/s]\u001b[A\n",
            " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç             | 2321/3603 [00:19<00:10, 125.88it/s]\u001b[A\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 2334/3603 [00:19<00:10, 120.97it/s]\u001b[A\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä             | 2347/3603 [00:19<00:10, 123.36it/s]\u001b[A\n",
            " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 2362/3603 [00:19<00:09, 128.09it/s]\u001b[A\n",
            " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 2381/3603 [00:19<00:08, 144.81it/s]\u001b[A\n",
            " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 2396/3603 [00:19<00:08, 146.21it/s]\u001b[A\n",
            " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 2411/3603 [00:20<00:09, 128.79it/s]\u001b[A\n",
            " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 2425/3603 [00:20<00:09, 121.66it/s]\u001b[A\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 2440/3603 [00:20<00:09, 128.55it/s]\u001b[A\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 2457/3603 [00:20<00:08, 138.66it/s]\u001b[A\n",
            " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 2472/3603 [00:20<00:07, 141.75it/s]\u001b[A\n",
            " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 2487/3603 [00:20<00:07, 142.28it/s]\u001b[A\n",
            " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 2504/3603 [00:20<00:07, 149.98it/s]\u001b[A\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 2520/3603 [00:20<00:07, 142.54it/s]\u001b[A\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 2535/3603 [00:20<00:07, 134.31it/s]\u001b[A\n",
            " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 2549/3603 [00:21<00:08, 130.15it/s]\u001b[A\n",
            " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 2563/3603 [00:21<00:08, 123.03it/s]\u001b[A\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 2582/3603 [00:21<00:07, 139.84it/s]\u001b[A\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 2598/3603 [00:21<00:06, 144.65it/s]\u001b[A\n",
            " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 2613/3603 [00:21<00:07, 138.76it/s]\u001b[A\n",
            " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 2628/3603 [00:21<00:07, 136.99it/s]\u001b[A\n",
            " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 2645/3603 [00:21<00:06, 144.63it/s]\u001b[A\n",
            " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 2660/3603 [00:21<00:06, 137.64it/s]\u001b[A\n",
            " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 2674/3603 [00:22<00:06, 134.28it/s]\u001b[A\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 2690/3603 [00:22<00:06, 139.57it/s]\u001b[A\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 2705/3603 [00:22<00:06, 133.68it/s]\u001b[A\n",
            " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 2723/3603 [00:22<00:06, 143.41it/s]\u001b[A\n",
            " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 2738/3603 [00:22<00:06, 124.48it/s]\u001b[A\n",
            " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 2751/3603 [00:22<00:07, 117.32it/s]\u001b[A\n",
            " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 2766/3603 [00:22<00:06, 125.30it/s]\u001b[A\n",
            " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 2779/3603 [00:22<00:06, 122.40it/s]\u001b[A\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç        | 2797/3603 [00:22<00:05, 137.70it/s]\u001b[A\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 2814/3603 [00:23<00:05, 141.18it/s]\u001b[A\n",
            " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 2829/3603 [00:23<00:05, 142.52it/s]\u001b[A\n",
            " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 2844/3603 [00:23<00:05, 137.50it/s]\u001b[A\n",
            " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 2858/3603 [00:23<00:05, 131.00it/s]\u001b[A\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 2872/3603 [00:23<00:06, 121.16it/s]\u001b[A\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 2885/3603 [00:23<00:06, 118.89it/s]\u001b[A\n",
            " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã       | 2907/3603 [00:23<00:04, 144.84it/s]\u001b[A\n",
            " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä       | 2922/3603 [00:23<00:05, 135.53it/s]\u001b[A\n",
            " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 2936/3603 [00:23<00:04, 133.96it/s]\u001b[A\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 2950/3603 [00:24<00:04, 131.48it/s]\u001b[A\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 2967/3603 [00:24<00:04, 140.30it/s]\u001b[A\n",
            " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 2982/3603 [00:24<00:04, 140.16it/s]\u001b[A\n",
            " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 2997/3603 [00:24<00:04, 132.68it/s]\u001b[A\n",
            " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä      | 3011/3603 [00:24<00:04, 127.08it/s]\u001b[A\n",
            " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ      | 3027/3603 [00:24<00:04, 133.84it/s]\u001b[A\n",
            " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 3041/3603 [00:24<00:04, 114.88it/s]\u001b[A\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 3058/3603 [00:24<00:04, 127.77it/s]\u001b[A\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 3075/3603 [00:25<00:03, 137.40it/s]\u001b[A\n",
            " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 3090/3603 [00:25<00:03, 139.02it/s]\u001b[A\n",
            " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 3105/3603 [00:25<00:03, 141.48it/s]\u001b[A\n",
            " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 3120/3603 [00:25<00:03, 137.21it/s]\u001b[A\n",
            " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 3134/3603 [00:25<00:04, 110.72it/s]\u001b[A\n",
            " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 3146/3603 [00:25<00:05, 76.36it/s]\u001b[A\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 3156/3603 [00:26<00:06, 71.48it/s]\u001b[A\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 3167/3603 [00:26<00:05, 78.65it/s]\u001b[A\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 3186/3603 [00:26<00:04, 99.65it/s]\u001b[A\n",
            " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 3198/3603 [00:26<00:03, 101.96it/s]\u001b[A\n",
            " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3213/3603 [00:26<00:03, 112.44it/s]\u001b[A\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3226/3603 [00:26<00:03, 114.15it/s]\u001b[A\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 3241/3603 [00:26<00:02, 122.45it/s]\u001b[A\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 3256/3603 [00:26<00:02, 129.71it/s]\u001b[A\n",
            " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 3270/3603 [00:26<00:02, 114.35it/s]\u001b[A\n",
            " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 3289/3603 [00:27<00:02, 132.32it/s]\u001b[A\n",
            " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 3304/3603 [00:27<00:02, 135.18it/s]\u001b[A\n",
            " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 3319/3603 [00:27<00:02, 137.98it/s]\u001b[A\n",
            " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 3336/3603 [00:27<00:01, 141.51it/s]\u001b[A\n",
            " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3351/3603 [00:27<00:01, 141.24it/s]\u001b[A\n",
            " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3366/3603 [00:27<00:01, 132.98it/s]\u001b[A\n",
            " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 3380/3603 [00:27<00:01, 134.63it/s]\u001b[A\n",
            " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 3395/3603 [00:27<00:01, 134.96it/s]\u001b[A\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 3409/3603 [00:27<00:01, 135.68it/s]\u001b[A\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 3424/3603 [00:28<00:01, 135.22it/s]\u001b[A\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 3439/3603 [00:28<00:01, 134.67it/s]\u001b[A\n",
            " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 3455/3603 [00:28<00:01, 137.88it/s]\u001b[A\n",
            " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3469/3603 [00:28<00:01, 131.43it/s]\u001b[A\n",
            " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 3484/3603 [00:28<00:00, 131.99it/s]\u001b[A\n",
            " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 3500/3603 [00:28<00:00, 139.33it/s]\u001b[A\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 3515/3603 [00:28<00:00, 133.49it/s]\u001b[A\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 3529/3603 [00:28<00:00, 134.84it/s]\u001b[A\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3547/3603 [00:28<00:00, 147.51it/s]\u001b[A\n",
            " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 3562/3603 [00:29<00:00, 137.49it/s]\u001b[A\n",
            " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 3577/3603 [00:29<00:00, 139.69it/s]\u001b[A\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3603/3603 [00:29<00:00, 123.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> File processing complete\n",
            "\n",
            "> Start normalizing data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|                                                  | 0/3603 [00:00<?, ?it/s]\u001b[A\n",
            "  3%|‚ñà‚ñè                                    | 113/3603 [00:00<00:03, 1128.06it/s]\u001b[A\n",
            "  7%|‚ñà‚ñà‚ñå                                   | 244/3603 [00:00<00:02, 1234.16it/s]\u001b[A\n",
            " 10%|‚ñà‚ñà‚ñà‚ñâ                                  | 368/3603 [00:00<00:02, 1198.96it/s]\u001b[A\n",
            " 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                                | 500/3603 [00:00<00:02, 1244.03it/s]\u001b[A\n",
            " 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 625/3603 [00:00<00:02, 1233.72it/s]\u001b[A\n",
            " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 749/3603 [00:00<00:02, 1202.65it/s]\u001b[A\n",
            " 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                            | 870/3603 [00:00<00:02, 1199.08it/s]\u001b[A\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                           | 992/3603 [00:00<00:02, 1200.94it/s]\u001b[A\n",
            " 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 1119/3603 [00:00<00:02, 1220.89it/s]\u001b[A\n",
            " 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                        | 1242/3603 [00:01<00:01, 1216.65it/s]\u001b[A\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 1364/3603 [00:01<00:01, 1213.76it/s]\u001b[A\n",
            " 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 1486/3603 [00:01<00:01, 1197.05it/s]\u001b[A\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 1606/3603 [00:01<00:01, 1194.15it/s]\u001b[A\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 1729/3603 [00:01<00:01, 1203.48it/s]\u001b[A\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 1856/3603 [00:01<00:01, 1223.18it/s]\u001b[A\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 1980/3603 [00:01<00:01, 1227.33it/s]\u001b[A\n",
            " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã               | 2109/3603 [00:01<00:01, 1244.84it/s]\u001b[A\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 2242/3603 [00:01<00:01, 1269.74it/s]\u001b[A\n",
            " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé            | 2371/3603 [00:01<00:00, 1275.09it/s]\u001b[A\n",
            " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 2499/3603 [00:02<00:00, 1235.34it/s]\u001b[A\n",
            " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 2644/3603 [00:02<00:00, 1297.52it/s]\u001b[A\n",
            " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã        | 2790/3603 [00:02<00:00, 1343.54it/s]\u001b[A\n",
            " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 2930/3603 [00:02<00:00, 1357.32it/s]\u001b[A\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 3068/3603 [00:02<00:00, 1362.49it/s]\u001b[A\n",
            " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 3205/3603 [00:02<00:00, 1319.39it/s]\u001b[A\n",
            " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 3338/3603 [00:02<00:00, 1297.65it/s]\u001b[A\n",
            " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 3469/3603 [00:02<00:00, 1269.58it/s]\u001b[A\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3603/3603 [00:02<00:00, 1247.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Normalizing data complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUAcf5sR7LuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80a8673-56a5-4a96-c4d2-a71995f23cb8"
      },
      "source": [
        "val_set = AICOVIDDataset('f_pub_train', torch.nn.ModuleList([transform0]), normalize=scaler, chunking=(400, 200), val_split=True, split_ratio=val_split, cleanup_after=False)\n",
        "test_set = AICOVIDDataset('f_pub_train', torch.nn.ModuleList([transform0]), normalize=scaler, val_split=True, split_ratio=val_split, cleanup_after=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Archive have already downloaded\n",
            "\n",
            "> Extract complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_21443/2611580008.py:171: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
            "  medical_condition_choice_df = pd.get_dummies(meta['medical_condition_choice'].apply(pd.Series).stack()).sum(level=0)\n",
            "/tmp/ipykernel_21443/2611580008.py:173: FutureWarning: Using the level keyword in DataFrame and Series aggregations is deprecated and will be removed in a future version. Use groupby instead. df.sum(level=1) should use df.groupby(level=1).sum().\n",
            "  symptoms_status_choice_df = pd.get_dummies(meta['symptoms_status_choice'].apply(pd.Series).stack()).sum(level=0)\n",
            "\n",
            "  0%|                                                   | 0/901 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|‚ñã                                        | 14/901 [00:00<00:06, 132.47it/s]\u001b[A\n",
            "  3%|‚ñà‚ñé                                       | 28/901 [00:00<00:07, 117.81it/s]\u001b[A\n",
            "  4%|‚ñà‚ñä                                       | 40/901 [00:00<00:07, 110.01it/s]\u001b[A\n",
            "  6%|‚ñà‚ñà‚ñé                                      | 52/901 [00:00<00:07, 113.16it/s]\u001b[A\n",
            "  7%|‚ñà‚ñà‚ñà                                      | 66/901 [00:00<00:06, 121.42it/s]\u001b[A\n",
            "  9%|‚ñà‚ñà‚ñà‚ñã                                     | 82/901 [00:00<00:06, 132.98it/s]\u001b[A\n",
            " 11%|‚ñà‚ñà‚ñà‚ñà‚ñé                                    | 96/901 [00:00<00:06, 123.75it/s]\u001b[A\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 109/901 [00:00<00:06, 118.91it/s]\u001b[A\n",
            " 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 122/901 [00:01<00:06, 119.00it/s]\u001b[A\n",
            " 15%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 137/901 [00:01<00:06, 122.38it/s]\u001b[A\n",
            " 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 150/901 [00:01<00:06, 122.15it/s]\u001b[A\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 163/901 [00:01<00:06, 119.58it/s]\u001b[A\n",
            " 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 175/901 [00:01<00:06, 114.48it/s]\u001b[A\n",
            " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 192/901 [00:01<00:05, 128.50it/s]\u001b[A\n",
            " 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                               | 205/901 [00:01<00:05, 126.03it/s]\u001b[A\n",
            " 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                              | 218/901 [00:01<00:05, 126.39it/s]\u001b[A\n",
            " 26%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 231/901 [00:01<00:05, 125.08it/s]\u001b[A\n",
            " 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 244/901 [00:01<00:05, 124.08it/s]\u001b[A\n",
            " 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                            | 259/901 [00:02<00:04, 130.96it/s]\u001b[A\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                           | 274/901 [00:02<00:04, 136.41it/s]\u001b[A\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                           | 288/901 [00:02<00:04, 132.62it/s]\u001b[A\n",
            " 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                          | 302/901 [00:02<00:04, 134.33it/s]\u001b[A\n",
            " 35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 316/901 [00:02<00:04, 125.34it/s]\u001b[A\n",
            " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                         | 329/901 [00:02<00:04, 119.74it/s]\u001b[A\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 342/901 [00:02<00:04, 122.03it/s]\u001b[A\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 358/901 [00:02<00:04, 130.82it/s]\u001b[A\n",
            " 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                       | 372/901 [00:02<00:04, 127.62it/s]\u001b[A\n",
            " 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                       | 385/901 [00:03<00:04, 122.12it/s]\u001b[A\n",
            " 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                      | 398/901 [00:03<00:04, 123.99it/s]\u001b[A\n",
            " 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                     | 412/901 [00:03<00:03, 126.62it/s]\u001b[A\n",
            " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                     | 427/901 [00:03<00:03, 130.81it/s]\u001b[A\n",
            " 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 443/901 [00:03<00:03, 133.74it/s]\u001b[A\n",
            " 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 457/901 [00:03<00:03, 132.04it/s]\u001b[A\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 471/901 [00:03<00:03, 129.23it/s]\u001b[A\n",
            " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 485/901 [00:03<00:03, 130.52it/s]\u001b[A\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 499/901 [00:03<00:03, 123.05it/s]\u001b[A\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 512/901 [00:04<00:03, 117.92it/s]\u001b[A\n",
            " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 525/901 [00:04<00:03, 119.17it/s]\u001b[A\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 538/901 [00:04<00:03, 120.64it/s]\u001b[A\n",
            " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 552/901 [00:04<00:02, 123.34it/s]\u001b[A\n",
            " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 566/901 [00:04<00:02, 125.13it/s]\u001b[A\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 583/901 [00:04<00:02, 137.18it/s]\u001b[A\n",
            " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 597/901 [00:04<00:02, 127.52it/s]\u001b[A\n",
            " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 610/901 [00:04<00:02, 124.89it/s]\u001b[A\n",
            " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã            | 625/901 [00:04<00:02, 131.08it/s]\u001b[A\n",
            " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 643/901 [00:05<00:01, 144.43it/s]\u001b[A\n",
            " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 658/901 [00:05<00:01, 137.35it/s]\u001b[A\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 672/901 [00:05<00:01, 128.54it/s]\u001b[A\n",
            " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 687/901 [00:05<00:01, 132.44it/s]\u001b[A\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 702/901 [00:05<00:01, 135.54it/s]\u001b[A\n",
            " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 716/901 [00:05<00:01, 133.71it/s]\u001b[A\n",
            " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç       | 730/901 [00:05<00:01, 135.10it/s]\u001b[A\n",
            " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 744/901 [00:05<00:01, 129.79it/s]\u001b[A\n",
            " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 758/901 [00:05<00:01, 130.87it/s]\u001b[A\n",
            " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé     | 773/901 [00:06<00:00, 134.76it/s]\u001b[A\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà     | 790/901 [00:06<00:00, 144.43it/s]\u001b[A\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 807/901 [00:06<00:00, 150.90it/s]\u001b[A\n",
            " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 823/901 [00:06<00:00, 139.52it/s]\u001b[A\n",
            " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 838/901 [00:06<00:00, 130.24it/s]\u001b[A\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 852/901 [00:06<00:00, 127.78it/s]\u001b[A\n",
            " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 870/901 [00:06<00:00, 140.32it/s]\u001b[A\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 885/901 [00:06<00:00, 136.84it/s]\u001b[A\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 901/901 [00:06<00:00, 128.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> File processing complete\n",
            "\n",
            "> Start normalizing data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|                                                   | 0/901 [00:00<?, ?it/s]\u001b[A\n",
            " 11%|‚ñà‚ñà‚ñà‚ñà‚ñç                                    | 98/901 [00:00<00:00, 977.16it/s]\u001b[A\n",
            " 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                             | 218/901 [00:00<00:00, 1105.15it/s]\u001b[A\n",
            " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 329/901 [00:00<00:00, 1037.22it/s]\u001b[A\n",
            " 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 438/901 [00:00<00:00, 1051.01it/s]\u001b[A\n",
            " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 544/901 [00:00<00:00, 1006.59it/s]\u001b[A\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 650/901 [00:00<00:00, 1020.93it/s]\u001b[A\n",
            " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 753/901 [00:00<00:00, 1014.26it/s]\u001b[A\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 901/901 [00:00<00:00, 1022.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Normalizing data complete\n",
            "> Archive have already downloaded\n",
            "\n",
            "> Extract complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|                                                   | 0/901 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|‚ñâ                                        | 20/901 [00:00<00:05, 175.10it/s]\u001b[A\n",
            "  4%|‚ñà‚ñã                                       | 38/901 [00:00<00:05, 149.92it/s]\u001b[A\n",
            "  6%|‚ñà‚ñà‚ñç                                      | 54/901 [00:00<00:05, 150.29it/s]\u001b[A\n",
            "  8%|‚ñà‚ñà‚ñà‚ñè                                     | 71/901 [00:00<00:05, 151.09it/s]\u001b[A\n",
            " 10%|‚ñà‚ñà‚ñà‚ñà‚ñè                                    | 91/901 [00:00<00:05, 161.94it/s]\u001b[A\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñä                                   | 108/901 [00:00<00:05, 157.72it/s]\u001b[A\n",
            " 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                  | 124/901 [00:00<00:05, 154.86it/s]\u001b[A\n",
            " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 140/901 [00:00<00:04, 155.53it/s]\u001b[A\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                 | 158/901 [00:01<00:04, 161.75it/s]\u001b[A\n",
            " 19%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                                | 175/901 [00:01<00:04, 145.85it/s]\u001b[A\n",
            " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                               | 193/901 [00:01<00:04, 155.08it/s]\u001b[A\n",
            " 23%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 209/901 [00:01<00:04, 147.84it/s]\u001b[A\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                              | 225/901 [00:01<00:04, 149.67it/s]\u001b[A\n",
            " 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                             | 243/901 [00:01<00:04, 154.92it/s]\u001b[A\n",
            " 29%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 260/901 [00:01<00:04, 158.50it/s]\u001b[A\n",
            " 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                           | 276/901 [00:01<00:03, 156.70it/s]\u001b[A\n",
            " 32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 292/901 [00:01<00:03, 155.65it/s]\u001b[A\n",
            " 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                          | 309/901 [00:01<00:03, 159.03it/s]\u001b[A\n",
            " 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 325/901 [00:02<00:03, 147.14it/s]\u001b[A\n",
            " 38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                        | 341/901 [00:02<00:03, 150.48it/s]\u001b[A\n",
            " 40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                        | 359/901 [00:02<00:03, 156.97it/s]\u001b[A\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                       | 375/901 [00:02<00:03, 148.89it/s]\u001b[A\n",
            " 43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 391/901 [00:02<00:03, 146.20it/s]\u001b[A\n",
            " 45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 409/901 [00:02<00:03, 154.93it/s]\u001b[A\n",
            " 48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 428/901 [00:02<00:02, 160.32it/s]\u001b[A\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                    | 449/901 [00:02<00:02, 168.64it/s]\u001b[A\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 466/901 [00:02<00:02, 166.85it/s]\u001b[A\n",
            " 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 483/901 [00:03<00:02, 166.99it/s]\u001b[A\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                 | 500/901 [00:03<00:02, 158.27it/s]\u001b[A\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                 | 516/901 [00:03<00:02, 149.52it/s]\u001b[A\n",
            " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                | 534/901 [00:03<00:02, 156.32it/s]\u001b[A\n",
            " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 552/901 [00:03<00:02, 157.55it/s]\u001b[A\n",
            " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 569/901 [00:03<00:02, 160.17it/s]\u001b[A\n",
            " 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè             | 589/901 [00:03<00:01, 168.31it/s]\u001b[A\n",
            " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ             | 606/901 [00:03<00:02, 146.99it/s]\u001b[A\n",
            " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå            | 622/901 [00:04<00:01, 146.98it/s]\u001b[A\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 646/901 [00:04<00:01, 171.30it/s]\u001b[A\n",
            " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 664/901 [00:04<00:01, 165.81it/s]\u001b[A\n",
            " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 681/901 [00:04<00:01, 155.22it/s]\u001b[A\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 699/901 [00:04<00:01, 159.74it/s]\u001b[A\n",
            " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 716/901 [00:04<00:01, 157.80it/s]\u001b[A\n",
            " 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 733/901 [00:04<00:01, 156.65it/s]\u001b[A\n",
            " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé      | 749/901 [00:04<00:01, 147.04it/s]\u001b[A\n",
            " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 767/901 [00:04<00:00, 154.46it/s]\u001b[A\n",
            " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 788/901 [00:05<00:00, 168.36it/s]\u001b[A\n",
            " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 806/901 [00:05<00:00, 167.51it/s]\u001b[A\n",
            " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 823/901 [00:05<00:00, 153.51it/s]\u001b[A\n",
            " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 839/901 [00:05<00:00, 144.48it/s]\u001b[A\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 854/901 [00:05<00:00, 142.36it/s]\u001b[A\n",
            " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 873/901 [00:05<00:00, 152.36it/s]\u001b[A\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 901/901 [00:05<00:00, 155.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> File processing complete\n",
            "\n",
            "> Start normalizing data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|                                                   | 0/901 [00:00<?, ?it/s]\u001b[A\n",
            " 13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                 | 120/901 [00:00<00:00, 1196.73it/s]\u001b[A\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                            | 253/901 [00:00<00:00, 1265.20it/s]\u001b[A\n",
            " 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 395/901 [00:00<00:00, 1335.48it/s]\u001b[A\n",
            " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 529/901 [00:00<00:00, 1286.81it/s]\u001b[A\n",
            " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 662/901 [00:00<00:00, 1299.73it/s]\u001b[A\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 901/901 [00:00<00:00, 1290.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Normalizing data complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4tnePIv5-w7"
      },
      "source": [
        "## Sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kGPWgFA-f-l"
      },
      "source": [
        "from math import ceil\n",
        "\n",
        "class ClassBalancedRandomSampler(Sampler):\n",
        "    def __init__(self, index_list_by_class, sampling_type: str='over'):\n",
        "        # Calculating weight for each class\n",
        "        num_samples = [len(l) for l in index_list_by_class]\n",
        "\n",
        "        # Get number of samples per class\n",
        "        if sampling_type == 'under':\n",
        "            # Limit that number by minor class\n",
        "            desired_samples_per_class = min(num_samples)\n",
        "        elif sampling_type == 'over':\n",
        "            # Limit that number by major class\n",
        "            desired_samples_per_class = max(num_samples)\n",
        "\n",
        "            # Duplicate sample in minor class\n",
        "            # Numer of samples per class alway > desired_samples_per_class\n",
        "            for i, index_list in enumerate(index_list_by_class):\n",
        "                rep_times = ceil(desired_samples_per_class/num_samples[i]) - 1\n",
        "                index_list_by_class[i] += rep_times*index_list\n",
        "                num_samples[i] += rep_times*num_samples[i]\n",
        "        else:\n",
        "            raise KeyError(\"sampling_type can only be 'over' (oversampling) or 'under' (undersampling)\")\n",
        "\n",
        "        class_weights = [desired_samples_per_class/n for n in num_samples]\n",
        "\n",
        "        # Replicating class weight for each sample\n",
        "        self.index_map = []\n",
        "        sample_weights = []\n",
        "\n",
        "        for i, class_list in enumerate(index_list_by_class):\n",
        "            self.index_map += class_list\n",
        "            sample_weights += len(class_list)*[class_weights[i]]\n",
        "\n",
        "        self.sampler = WeightedRandomSampler(\n",
        "            weights=sample_weights,\n",
        "            num_samples=len(index_list_by_class)*desired_samples_per_class,\n",
        "            replacement=False\n",
        "        )\n",
        "    \n",
        "    def __iter__(self):\n",
        "        for i in self.sampler:\n",
        "            yield self.index_map[i]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM-M63AGNByi"
      },
      "source": [
        "exploded_df = train_set.meta_df.iloc[train_set.idxs].reset_index()\n",
        "index_list_by_class = [exploded_df.query(\"assessment_result==0\").index.to_list(),exploded_df.query(\"assessment_result==1\").index.to_list()]\n",
        "\n",
        "weighted_sampler = ClassBalancedRandomSampler(index_list_by_class, 'over')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37j76Vm4q9P2"
      },
      "source": [
        "## Collate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-wzTV7BhoHU"
      },
      "source": [
        "cols_to_drop = ['uuid', 'subject_age', 'audio_noise_note', 'cough_intervals', ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpswQ8ayvZOo"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_pad_seq_fn(batch):\n",
        "    # A data tuple has the form:\n",
        "    # spec, covid_label, sex_label, \n",
        "\n",
        "    specs, covids, sexs, multilabels = [], [], [], []\n",
        "\n",
        "    # Gather in lists, and encode labels as indices\n",
        "    for spec, covid, meta in batch:\n",
        "        specs += [spec.permute(2,0,1)]\n",
        "        covids += [covid]\n",
        "        if covid is not None:\n",
        "            meta = meta.drop(cols_to_drop)\n",
        "            meta[meta > 1] = 1\n",
        "            sexs += [torch.tensor(meta['male'])]\n",
        "            meta = meta.drop(['female', 'male'])\n",
        "            multilabels += [torch.tensor(meta)]\n",
        "\n",
        "    # Group the list of tensors into a batched tensor\n",
        "    specs = pad_sequence(specs, batch_first=True).permute(0,2,3,1)\n",
        "    try:\n",
        "      covids = torch.stack(covids)\n",
        "      sexs = torch.stack(sexs)\n",
        "      multilabels = torch.stack(multilabels)\n",
        "      return specs, covids, sexs, multilabels\n",
        "    except:\n",
        "      return specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmd8ZC6kHQlk"
      },
      "source": [
        "def collate_pad_1024_fn(batch):\n",
        "    # A data tuple has the form:\n",
        "    # spec, covid_label, sex_label, \n",
        "\n",
        "    specs, covids, sexs, multilabels = [], [], [], []\n",
        "\n",
        "    # Gather in lists, and encode labels as indices\n",
        "    for spec, covid, meta in batch:\n",
        "        if spec.shape[-1] > 1024:\n",
        "            spec = spec[..., :1024]\n",
        "        elif spec.shape[-1] < 1024:\n",
        "            pad_size = (0, 1024-spec.shape[-1])\n",
        "            spec = torch.nn.functional.pad(spec, pad_size, mode='constant', value=0)\n",
        "\n",
        "        specs += [spec.permute(2,0,1)]\n",
        "        covids += [covid]\n",
        "        if covid is not None:\n",
        "            meta = meta.drop(cols_to_drop)\n",
        "            meta[meta > 1] = 1\n",
        "            sexs += [torch.tensor(meta['male'])]\n",
        "            meta = meta.drop(['female', 'male'])\n",
        "            multilabels += [torch.tensor(meta)]\n",
        "\n",
        "    # Group the list of tensors into a batched tensor\n",
        "    specs = pad_sequence(specs, batch_first=True).permute(0,2,3,1)\n",
        "    try:\n",
        "      covids = torch.stack(covids)\n",
        "      sexs = torch.stack(sexs)\n",
        "      multilabels = torch.stack(multilabels)\n",
        "      return specs, covids, sexs, multilabels\n",
        "    except:\n",
        "      return specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpCUnnvX2Ajc"
      },
      "source": [
        "def collate_fn(batch):\n",
        "    # A data tuple has the form:\n",
        "    # spec, covid_label, sex_label, \n",
        "\n",
        "    specs, covids, sexs, multilabels = [], [], [], []\n",
        "\n",
        "    # Gather in lists, and encode labels as indices\n",
        "    for spec, covid, meta in batch:\n",
        "        specs += [spec]\n",
        "        covids += [covid]\n",
        "        if covid is not None:\n",
        "            meta = meta.drop(cols_to_drop)\n",
        "            meta[meta > 1] = 1\n",
        "            sexs += [torch.tensor(meta['male'])]\n",
        "            meta = meta.drop(['female', 'male'])\n",
        "            multilabels += [torch.tensor(meta)]\n",
        "\n",
        "\n",
        "    # Group the list of tensors into a batched tensor\n",
        "    specs = torch.stack(specs)\n",
        "    try:\n",
        "      covids = torch.stack(covids)\n",
        "      sexs = torch.stack(sexs)\n",
        "      multilabels = torch.stack(multilabels)\n",
        "      return specs, covids, sexs, multilabels\n",
        "    except:\n",
        "      return specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC9H2rfap_hJ"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOg5s4DbLdXZ"
      },
      "source": [
        "num_workers=8\n",
        "pin_memory=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTy3Zayd3H3D"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=batch_size,\n",
        "    sampler=weighted_sampler,\n",
        "    collate_fn=collate_pad_1024_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_pad_1024_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_pad_1024_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA2gBdmlRvMP"
      },
      "source": [
        "# Experiment - Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de8x3e4UM0ZM"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8spWmDjjmcqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b12ba82-bfae-4386-9ef4-d22ef7f4468a"
      },
      "source": [
        "exp_logger = logger(logger_exp_name)\n",
        "# Log hyperparam to logger for convinient\n",
        "exp_logger.experiment['hyperparam'] = trainer_params\n",
        "exp_logger.experiment['hyperparam'] = optim_config\n",
        "\n",
        "model = AICOVIDModule(ast_mdl, optim_config=optim_config, task_weight=(1., 0.5))#, augment=SpecAugment(time_W=100, freq_W=50, T=80))\n",
        "trainer = pl.Trainer(**trainer_params, logger=exp_logger)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://app.neptune.ai/vulong61/AICOVID/e/AIC-160\n",
            "Remember to stop your run once you‚Äôve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Using native 16bit precision.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doxcKBBqMBol"
      },
      "source": [
        "Summary model output shape since this will be logged to Neptune too!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKN6ODkUZyRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed43c72-9d5d-4bcb-c2aa-34c9e9c48c40"
      },
      "source": [
        "mdl_summary = summary(ast_mdl, (4,1,128,1024))\n",
        "exp_logger.experiment['monitoring/model_summary'] = mdl_summary\n",
        "mdl_summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ASTModel                                 --                        --\n",
              "‚îú‚îÄDistilledVisionTransformer: 1          --                        --\n",
              "‚îÇ    ‚îî‚îÄPatchEmbed: 2-1                   [4, 1212, 768]            --\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                  [4, 768, 12, 101]         197,376\n",
              "‚îÇ    ‚îî‚îÄDropout: 2-2                      [4, 1214, 768]            --\n",
              "‚îÇ    ‚îî‚îÄSequential: 2-3                   [4, 1214, 768]            --\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-2                   [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-3                   [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-4                   [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-5                   [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-6                   [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-7                   [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-8                   [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-9                   [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-10                  [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-11                  [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-12                  [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îÇ    ‚îî‚îÄBlock: 3-13                  [4, 1214, 768]            7,087,872\n",
              "‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    [4, 1214, 768]            1,536\n",
              "‚îú‚îÄReduce: 1-1                            [4, 768]                  --\n",
              "‚îú‚îÄIdentity: 1-2                          [4, 768]                  --\n",
              "==========================================================================================\n",
              "Total params: 85,253,376\n",
              "Trainable params: 85,253,376\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 1.30\n",
              "==========================================================================================\n",
              "Input size (MB): 2.10\n",
              "Forward/backward pass size (MB): 3997.88\n",
              "Params size (MB): 341.01\n",
              "Estimated Total Size (MB): 4340.99\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUZlB5UMtBf"
      },
      "source": [
        "Print gpu device info too!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5UW9uwTMmRD"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "exp_logger.experiment['monitoring/gpu_info'] = subprocess.check_output(\"nvidia-smi\", shell=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xcTzY1smd1H"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtkN__wPmcqM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e405808-502f-4b8a-930f-bed88036978a"
      },
      "source": [
        "# trainer.fit(model, train_loader, val_loader)\n",
        "trainer.fit(model, train_loader, test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "    | Name                             | Type                       | Params\n",
            "----------------------------------------------------------------------------------\n",
            "0   | model                            | ASTModel                   | 87.7 M\n",
            "1   | model.v                          | DistilledVisionTransformer | 87.7 M\n",
            "2   | model.v.patch_embed              | PatchEmbed                 | 197 K \n",
            "3   | model.v.patch_embed.proj         | Conv2d                     | 197 K \n",
            "4   | model.v.pos_drop                 | Dropout                    | 0     \n",
            "5   | model.v.blocks                   | Sequential                 | 85.1 M\n",
            "6   | model.v.blocks.0                 | Block                      | 7.1 M \n",
            "7   | model.v.blocks.0.norm1           | LayerNorm                  | 1.5 K \n",
            "8   | model.v.blocks.0.attn            | Attention                  | 2.4 M \n",
            "9   | model.v.blocks.0.attn.qkv        | Linear                     | 1.8 M \n",
            "10  | model.v.blocks.0.attn.attn_drop  | Dropout                    | 0     \n",
            "11  | model.v.blocks.0.attn.proj       | Linear                     | 590 K \n",
            "12  | model.v.blocks.0.attn.proj_drop  | Dropout                    | 0     \n",
            "13  | model.v.blocks.0.drop_path       | Identity                   | 0     \n",
            "14  | model.v.blocks.0.norm2           | LayerNorm                  | 1.5 K \n",
            "15  | model.v.blocks.0.mlp             | Mlp                        | 4.7 M \n",
            "16  | model.v.blocks.0.mlp.fc1         | Linear                     | 2.4 M \n",
            "17  | model.v.blocks.0.mlp.act         | GELU                       | 0     \n",
            "18  | model.v.blocks.0.mlp.fc2         | Linear                     | 2.4 M \n",
            "19  | model.v.blocks.0.mlp.drop        | Dropout                    | 0     \n",
            "20  | model.v.blocks.1                 | Block                      | 7.1 M \n",
            "21  | model.v.blocks.1.norm1           | LayerNorm                  | 1.5 K \n",
            "22  | model.v.blocks.1.attn            | Attention                  | 2.4 M \n",
            "23  | model.v.blocks.1.attn.qkv        | Linear                     | 1.8 M \n",
            "24  | model.v.blocks.1.attn.attn_drop  | Dropout                    | 0     \n",
            "25  | model.v.blocks.1.attn.proj       | Linear                     | 590 K \n",
            "26  | model.v.blocks.1.attn.proj_drop  | Dropout                    | 0     \n",
            "27  | model.v.blocks.1.drop_path       | Identity                   | 0     \n",
            "28  | model.v.blocks.1.norm2           | LayerNorm                  | 1.5 K \n",
            "29  | model.v.blocks.1.mlp             | Mlp                        | 4.7 M \n",
            "30  | model.v.blocks.1.mlp.fc1         | Linear                     | 2.4 M \n",
            "31  | model.v.blocks.1.mlp.act         | GELU                       | 0     \n",
            "32  | model.v.blocks.1.mlp.fc2         | Linear                     | 2.4 M \n",
            "33  | model.v.blocks.1.mlp.drop        | Dropout                    | 0     \n",
            "34  | model.v.blocks.2                 | Block                      | 7.1 M \n",
            "35  | model.v.blocks.2.norm1           | LayerNorm                  | 1.5 K \n",
            "36  | model.v.blocks.2.attn            | Attention                  | 2.4 M \n",
            "37  | model.v.blocks.2.attn.qkv        | Linear                     | 1.8 M \n",
            "38  | model.v.blocks.2.attn.attn_drop  | Dropout                    | 0     \n",
            "39  | model.v.blocks.2.attn.proj       | Linear                     | 590 K \n",
            "40  | model.v.blocks.2.attn.proj_drop  | Dropout                    | 0     \n",
            "41  | model.v.blocks.2.drop_path       | Identity                   | 0     \n",
            "42  | model.v.blocks.2.norm2           | LayerNorm                  | 1.5 K \n",
            "43  | model.v.blocks.2.mlp             | Mlp                        | 4.7 M \n",
            "44  | model.v.blocks.2.mlp.fc1         | Linear                     | 2.4 M \n",
            "45  | model.v.blocks.2.mlp.act         | GELU                       | 0     \n",
            "46  | model.v.blocks.2.mlp.fc2         | Linear                     | 2.4 M \n",
            "47  | model.v.blocks.2.mlp.drop        | Dropout                    | 0     \n",
            "48  | model.v.blocks.3                 | Block                      | 7.1 M \n",
            "49  | model.v.blocks.3.norm1           | LayerNorm                  | 1.5 K \n",
            "50  | model.v.blocks.3.attn            | Attention                  | 2.4 M \n",
            "51  | model.v.blocks.3.attn.qkv        | Linear                     | 1.8 M \n",
            "52  | model.v.blocks.3.attn.attn_drop  | Dropout                    | 0     \n",
            "53  | model.v.blocks.3.attn.proj       | Linear                     | 590 K \n",
            "54  | model.v.blocks.3.attn.proj_drop  | Dropout                    | 0     \n",
            "55  | model.v.blocks.3.drop_path       | Identity                   | 0     \n",
            "56  | model.v.blocks.3.norm2           | LayerNorm                  | 1.5 K \n",
            "57  | model.v.blocks.3.mlp             | Mlp                        | 4.7 M \n",
            "58  | model.v.blocks.3.mlp.fc1         | Linear                     | 2.4 M \n",
            "59  | model.v.blocks.3.mlp.act         | GELU                       | 0     \n",
            "60  | model.v.blocks.3.mlp.fc2         | Linear                     | 2.4 M \n",
            "61  | model.v.blocks.3.mlp.drop        | Dropout                    | 0     \n",
            "62  | model.v.blocks.4                 | Block                      | 7.1 M \n",
            "63  | model.v.blocks.4.norm1           | LayerNorm                  | 1.5 K \n",
            "64  | model.v.blocks.4.attn            | Attention                  | 2.4 M \n",
            "65  | model.v.blocks.4.attn.qkv        | Linear                     | 1.8 M \n",
            "66  | model.v.blocks.4.attn.attn_drop  | Dropout                    | 0     \n",
            "67  | model.v.blocks.4.attn.proj       | Linear                     | 590 K \n",
            "68  | model.v.blocks.4.attn.proj_drop  | Dropout                    | 0     \n",
            "69  | model.v.blocks.4.drop_path       | Identity                   | 0     \n",
            "70  | model.v.blocks.4.norm2           | LayerNorm                  | 1.5 K \n",
            "71  | model.v.blocks.4.mlp             | Mlp                        | 4.7 M \n",
            "72  | model.v.blocks.4.mlp.fc1         | Linear                     | 2.4 M \n",
            "73  | model.v.blocks.4.mlp.act         | GELU                       | 0     \n",
            "74  | model.v.blocks.4.mlp.fc2         | Linear                     | 2.4 M \n",
            "75  | model.v.blocks.4.mlp.drop        | Dropout                    | 0     \n",
            "76  | model.v.blocks.5                 | Block                      | 7.1 M \n",
            "77  | model.v.blocks.5.norm1           | LayerNorm                  | 1.5 K \n",
            "78  | model.v.blocks.5.attn            | Attention                  | 2.4 M \n",
            "79  | model.v.blocks.5.attn.qkv        | Linear                     | 1.8 M \n",
            "80  | model.v.blocks.5.attn.attn_drop  | Dropout                    | 0     \n",
            "81  | model.v.blocks.5.attn.proj       | Linear                     | 590 K \n",
            "82  | model.v.blocks.5.attn.proj_drop  | Dropout                    | 0     \n",
            "83  | model.v.blocks.5.drop_path       | Identity                   | 0     \n",
            "84  | model.v.blocks.5.norm2           | LayerNorm                  | 1.5 K \n",
            "85  | model.v.blocks.5.mlp             | Mlp                        | 4.7 M \n",
            "86  | model.v.blocks.5.mlp.fc1         | Linear                     | 2.4 M \n",
            "87  | model.v.blocks.5.mlp.act         | GELU                       | 0     \n",
            "88  | model.v.blocks.5.mlp.fc2         | Linear                     | 2.4 M \n",
            "89  | model.v.blocks.5.mlp.drop        | Dropout                    | 0     \n",
            "90  | model.v.blocks.6                 | Block                      | 7.1 M \n",
            "91  | model.v.blocks.6.norm1           | LayerNorm                  | 1.5 K \n",
            "92  | model.v.blocks.6.attn            | Attention                  | 2.4 M \n",
            "93  | model.v.blocks.6.attn.qkv        | Linear                     | 1.8 M \n",
            "94  | model.v.blocks.6.attn.attn_drop  | Dropout                    | 0     \n",
            "95  | model.v.blocks.6.attn.proj       | Linear                     | 590 K \n",
            "96  | model.v.blocks.6.attn.proj_drop  | Dropout                    | 0     \n",
            "97  | model.v.blocks.6.drop_path       | Identity                   | 0     \n",
            "98  | model.v.blocks.6.norm2           | LayerNorm                  | 1.5 K \n",
            "99  | model.v.blocks.6.mlp             | Mlp                        | 4.7 M \n",
            "100 | model.v.blocks.6.mlp.fc1         | Linear                     | 2.4 M \n",
            "101 | model.v.blocks.6.mlp.act         | GELU                       | 0     \n",
            "102 | model.v.blocks.6.mlp.fc2         | Linear                     | 2.4 M \n",
            "103 | model.v.blocks.6.mlp.drop        | Dropout                    | 0     \n",
            "104 | model.v.blocks.7                 | Block                      | 7.1 M \n",
            "105 | model.v.blocks.7.norm1           | LayerNorm                  | 1.5 K \n",
            "106 | model.v.blocks.7.attn            | Attention                  | 2.4 M \n",
            "107 | model.v.blocks.7.attn.qkv        | Linear                     | 1.8 M \n",
            "108 | model.v.blocks.7.attn.attn_drop  | Dropout                    | 0     \n",
            "109 | model.v.blocks.7.attn.proj       | Linear                     | 590 K \n",
            "110 | model.v.blocks.7.attn.proj_drop  | Dropout                    | 0     \n",
            "111 | model.v.blocks.7.drop_path       | Identity                   | 0     \n",
            "112 | model.v.blocks.7.norm2           | LayerNorm                  | 1.5 K \n",
            "113 | model.v.blocks.7.mlp             | Mlp                        | 4.7 M \n",
            "114 | model.v.blocks.7.mlp.fc1         | Linear                     | 2.4 M \n",
            "115 | model.v.blocks.7.mlp.act         | GELU                       | 0     \n",
            "116 | model.v.blocks.7.mlp.fc2         | Linear                     | 2.4 M \n",
            "117 | model.v.blocks.7.mlp.drop        | Dropout                    | 0     \n",
            "118 | model.v.blocks.8                 | Block                      | 7.1 M \n",
            "119 | model.v.blocks.8.norm1           | LayerNorm                  | 1.5 K \n",
            "120 | model.v.blocks.8.attn            | Attention                  | 2.4 M \n",
            "121 | model.v.blocks.8.attn.qkv        | Linear                     | 1.8 M \n",
            "122 | model.v.blocks.8.attn.attn_drop  | Dropout                    | 0     \n",
            "123 | model.v.blocks.8.attn.proj       | Linear                     | 590 K \n",
            "124 | model.v.blocks.8.attn.proj_drop  | Dropout                    | 0     \n",
            "125 | model.v.blocks.8.drop_path       | Identity                   | 0     \n",
            "126 | model.v.blocks.8.norm2           | LayerNorm                  | 1.5 K \n",
            "127 | model.v.blocks.8.mlp             | Mlp                        | 4.7 M \n",
            "128 | model.v.blocks.8.mlp.fc1         | Linear                     | 2.4 M \n",
            "129 | model.v.blocks.8.mlp.act         | GELU                       | 0     \n",
            "130 | model.v.blocks.8.mlp.fc2         | Linear                     | 2.4 M \n",
            "131 | model.v.blocks.8.mlp.drop        | Dropout                    | 0     \n",
            "132 | model.v.blocks.9                 | Block                      | 7.1 M \n",
            "133 | model.v.blocks.9.norm1           | LayerNorm                  | 1.5 K \n",
            "134 | model.v.blocks.9.attn            | Attention                  | 2.4 M \n",
            "135 | model.v.blocks.9.attn.qkv        | Linear                     | 1.8 M \n",
            "136 | model.v.blocks.9.attn.attn_drop  | Dropout                    | 0     \n",
            "137 | model.v.blocks.9.attn.proj       | Linear                     | 590 K \n",
            "138 | model.v.blocks.9.attn.proj_drop  | Dropout                    | 0     \n",
            "139 | model.v.blocks.9.drop_path       | Identity                   | 0     \n",
            "140 | model.v.blocks.9.norm2           | LayerNorm                  | 1.5 K \n",
            "141 | model.v.blocks.9.mlp             | Mlp                        | 4.7 M \n",
            "142 | model.v.blocks.9.mlp.fc1         | Linear                     | 2.4 M \n",
            "143 | model.v.blocks.9.mlp.act         | GELU                       | 0     \n",
            "144 | model.v.blocks.9.mlp.fc2         | Linear                     | 2.4 M \n",
            "145 | model.v.blocks.9.mlp.drop        | Dropout                    | 0     \n",
            "146 | model.v.blocks.10                | Block                      | 7.1 M \n",
            "147 | model.v.blocks.10.norm1          | LayerNorm                  | 1.5 K \n",
            "148 | model.v.blocks.10.attn           | Attention                  | 2.4 M \n",
            "149 | model.v.blocks.10.attn.qkv       | Linear                     | 1.8 M \n",
            "150 | model.v.blocks.10.attn.attn_drop | Dropout                    | 0     \n",
            "151 | model.v.blocks.10.attn.proj      | Linear                     | 590 K \n",
            "152 | model.v.blocks.10.attn.proj_drop | Dropout                    | 0     \n",
            "153 | model.v.blocks.10.drop_path      | Identity                   | 0     \n",
            "154 | model.v.blocks.10.norm2          | LayerNorm                  | 1.5 K \n",
            "155 | model.v.blocks.10.mlp            | Mlp                        | 4.7 M \n",
            "156 | model.v.blocks.10.mlp.fc1        | Linear                     | 2.4 M \n",
            "157 | model.v.blocks.10.mlp.act        | GELU                       | 0     \n",
            "158 | model.v.blocks.10.mlp.fc2        | Linear                     | 2.4 M \n",
            "159 | model.v.blocks.10.mlp.drop       | Dropout                    | 0     \n",
            "160 | model.v.blocks.11                | Block                      | 7.1 M \n",
            "161 | model.v.blocks.11.norm1          | LayerNorm                  | 1.5 K \n",
            "162 | model.v.blocks.11.attn           | Attention                  | 2.4 M \n",
            "163 | model.v.blocks.11.attn.qkv       | Linear                     | 1.8 M \n",
            "164 | model.v.blocks.11.attn.attn_drop | Dropout                    | 0     \n",
            "165 | model.v.blocks.11.attn.proj      | Linear                     | 590 K \n",
            "166 | model.v.blocks.11.attn.proj_drop | Dropout                    | 0     \n",
            "167 | model.v.blocks.11.drop_path      | Identity                   | 0     \n",
            "168 | model.v.blocks.11.norm2          | LayerNorm                  | 1.5 K \n",
            "169 | model.v.blocks.11.mlp            | Mlp                        | 4.7 M \n",
            "170 | model.v.blocks.11.mlp.fc1        | Linear                     | 2.4 M \n",
            "171 | model.v.blocks.11.mlp.act        | GELU                       | 0     \n",
            "172 | model.v.blocks.11.mlp.fc2        | Linear                     | 2.4 M \n",
            "173 | model.v.blocks.11.mlp.drop       | Dropout                    | 0     \n",
            "174 | model.v.norm                     | LayerNorm                  | 1.5 K \n",
            "175 | model.v.pre_logits               | Identity                   | 0     \n",
            "176 | model.v.head                     | Linear                     | 769 K \n",
            "177 | model.v.head_dist                | Linear                     | 769 K \n",
            "178 | model.pooling_layer              | Reduce                     | 0     \n",
            "179 | model.pre_logits                 | Identity                   | 0     \n",
            "180 | covid_head                       | Linear                     | 769   \n",
            "181 | gender_head                      | Linear                     | 1.5 K \n",
            "182 | multilabel                       | Linear                     | 18.5 K\n",
            "183 | covid_loss                       | BCEWithLogitsLoss          | 0     \n",
            "184 | gender_loss                      | CrossEntropyLoss           | 0     \n",
            "185 | multilabel_loss                  | BCEWithLogitsLoss          | 0     \n",
            "----------------------------------------------------------------------------------\n",
            "87.7 M    Trainable params\n",
            "0         Non-trainable params\n",
            "87.7 M    Total params\n",
            "350.984   Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                                                                "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:   0%|                                         | 0/2337 [00:00<?, ?it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "/home/long/anaconda3/envs/cuda-38/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2040/2337 [11:39<01:41,  2.92it/s, loss=0.644, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 0:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2050/2337 [11:41<01:38,  2.92it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2060/2337 [11:42<01:34,  2.93it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2070/2337 [11:43<01:30,  2.94it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2080/2337 [11:44<01:27,  2.95it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2090/2337 [11:45<01:23,  2.96it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2100/2337 [11:46<01:19,  2.97it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2110/2337 [11:47<01:16,  2.98it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2120/2337 [11:48<01:12,  2.99it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2130/2337 [11:49<01:08,  3.00it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2140/2337 [11:50<01:05,  3.01it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2150/2337 [11:51<01:01,  3.02it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2160/2337 [11:52<00:58,  3.03it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2170/2337 [11:53<00:54,  3.04it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2180/2337 [11:55<00:51,  3.05it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2190/2337 [11:56<00:48,  3.06it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2200/2337 [11:57<00:44,  3.07it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2210/2337 [11:58<00:41,  3.08it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2220/2337 [11:59<00:37,  3.09it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2230/2337 [12:00<00:34,  3.10it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2240/2337 [12:01<00:31,  3.10it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2250/2337 [12:02<00:27,  3.11it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2260/2337 [12:03<00:24,  3.12it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2270/2337 [12:04<00:21,  3.13it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2280/2337 [12:05<00:18,  3.14it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [12:06<00:14,  3.15it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [12:07<00:11,  3.16it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [12:08<00:08,  3.17it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [12:10<00:05,  3.18it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [12:11<00:02,  3.19it/s, loss=0.644, v_num=-160]\n",
            "Epoch 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [12:12<00:00,  3.19it/s, loss=0.622, v_num=-160]\n",
            "Epoch 1:   0%|                 | 0/2337 [00:00<?, ?it/s, loss=0.622, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2040/2337 [11:03<01:36,  3.08it/s, loss=0.238, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2050/2337 [11:04<01:33,  3.09it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2060/2337 [11:05<01:29,  3.10it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2070/2337 [11:06<01:25,  3.11it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2080/2337 [11:07<01:22,  3.12it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2090/2337 [11:08<01:19,  3.13it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2100/2337 [11:09<01:15,  3.14it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2110/2337 [11:10<01:12,  3.15it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2120/2337 [11:11<01:08,  3.16it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2130/2337 [11:13<01:05,  3.16it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2140/2337 [11:14<01:02,  3.17it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2150/2337 [11:15<00:58,  3.18it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2160/2337 [11:16<00:55,  3.19it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2170/2337 [11:17<00:52,  3.20it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2180/2337 [11:18<00:48,  3.21it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2190/2337 [11:19<00:45,  3.22it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2200/2337 [11:20<00:42,  3.23it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2210/2337 [11:21<00:39,  3.24it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2220/2337 [11:22<00:35,  3.25it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2230/2337 [11:23<00:32,  3.26it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:24<00:29,  3.27it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:25<00:26,  3.28it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:27<00:23,  3.29it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2270/2337 [11:28<00:20,  3.30it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2280/2337 [11:29<00:17,  3.31it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:30<00:14,  3.32it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:31<00:11,  3.33it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:32<00:08,  3.34it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:33<00:05,  3.35it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:34<00:02,  3.35it/s, loss=0.238, v_num=-160]\n",
            "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:35<00:00,  3.36it/s, loss=0.228, v_num=-160]\n",
            "Epoch 2:   0%|                 | 0/2337 [00:00<?, ?it/s, loss=0.228, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 2040/2337 [11:06<01:37,  3.06it/s, loss=0.13, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2050/2337 [11:08<01:33,  3.07it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2060/2337 [11:09<01:29,  3.08it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2070/2337 [11:10<01:26,  3.09it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 2080/2337 [11:11<01:22,  3.10it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2090/2337 [11:12<01:19,  3.11it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2100/2337 [11:13<01:15,  3.12it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2110/2337 [11:14<01:12,  3.13it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 2120/2337 [11:15<01:09,  3.14it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2130/2337 [11:16<01:05,  3.15it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2140/2337 [11:17<01:02,  3.16it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2150/2337 [11:18<00:59,  3.17it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2160/2337 [11:19<00:55,  3.18it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 2170/2337 [11:20<00:52,  3.19it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2180/2337 [11:22<00:49,  3.20it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2190/2337 [11:23<00:45,  3.21it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2200/2337 [11:24<00:42,  3.22it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 2210/2337 [11:25<00:39,  3.23it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2220/2337 [11:26<00:36,  3.23it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2230/2337 [11:27<00:32,  3.24it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2240/2337 [11:28<00:29,  3.25it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 2250/2337 [11:29<00:26,  3.26it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:30<00:23,  3.27it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2270/2337 [11:31<00:20,  3.28it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2280/2337 [11:32<00:17,  3.29it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 2290/2337 [11:33<00:14,  3.30it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:34<00:11,  3.31it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:35<00:08,  3.32it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:37<00:05,  3.33it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:38<00:02,  3.34it/s, loss=0.13, v_num=-160]\n",
            "Epoch 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:39<00:00,  3.34it/s, loss=0.136, v_num=-160]\n",
            "Epoch 3:   0%|                 | 0/2337 [00:00<?, ?it/s, loss=0.136, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3:  87%|‚ñà‚ñà‚ñà‚ñà‚ñé| 2040/2337 [10:59<01:36,  3.09it/s, loss=0.0769, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2050/2337 [11:01<01:32,  3.10it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2060/2337 [11:02<01:29,  3.11it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2070/2337 [11:03<01:25,  3.12it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2080/2337 [11:04<01:22,  3.13it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2090/2337 [11:05<01:18,  3.14it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  90%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2100/2337 [11:06<01:15,  3.15it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  90%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:07<01:11,  3.16it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2120/2337 [11:08<01:08,  3.17it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2130/2337 [11:09<01:05,  3.18it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2140/2337 [11:10<01:01,  3.19it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2150/2337 [11:11<00:58,  3.20it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2160/2337 [11:12<00:55,  3.21it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:13<00:51,  3.22it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:15<00:48,  3.23it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:16<00:45,  3.24it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2200/2337 [11:17<00:42,  3.25it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2210/2337 [11:18<00:38,  3.26it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2220/2337 [11:19<00:35,  3.27it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  95%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:20<00:32,  3.28it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:21<00:29,  3.29it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:22<00:26,  3.30it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:23<00:23,  3.31it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2270/2337 [11:24<00:20,  3.32it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:25<00:17,  3.32it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:26<00:14,  3.33it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:27<00:11,  3.34it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:28<00:08,  3.35it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:30<00:05,  3.36it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:31<00:02,  3.37it/s, loss=0.0769, v_num=-160]\n",
            "Epoch 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:32<00:00,  3.38it/s, loss=0.0749, v_num=-160]\n",
            "Epoch 4:   0%|                | 0/2337 [00:00<?, ?it/s, loss=0.0749, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4:  87%|‚ñà‚ñà‚ñà‚ñà‚ñé| 2040/2337 [10:59<01:35,  3.10it/s, loss=0.0765, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2050/2337 [11:00<01:32,  3.10it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2060/2337 [11:01<01:28,  3.11it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2070/2337 [11:02<01:25,  3.12it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2080/2337 [11:03<01:21,  3.13it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2090/2337 [11:04<01:18,  3.14it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  90%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2100/2337 [11:05<01:15,  3.15it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  90%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:06<01:11,  3.16it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2120/2337 [11:07<01:08,  3.17it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2130/2337 [11:09<01:05,  3.18it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2140/2337 [11:10<01:01,  3.19it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2150/2337 [11:11<00:58,  3.20it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2160/2337 [11:12<00:55,  3.21it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:13<00:51,  3.22it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:14<00:48,  3.23it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:15<00:45,  3.24it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2200/2337 [11:16<00:42,  3.25it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2210/2337 [11:17<00:38,  3.26it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2220/2337 [11:18<00:35,  3.27it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  95%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:19<00:32,  3.28it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:20<00:29,  3.29it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:21<00:26,  3.30it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:22<00:23,  3.31it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2270/2337 [11:24<00:20,  3.32it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:25<00:17,  3.33it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:26<00:14,  3.34it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:27<00:11,  3.35it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:28<00:08,  3.36it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:29<00:05,  3.37it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:30<00:02,  3.37it/s, loss=0.0765, v_num=-160]\n",
            "Epoch 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:31<00:00,  3.38it/s, loss=0.0745, v_num=-160]\n",
            "Epoch 5:   0%|                | 0/2337 [00:00<?, ?it/s, loss=0.0745, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5:  87%|‚ñà‚ñà‚ñà‚ñà‚ñé| 2030/2337 [11:12<01:41,  3.02it/s, loss=0.0548, v_num=-160]5 epoch backuped: checkpoints/NeptuneLogger/AIC-160/checkpoints/epoch=4-step=3309.ckpt\n",
            "Epoch 5:  87%|‚ñà‚ñà‚ñà‚ñà‚ñé| 2040/2337 [11:14<01:38,  3.03it/s, loss=0.0548, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2050/2337 [11:15<01:34,  3.03it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2060/2337 [11:16<01:31,  3.04it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2070/2337 [11:18<01:27,  3.05it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2080/2337 [11:19<01:23,  3.06it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2090/2337 [11:20<01:20,  3.07it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  90%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2100/2337 [11:21<01:16,  3.08it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  90%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:22<01:13,  3.09it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2120/2337 [11:23<01:09,  3.10it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2130/2337 [11:24<01:06,  3.11it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2140/2337 [11:26<01:03,  3.12it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2150/2337 [11:27<00:59,  3.13it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2160/2337 [11:28<00:56,  3.14it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:29<00:53,  3.15it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:30<00:49,  3.16it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:31<00:46,  3.17it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2200/2337 [11:32<00:43,  3.18it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2210/2337 [11:34<00:39,  3.18it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2220/2337 [11:35<00:36,  3.19it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  95%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:36<00:33,  3.20it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:37<00:30,  3.21it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:38<00:27,  3.22it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:39<00:23,  3.23it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2270/2337 [11:40<00:20,  3.24it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:41<00:17,  3.25it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:43<00:14,  3.26it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:44<00:11,  3.27it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:45<00:08,  3.27it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:46<00:05,  3.28it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:47<00:02,  3.29it/s, loss=0.0548, v_num=-160]\n",
            "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:49<00:00,  3.30it/s, loss=0.0618, v_num=-160]\n",
            "Epoch 6:   0%|                | 0/2337 [00:00<?, ?it/s, loss=0.0618, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6:  87%|‚ñà‚ñà‚ñà‚ñà‚ñé| 2040/2337 [11:00<01:36,  3.09it/s, loss=0.0484, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2050/2337 [11:01<01:32,  3.10it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2060/2337 [11:02<01:29,  3.11it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2070/2337 [11:03<01:25,  3.12it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2080/2337 [11:04<01:22,  3.13it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2090/2337 [11:05<01:18,  3.14it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  90%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2100/2337 [11:07<01:15,  3.15it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  90%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:08<01:11,  3.16it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2120/2337 [11:09<01:08,  3.17it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2130/2337 [11:10<01:05,  3.18it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2140/2337 [11:11<01:01,  3.19it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2150/2337 [11:12<00:58,  3.20it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2160/2337 [11:13<00:55,  3.21it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:14<00:51,  3.22it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:15<00:48,  3.23it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:16<00:45,  3.24it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2200/2337 [11:17<00:42,  3.25it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2210/2337 [11:18<00:39,  3.26it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2220/2337 [11:19<00:35,  3.27it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  95%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:20<00:32,  3.27it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:22<00:29,  3.28it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:23<00:26,  3.29it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:24<00:23,  3.30it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2270/2337 [11:25<00:20,  3.31it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:26<00:17,  3.32it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:27<00:14,  3.33it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:28<00:11,  3.34it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:29<00:08,  3.35it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:30<00:05,  3.36it/s, loss=0.0484, v_num=-160]\n",
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:31<00:02,  3.37it/s, loss=0.0484, v_num=-160]\n",
            "Validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 300/301 [00:32<00:00,  9.33it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:32<00:00,  3.37it/s, loss=0.0492, v_num=-160]\n",
            "Epoch 7:   0%|                | 0/2337 [00:00<?, ?it/s, loss=0.0492, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7:  87%|‚ñà‚ñà‚ñà‚ñà‚ñé| 2040/2337 [10:58<01:35,  3.10it/s, loss=0.0447, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2050/2337 [11:00<01:32,  3.11it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2060/2337 [11:01<01:28,  3.12it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2070/2337 [11:02<01:25,  3.13it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2080/2337 [11:03<01:21,  3.14it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2090/2337 [11:04<01:18,  3.15it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  90%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2100/2337 [11:05<01:15,  3.16it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  90%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:06<01:11,  3.17it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2120/2337 [11:07<01:08,  3.18it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2130/2337 [11:08<01:04,  3.18it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2140/2337 [11:09<01:01,  3.19it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2150/2337 [11:10<00:58,  3.20it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2160/2337 [11:11<00:55,  3.21it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:13<00:51,  3.22it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:14<00:48,  3.23it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:15<00:45,  3.24it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2200/2337 [11:16<00:42,  3.25it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2210/2337 [11:17<00:38,  3.26it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2220/2337 [11:18<00:35,  3.27it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  95%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:19<00:32,  3.28it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:20<00:29,  3.29it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:21<00:26,  3.30it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:22<00:23,  3.31it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2270/2337 [11:23<00:20,  3.32it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:24<00:17,  3.33it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:25<00:14,  3.34it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:27<00:11,  3.35it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:28<00:08,  3.36it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:29<00:05,  3.37it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:30<00:02,  3.38it/s, loss=0.0447, v_num=-160]\n",
            "Epoch 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:31<00:00,  3.38it/s, loss=0.0443, v_num=-160]\n",
            "Epoch 8:   0%|                | 0/2337 [00:00<?, ?it/s, loss=0.0443, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8:  87%|‚ñà‚ñà‚ñà‚ñà‚ñé| 2040/2337 [10:57<01:35,  3.10it/s, loss=0.0429, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2050/2337 [10:59<01:32,  3.11it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2060/2337 [11:00<01:28,  3.12it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2070/2337 [11:01<01:25,  3.13it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2080/2337 [11:02<01:21,  3.14it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2090/2337 [11:03<01:18,  3.15it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  90%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2100/2337 [11:04<01:15,  3.16it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  90%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:05<01:11,  3.17it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2120/2337 [11:06<01:08,  3.18it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2130/2337 [11:07<01:04,  3.19it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2140/2337 [11:08<01:01,  3.20it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2150/2337 [11:10<00:58,  3.21it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2160/2337 [11:11<00:54,  3.22it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:12<00:51,  3.23it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:13<00:48,  3.24it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:14<00:45,  3.25it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2200/2337 [11:15<00:42,  3.26it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2210/2337 [11:16<00:38,  3.27it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2220/2337 [11:17<00:35,  3.28it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  95%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:18<00:32,  3.29it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:19<00:29,  3.30it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:20<00:26,  3.30it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:21<00:23,  3.31it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2270/2337 [11:22<00:20,  3.32it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:24<00:17,  3.33it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:25<00:14,  3.34it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:26<00:11,  3.35it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:27<00:08,  3.36it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:28<00:05,  3.37it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:29<00:02,  3.38it/s, loss=0.0429, v_num=-160]\n",
            "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:30<00:00,  3.38it/s, loss=0.0434, v_num=-160]\n",
            "Epoch 9:   0%|                | 0/2337 [00:00<?, ?it/s, loss=0.0434, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9:  87%|‚ñà‚ñà‚ñà‚ñà‚ñé| 2040/2337 [10:57<01:35,  3.10it/s, loss=0.0393, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2050/2337 [10:58<01:32,  3.11it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  88%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2060/2337 [10:59<01:28,  3.12it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2070/2337 [11:00<01:25,  3.13it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2080/2337 [11:01<01:21,  3.14it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  89%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2090/2337 [11:02<01:18,  3.15it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  90%|‚ñà‚ñà‚ñà‚ñà‚ñç| 2100/2337 [11:03<01:14,  3.16it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  90%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:04<01:11,  3.17it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2120/2337 [11:06<01:08,  3.18it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  91%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2130/2337 [11:07<01:04,  3.19it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2140/2337 [11:08<01:01,  3.20it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2150/2337 [11:09<00:58,  3.21it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  92%|‚ñà‚ñà‚ñà‚ñà‚ñå| 2160/2337 [11:10<00:54,  3.22it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:11<00:51,  3.23it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  93%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:12<00:48,  3.24it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:13<00:45,  3.25it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  94%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2200/2337 [11:14<00:42,  3.26it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2210/2337 [11:15<00:38,  3.27it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  95%|‚ñà‚ñà‚ñà‚ñà‚ñã| 2220/2337 [11:16<00:35,  3.28it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  95%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:17<00:32,  3.29it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:18<00:29,  3.30it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  96%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:19<00:26,  3.31it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:21<00:23,  3.32it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  97%|‚ñà‚ñà‚ñà‚ñà‚ñä| 2270/2337 [11:22<00:20,  3.33it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:23<00:17,  3.34it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:24<00:14,  3.35it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  98%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:25<00:11,  3.36it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:26<00:08,  3.37it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9:  99%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:27<00:05,  3.37it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:28<00:02,  3.38it/s, loss=0.0393, v_num=-160]\n",
            "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:29<00:00,  3.39it/s, loss=0.0378, v_num=-160]\n",
            "Epoch 10:   0%|               | 0/2337 [00:00<?, ?it/s, loss=0.0378, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10:  87%|‚ñà‚ñà‚ñà‚ñç| 2030/2337 [10:55<01:39,  3.10it/s, loss=0.0366, v_num=-160]10 epoch backuped: checkpoints/NeptuneLogger/AIC-160/checkpoints/epoch=9-step=3693.ckpt\n",
            "Epoch 10:  87%|‚ñà‚ñà‚ñà‚ñç| 2040/2337 [10:57<01:35,  3.10it/s, loss=0.0366, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10:  88%|‚ñà‚ñà‚ñà‚ñå| 2050/2337 [10:58<01:32,  3.11it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  88%|‚ñà‚ñà‚ñà‚ñå| 2060/2337 [10:59<01:28,  3.12it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  89%|‚ñà‚ñà‚ñà‚ñå| 2070/2337 [11:00<01:25,  3.13it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  89%|‚ñà‚ñà‚ñà‚ñå| 2080/2337 [11:01<01:21,  3.14it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  89%|‚ñà‚ñà‚ñà‚ñå| 2090/2337 [11:03<01:18,  3.15it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  90%|‚ñà‚ñà‚ñà‚ñå| 2100/2337 [11:04<01:14,  3.16it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  90%|‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:05<01:11,  3.17it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  91%|‚ñà‚ñà‚ñà‚ñã| 2120/2337 [11:06<01:08,  3.18it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  91%|‚ñà‚ñà‚ñà‚ñã| 2130/2337 [11:07<01:04,  3.19it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  92%|‚ñà‚ñà‚ñà‚ñã| 2140/2337 [11:08<01:01,  3.20it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  92%|‚ñà‚ñà‚ñà‚ñã| 2150/2337 [11:09<00:58,  3.21it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  92%|‚ñà‚ñà‚ñà‚ñã| 2160/2337 [11:10<00:54,  3.22it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  93%|‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:11<00:51,  3.23it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  93%|‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:12<00:48,  3.24it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  94%|‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:13<00:45,  3.25it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  94%|‚ñà‚ñà‚ñà‚ñä| 2200/2337 [11:14<00:42,  3.26it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  95%|‚ñà‚ñà‚ñà‚ñä| 2210/2337 [11:15<00:38,  3.27it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  95%|‚ñà‚ñà‚ñà‚ñä| 2220/2337 [11:17<00:35,  3.28it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  95%|‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:18<00:32,  3.29it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  96%|‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:19<00:29,  3.30it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  96%|‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:20<00:26,  3.31it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  97%|‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:21<00:23,  3.32it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  97%|‚ñà‚ñà‚ñà‚ñâ| 2270/2337 [11:22<00:20,  3.33it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  98%|‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:23<00:17,  3.34it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  98%|‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:24<00:14,  3.35it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  98%|‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:25<00:11,  3.35it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  99%|‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:26<00:08,  3.36it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10:  99%|‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:27<00:05,  3.37it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:28<00:02,  3.38it/s, loss=0.0366, v_num=-160]\n",
            "Epoch 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:30<00:00,  3.39it/s, loss=0.036, v_num=-160]\n",
            "Epoch 11:   0%|                | 0/2337 [00:00<?, ?it/s, loss=0.036, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11:  87%|‚ñà‚ñà‚ñà‚ñç| 2040/2337 [10:57<01:35,  3.10it/s, loss=0.0338, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11:  88%|‚ñà‚ñà‚ñà‚ñå| 2050/2337 [10:58<01:32,  3.11it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  88%|‚ñà‚ñà‚ñà‚ñå| 2060/2337 [10:59<01:28,  3.12it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  89%|‚ñà‚ñà‚ñà‚ñå| 2070/2337 [11:01<01:25,  3.13it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  89%|‚ñà‚ñà‚ñà‚ñå| 2080/2337 [11:02<01:21,  3.14it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  89%|‚ñà‚ñà‚ñà‚ñå| 2090/2337 [11:03<01:18,  3.15it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  90%|‚ñà‚ñà‚ñà‚ñå| 2100/2337 [11:04<01:14,  3.16it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  90%|‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:05<01:11,  3.17it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  91%|‚ñà‚ñà‚ñà‚ñã| 2120/2337 [11:06<01:08,  3.18it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  91%|‚ñà‚ñà‚ñà‚ñã| 2130/2337 [11:07<01:04,  3.19it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  92%|‚ñà‚ñà‚ñà‚ñã| 2140/2337 [11:08<01:01,  3.20it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  92%|‚ñà‚ñà‚ñà‚ñã| 2150/2337 [11:09<00:58,  3.21it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  92%|‚ñà‚ñà‚ñà‚ñã| 2160/2337 [11:10<00:54,  3.22it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  93%|‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:11<00:51,  3.23it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  93%|‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:12<00:48,  3.24it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  94%|‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:13<00:45,  3.25it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  94%|‚ñà‚ñà‚ñà‚ñä| 2200/2337 [11:15<00:42,  3.26it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  95%|‚ñà‚ñà‚ñà‚ñä| 2210/2337 [11:16<00:38,  3.27it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  95%|‚ñà‚ñà‚ñà‚ñä| 2220/2337 [11:17<00:35,  3.28it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  95%|‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:18<00:32,  3.29it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  96%|‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:19<00:29,  3.30it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  96%|‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:20<00:26,  3.31it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  97%|‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:21<00:23,  3.32it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  97%|‚ñà‚ñà‚ñà‚ñâ| 2270/2337 [11:22<00:20,  3.33it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  98%|‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:23<00:17,  3.33it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  98%|‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:24<00:14,  3.34it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  98%|‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:25<00:11,  3.35it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  99%|‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:26<00:08,  3.36it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11:  99%|‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:27<00:05,  3.37it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:29<00:02,  3.38it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 11: 100%|‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:30<00:00,  3.39it/s, loss=0.0338, v_num=-160]\n",
            "Epoch 12:   0%|               | 0/2337 [00:00<?, ?it/s, loss=0.0338, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12:  87%|‚ñà‚ñà‚ñà‚ñç| 2040/2337 [10:57<01:35,  3.10it/s, loss=0.0322, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12:  88%|‚ñà‚ñà‚ñà‚ñå| 2050/2337 [10:59<01:32,  3.11it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  88%|‚ñà‚ñà‚ñà‚ñå| 2060/2337 [11:00<01:28,  3.12it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  89%|‚ñà‚ñà‚ñà‚ñå| 2070/2337 [11:01<01:25,  3.13it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  89%|‚ñà‚ñà‚ñà‚ñå| 2080/2337 [11:02<01:21,  3.14it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  89%|‚ñà‚ñà‚ñà‚ñå| 2090/2337 [11:03<01:18,  3.15it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  90%|‚ñà‚ñà‚ñà‚ñå| 2100/2337 [11:04<01:15,  3.16it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  90%|‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:05<01:11,  3.17it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  91%|‚ñà‚ñà‚ñà‚ñã| 2120/2337 [11:06<01:08,  3.18it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  91%|‚ñà‚ñà‚ñà‚ñã| 2130/2337 [11:07<01:04,  3.19it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  92%|‚ñà‚ñà‚ñà‚ñã| 2140/2337 [11:09<01:01,  3.20it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  92%|‚ñà‚ñà‚ñà‚ñã| 2150/2337 [11:10<00:58,  3.21it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  92%|‚ñà‚ñà‚ñà‚ñã| 2160/2337 [11:11<00:54,  3.22it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  93%|‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:12<00:51,  3.23it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  93%|‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:13<00:48,  3.24it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  94%|‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:14<00:45,  3.25it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  94%|‚ñà‚ñà‚ñà‚ñä| 2200/2337 [11:15<00:42,  3.26it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  95%|‚ñà‚ñà‚ñà‚ñä| 2210/2337 [11:16<00:38,  3.27it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  95%|‚ñà‚ñà‚ñà‚ñä| 2220/2337 [11:17<00:35,  3.28it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  95%|‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:18<00:32,  3.29it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  96%|‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:19<00:29,  3.30it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  96%|‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:20<00:26,  3.30it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  97%|‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:21<00:23,  3.31it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  97%|‚ñà‚ñà‚ñà‚ñâ| 2270/2337 [11:22<00:20,  3.32it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  98%|‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:24<00:17,  3.33it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  98%|‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:25<00:14,  3.34it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  98%|‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:26<00:11,  3.35it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  99%|‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:27<00:08,  3.36it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12:  99%|‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:28<00:05,  3.37it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:29<00:02,  3.38it/s, loss=0.0322, v_num=-160]\n",
            "Epoch 12: 100%|‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:30<00:00,  3.38it/s, loss=0.0316, v_num=-160]\n",
            "Epoch 13:   0%|               | 0/2337 [00:00<?, ?it/s, loss=0.0316, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13:  87%|‚ñà‚ñà‚ñà‚ñç| 2040/2337 [10:57<01:35,  3.10it/s, loss=0.0305, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 13:  88%|‚ñà‚ñà‚ñà‚ñå| 2050/2337 [10:58<01:32,  3.11it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  88%|‚ñà‚ñà‚ñà‚ñå| 2060/2337 [10:59<01:28,  3.12it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  89%|‚ñà‚ñà‚ñà‚ñå| 2070/2337 [11:01<01:25,  3.13it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  89%|‚ñà‚ñà‚ñà‚ñå| 2080/2337 [11:02<01:21,  3.14it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  89%|‚ñà‚ñà‚ñà‚ñå| 2090/2337 [11:03<01:18,  3.15it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  90%|‚ñà‚ñà‚ñà‚ñå| 2100/2337 [11:04<01:14,  3.16it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  90%|‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:05<01:11,  3.17it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  91%|‚ñà‚ñà‚ñà‚ñã| 2120/2337 [11:06<01:08,  3.18it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  91%|‚ñà‚ñà‚ñà‚ñã| 2130/2337 [11:07<01:04,  3.19it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  92%|‚ñà‚ñà‚ñà‚ñã| 2140/2337 [11:08<01:01,  3.20it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  92%|‚ñà‚ñà‚ñà‚ñã| 2150/2337 [11:09<00:58,  3.21it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  92%|‚ñà‚ñà‚ñà‚ñã| 2160/2337 [11:10<00:54,  3.22it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  93%|‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:11<00:51,  3.23it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  93%|‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:12<00:48,  3.24it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  94%|‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:13<00:45,  3.25it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  94%|‚ñà‚ñà‚ñà‚ñä| 2200/2337 [11:14<00:42,  3.26it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  95%|‚ñà‚ñà‚ñà‚ñä| 2210/2337 [11:16<00:38,  3.27it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  95%|‚ñà‚ñà‚ñà‚ñä| 2220/2337 [11:17<00:35,  3.28it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  95%|‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:18<00:32,  3.29it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  96%|‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:19<00:29,  3.30it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  96%|‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:20<00:26,  3.31it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  97%|‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:21<00:23,  3.32it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  97%|‚ñà‚ñà‚ñà‚ñâ| 2270/2337 [11:22<00:20,  3.33it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  98%|‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:23<00:17,  3.34it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  98%|‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:24<00:14,  3.34it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  98%|‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:25<00:11,  3.35it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  99%|‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:26<00:08,  3.36it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13:  99%|‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:27<00:05,  3.37it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:28<00:02,  3.38it/s, loss=0.0305, v_num=-160]\n",
            "Epoch 13: 100%|‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:30<00:00,  3.39it/s, loss=0.0308, v_num=-160]\n",
            "Epoch 14:   0%|               | 0/2337 [00:00<?, ?it/s, loss=0.0308, v_num=-160]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14:  87%|‚ñà‚ñà‚ñà‚ñç| 2040/2337 [11:01<01:36,  3.08it/s, loss=0.0307, v_num=-160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0%|                                       | 0/301 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 14:  88%|‚ñà‚ñà‚ñà‚ñå| 2050/2337 [11:03<01:32,  3.09it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  88%|‚ñà‚ñà‚ñà‚ñå| 2060/2337 [11:04<01:29,  3.10it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  89%|‚ñà‚ñà‚ñà‚ñå| 2070/2337 [11:05<01:25,  3.11it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  89%|‚ñà‚ñà‚ñà‚ñå| 2080/2337 [11:06<01:22,  3.12it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  89%|‚ñà‚ñà‚ñà‚ñå| 2090/2337 [11:07<01:18,  3.13it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  90%|‚ñà‚ñà‚ñà‚ñå| 2100/2337 [11:08<01:15,  3.14it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  90%|‚ñà‚ñà‚ñà‚ñå| 2110/2337 [11:10<01:12,  3.15it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  91%|‚ñà‚ñà‚ñà‚ñã| 2120/2337 [11:11<01:08,  3.16it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  91%|‚ñà‚ñà‚ñà‚ñã| 2130/2337 [11:12<01:05,  3.17it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  92%|‚ñà‚ñà‚ñà‚ñã| 2140/2337 [11:13<01:01,  3.18it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  92%|‚ñà‚ñà‚ñà‚ñã| 2150/2337 [11:14<00:58,  3.19it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  92%|‚ñà‚ñà‚ñà‚ñã| 2160/2337 [11:15<00:55,  3.20it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  93%|‚ñà‚ñà‚ñà‚ñã| 2170/2337 [11:16<00:52,  3.21it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  93%|‚ñà‚ñà‚ñà‚ñã| 2180/2337 [11:18<00:48,  3.22it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  94%|‚ñà‚ñà‚ñà‚ñã| 2190/2337 [11:19<00:45,  3.22it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  94%|‚ñà‚ñà‚ñà‚ñä| 2200/2337 [11:20<00:42,  3.23it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  95%|‚ñà‚ñà‚ñà‚ñä| 2210/2337 [11:21<00:39,  3.24it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  95%|‚ñà‚ñà‚ñà‚ñä| 2220/2337 [11:22<00:35,  3.25it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  95%|‚ñà‚ñà‚ñà‚ñä| 2230/2337 [11:23<00:32,  3.26it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  96%|‚ñà‚ñà‚ñà‚ñä| 2240/2337 [11:24<00:29,  3.27it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  96%|‚ñà‚ñà‚ñà‚ñä| 2250/2337 [11:25<00:26,  3.28it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  97%|‚ñà‚ñà‚ñà‚ñä| 2260/2337 [11:27<00:23,  3.29it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  97%|‚ñà‚ñà‚ñà‚ñâ| 2270/2337 [11:28<00:20,  3.30it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  98%|‚ñà‚ñà‚ñà‚ñâ| 2280/2337 [11:29<00:17,  3.31it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  98%|‚ñà‚ñà‚ñà‚ñâ| 2290/2337 [11:30<00:14,  3.32it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  98%|‚ñà‚ñà‚ñà‚ñâ| 2300/2337 [11:31<00:11,  3.33it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  99%|‚ñà‚ñà‚ñà‚ñâ| 2310/2337 [11:32<00:08,  3.33it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14:  99%|‚ñà‚ñà‚ñà‚ñâ| 2320/2337 [11:33<00:05,  3.34it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñâ| 2330/2337 [11:35<00:02,  3.35it/s, loss=0.0307, v_num=-160]\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:36<00:00,  3.36it/s, loss=0.03, v_num=-160]\n",
            "                                                                                \u001b[A14 epoch backuped: checkpoints/NeptuneLogger/AIC-160/checkpoints/epoch=14-step=3853.ckpt\n",
            "Epoch 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2337/2337 [11:37<00:00,  3.35it/s, loss=0.03, v_num=-160]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8CPhdRxwVZA"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQMU5EfwvpE9"
      },
      "source": [
        "# trainer.test(test_dataloaders=val_loader)#, ckpt_path='latest.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHfFgV0uJL84"
      },
      "source": [
        "## Stop online logger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rhu6ypKHJPAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e947cf-06f5-4240-cbd9-942a74beba16"
      },
      "source": [
        "exp_logger.experiment.stop()\n",
        "\n",
        "# M√¨nh kh√¥ng c√†i logger trong lightning module nh∆∞ng pl h·ªç t·ª± g·ªçi log khi trainer c√≥ logger\n",
        "# do ƒë√≥ c·∫ßn x√≥a logger ƒëi ƒë·ªÉ tr√°nh l·ªói khi ƒë√£ ng∆∞ng logger\n",
        "trainer.logger=None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Waiting for the remaining 34 operations to synchronize with Neptune. Do not kill this process.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n",
            "Still waiting for the remaining 34 operations (0.00% done). Please wait.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All 34 operations synced, thanks for waiting!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NdDA6uC13XV"
      },
      "source": [
        "# Evaluating model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQtRaoeOwVDP"
      },
      "source": [
        "## Visualize misclassified samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsU1QJa8zSl_"
      },
      "source": [
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdXrW8PC1qUN"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g50Y8yRZw6JT"
      },
      "source": [
        "## Public test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbEpXGUpFhF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52dcba0-056f-40c3-94e7-d98d6b6bc951"
      },
      "source": [
        "private_set = AICOVIDDataset('f_pub_test', torch.nn.ModuleList([transform0]), normalize=scaler, cleanup_after=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Archive have already downloaded\n",
            "\n",
            "> Extract complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|                                                  | 0/1233 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|‚ñå                                       | 19/1233 [00:00<00:06, 184.20it/s]\u001b[A\n",
            "  3%|‚ñà‚ñè                                      | 38/1233 [00:00<00:07, 169.41it/s]\u001b[A\n",
            "  5%|‚ñà‚ñä                                      | 56/1233 [00:00<00:08, 142.27it/s]\u001b[A\n",
            "  6%|‚ñà‚ñà‚ñé                                     | 71/1233 [00:00<00:08, 134.14it/s]\u001b[A\n",
            "  7%|‚ñà‚ñà‚ñâ                                     | 91/1233 [00:00<00:07, 153.00it/s]\u001b[A\n",
            "  9%|‚ñà‚ñà‚ñà‚ñç                                   | 107/1233 [00:00<00:07, 152.96it/s]\u001b[A\n",
            " 10%|‚ñà‚ñà‚ñà‚ñâ                                   | 123/1233 [00:00<00:07, 150.24it/s]\u001b[A\n",
            " 11%|‚ñà‚ñà‚ñà‚ñà‚ñç                                  | 140/1233 [00:00<00:07, 151.33it/s]\u001b[A\n",
            " 13%|‚ñà‚ñà‚ñà‚ñà‚ñà                                  | 159/1233 [00:01<00:06, 161.88it/s]\u001b[A\n",
            " 14%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                 | 176/1233 [00:01<00:06, 161.89it/s]\u001b[A\n",
            " 16%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                | 194/1233 [00:01<00:06, 165.20it/s]\u001b[A\n",
            " 17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                                | 211/1233 [00:01<00:06, 163.73it/s]\u001b[A\n",
            " 18%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                               | 228/1233 [00:01<00:06, 163.19it/s]\u001b[A\n",
            " 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                               | 245/1233 [00:01<00:06, 155.68it/s]\u001b[A\n",
            " 21%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                              | 261/1233 [00:01<00:06, 156.14it/s]\u001b[A\n",
            " 22%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                              | 277/1233 [00:01<00:06, 157.09it/s]\u001b[A\n",
            " 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                             | 296/1233 [00:01<00:05, 166.58it/s]\u001b[A\n",
            " 25%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                             | 313/1233 [00:01<00:05, 161.46it/s]\u001b[A\n",
            " 27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                            | 333/1233 [00:02<00:05, 171.82it/s]\u001b[A\n",
            " 28%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 351/1233 [00:02<00:05, 154.94it/s]\u001b[A\n",
            " 30%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                           | 370/1233 [00:02<00:05, 163.71it/s]\u001b[A\n",
            " 31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 388/1233 [00:02<00:05, 167.03it/s]\u001b[A\n",
            " 33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                          | 405/1233 [00:02<00:05, 162.17it/s]\u001b[A\n",
            " 34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                         | 422/1233 [00:02<00:04, 164.23it/s]\u001b[A\n",
            " 36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                         | 441/1233 [00:02<00:04, 171.04it/s]\u001b[A\n",
            " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                        | 462/1233 [00:02<00:04, 181.75it/s]\u001b[A\n",
            " 39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                       | 483/1233 [00:02<00:03, 188.97it/s]\u001b[A\n",
            " 41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                       | 503/1233 [00:03<00:03, 186.29it/s]\u001b[A\n",
            " 42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 524/1233 [00:03<00:03, 190.94it/s]\u001b[A\n",
            " 44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 544/1233 [00:03<00:03, 183.75it/s]\u001b[A\n",
            " 46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                     | 563/1233 [00:03<00:03, 178.49it/s]\u001b[A\n",
            " 47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                    | 581/1233 [00:03<00:03, 163.51it/s]\u001b[A\n",
            " 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                    | 601/1233 [00:03<00:03, 172.96it/s]\u001b[A\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                   | 619/1233 [00:03<00:03, 161.56it/s]\u001b[A\n",
            " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                  | 638/1233 [00:03<00:03, 168.12it/s]\u001b[A\n",
            " 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                  | 656/1233 [00:03<00:03, 158.54it/s]\u001b[A\n",
            " 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                 | 673/1233 [00:04<00:03, 155.82it/s]\u001b[A\n",
            " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                 | 689/1233 [00:04<00:03, 156.56it/s]\u001b[A\n",
            " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                | 706/1233 [00:04<00:03, 160.12it/s]\u001b[A\n",
            " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 727/1233 [00:04<00:03, 168.40it/s]\u001b[A\n",
            " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå               | 746/1233 [00:04<00:02, 169.14it/s]\u001b[A\n",
            " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé              | 767/1233 [00:04<00:02, 179.04it/s]\u001b[A\n",
            " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ              | 787/1233 [00:04<00:02, 179.27it/s]\u001b[A\n",
            " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå             | 810/1233 [00:04<00:02, 188.05it/s]\u001b[A\n",
            " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 829/1233 [00:04<00:02, 180.30it/s]\u001b[A\n",
            " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä            | 848/1233 [00:05<00:02, 182.13it/s]\u001b[A\n",
            " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 868/1233 [00:05<00:01, 186.49it/s]\u001b[A\n",
            " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 887/1233 [00:05<00:01, 180.57it/s]\u001b[A\n",
            " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 909/1233 [00:05<00:01, 189.84it/s]\u001b[A\n",
            " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 929/1233 [00:05<00:01, 186.09it/s]\u001b[A\n",
            " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 948/1233 [00:05<00:01, 177.08it/s]\u001b[A\n",
            " 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå        | 966/1233 [00:05<00:01, 169.18it/s]\u001b[A\n",
            " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè       | 985/1233 [00:05<00:01, 173.99it/s]\u001b[A\n",
            " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 1006/1233 [00:05<00:01, 183.91it/s]\u001b[A\n",
            " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå      | 1025/1233 [00:06<00:01, 118.93it/s]\u001b[A\n",
            " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà      | 1040/1233 [00:06<00:01, 113.98it/s]\u001b[A\n",
            " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 1059/1233 [00:06<00:01, 129.80it/s]\u001b[A\n",
            " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 1075/1233 [00:06<00:01, 136.69it/s]\u001b[A\n",
            " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 1091/1233 [00:06<00:01, 140.39it/s]\u001b[A\n",
            " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 1107/1233 [00:06<00:00, 133.48it/s]\u001b[A\n",
            " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 1122/1233 [00:06<00:00, 132.83it/s]\u001b[A\n",
            " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 1139/1233 [00:07<00:00, 141.76it/s]\u001b[A\n",
            " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 1155/1233 [00:07<00:00, 144.99it/s]\u001b[A\n",
            " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 1173/1233 [00:07<00:00, 149.75it/s]\u001b[A\n",
            " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 1189/1233 [00:07<00:00, 147.32it/s]\u001b[A\n",
            " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 1204/1233 [00:07<00:00, 144.43it/s]\u001b[A\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1233/1233 [00:07<00:00, 160.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> File processing complete\n",
            "\n",
            "> Start normalizing data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|                                                  | 0/1233 [00:00<?, ?it/s]\u001b[A\n",
            " 12%|‚ñà‚ñà‚ñà‚ñà‚ñã                                 | 151/1233 [00:00<00:00, 1503.17it/s]\u001b[A\n",
            " 24%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                            | 302/1233 [00:00<00:00, 1484.19it/s]\u001b[A\n",
            " 37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                        | 455/1233 [00:00<00:00, 1501.30it/s]\u001b[A\n",
            " 49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                   | 606/1233 [00:00<00:00, 1457.68it/s]\u001b[A\n",
            " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè              | 752/1233 [00:00<00:00, 1440.64it/s]\u001b[A\n",
            " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 897/1233 [00:00<00:00, 1421.75it/s]\u001b[A\n",
            " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 1040/1233 [00:00<00:00, 1411.22it/s]\u001b[A\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1233/1233 [00:00<00:00, 1397.89it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "> Normalizing data complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNR8gns5FhF3"
      },
      "source": [
        "private_loader = torch.utils.data.DataLoader(\n",
        "    private_set,\n",
        "    collate_fn=collate_pad_1024_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8vo4LuEFlWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0ae1b6c-47fc-49c2-cd99-7b6d0bee32f4"
      },
      "source": [
        "preds = trainer.predict(dataloaders=private_loader)\n",
        "preds = torch.cat(preds)\n",
        "preds = preds.cpu().numpy()\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\rPredicting: 2036it [00:00, ?it/s]"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\rPredicting: 2036it [00:46, ?it/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.010e-01, 6.985e-03, 2.189e-01, ..., 2.187e-02, 5.571e-01,\n",
              "       3.678e-05], dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mlQ9N2J1x21"
      },
      "source": [
        "# L∆∞u k·∫øt qu·∫£"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Rb7KoY9Mi4Oj"
      },
      "source": [
        "#@markdown L∆∞u l·∫°i model l√™n Google Drive\n",
        "if train_mode:\n",
        "  os.system('mkdir trained_models')\n",
        "  compressed_name = f'{zip_name}_model.zip'\n",
        "  torch.save(model.state_dict(), './trained_models/model_weights.pth')\n",
        "  \n",
        "  os.system(f'zip -j ./{compressed_name} ./trained_models/*')\n",
        "  drive.Upload(compressed_name, model_zoo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQMWT6nXWebS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "29126209-4601-4603-db14-1259a7051654"
      },
      "source": [
        "#@markdown L∆∞u l·∫°i public test submission l√™n Google Drive\n",
        "submit_df = pd.DataFrame({'uuid': private_set.meta_df['uuid'],\n",
        "                          'assessment_result': preds})\n",
        "submit_df.to_csv('results.csv', index=False)\n",
        "\n",
        "# N√©n file\n",
        "os.system(f'zip -j ./{zip_name}.zip ./results.csv')\n",
        "\n",
        "drive.Upload(zip_name+'.zip', submission_folder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: results.csv (deflated 45%)\n",
            "Your browser has been opened to visit:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=324036170913-094orce5eji9sr78pstqsi3e6opo5jnp.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=online&response_type=code\n",
            "\n",
            "Opening in existing browser session.\n",
            "Authentication successful.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv4lQXEsrep-",
        "cellView": "form"
      },
      "source": [
        "#@markdown L∆∞u l·∫°i private test submission l√™n Google Drive\n",
        "submit_df = pd.DataFrame({'uuid': private_test_meta['uuid'],\n",
        "                          'assessment_result': preds})\n",
        "submit_df.to_csv('results.csv', index=False)\n",
        "\n",
        "# N√©n file\n",
        "os.system(f'zip -j ./{zip_name}_private_test.zip ./results.csv')\n",
        "\n",
        "drive.Upload(zip_name+'_private_test.zip', submission_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "lHzHpd7InP8M"
      },
      "source": [
        "#@markdown Load model l∆∞u s·∫µn\n",
        "if not train_mode:\n",
        "  drive.Download(f'{zip_name}_model.zip', model_zoo)\n",
        "  os.system(f'unzip -o {zip_name}_model.zip')\n",
        "  model.load_state_dict(torch.load('model_weights.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}