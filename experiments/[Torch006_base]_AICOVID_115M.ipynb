{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Torch006_base] AICOVID_115M.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "g6trLD9GlZeY",
        "3ewK6TTR-tdL",
        "cQ1eHjGs_BnM",
        "9RPgo8DvmDeu",
        "gTp2e79LSHVx",
        "HEboAF063rLi",
        "KkxxsDa8r0ql",
        "g2Lc0HIA2ZjG",
        "Y1nyBy3_mgnh",
        "xlMNZ1_rqxex",
        "_GxCO0fvq1yr",
        "37j76Vm4q9P2",
        "_Y9lvxslO4sU",
        "8x6CcaJTyVJ2",
        "KLR3pZnkyYRn",
        "35ohhS599zA3"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fa9ad4c423f94e2d82336c7875edf8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_99191948268e4d3d9c9d0afa08a4bef1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb199159c2ba4082b91b51c42e0f1569",
              "IPY_MODEL_d2823aaf3c8749e685347875163b15f8"
            ]
          }
        },
        "99191948268e4d3d9c9d0afa08a4bef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "fb199159c2ba4082b91b51c42e0f1569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03085d9d46eb4d7ea7c5d7a39ef4e472",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_14f9bf82827f45a1a4bd1ad967d1416f"
          }
        },
        "d2823aaf3c8749e685347875163b15f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_159db56ce0d8458088c9a72499908571",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:01&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08d7b75a30b1450dbe7b819903367e52"
          }
        },
        "03085d9d46eb4d7ea7c5d7a39ef4e472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "14f9bf82827f45a1a4bd1ad967d1416f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "159db56ce0d8458088c9a72499908571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08d7b75a30b1450dbe7b819903367e52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4913c84fd74347e6b958abb5ac3a8de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2ec18fcd8ce4b278413fcaadca50091",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c360fed825142fda9cca5d1a718186f",
              "IPY_MODEL_ecc4bdb3bc0c4cc783285c77205479dc"
            ]
          }
        },
        "b2ec18fcd8ce4b278413fcaadca50091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "9c360fed825142fda9cca5d1a718186f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_813950ef55294d8c9c9333cb4a1d3140",
            "_dom_classes": [],
            "description": "Epoch 1:  65%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 124,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 80,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40ce94f506b5415f9f7e96a0754c1b60"
          }
        },
        "ecc4bdb3bc0c4cc783285c77205479dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad7a24f0fabf41a694f65dc2fe6aa962",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 80/124 [00:27&lt;00:15,  2.88it/s, loss=0.661, v_num=C-71]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a321e1efa46a483ab689e9c5698703d1"
          }
        },
        "813950ef55294d8c9c9333cb4a1d3140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40ce94f506b5415f9f7e96a0754c1b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad7a24f0fabf41a694f65dc2fe6aa962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a321e1efa46a483ab689e9c5698703d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0eb953f1800466e9cea748284cc7f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1675202443ee49968ff98b7150180722",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_65f6beee2c5c44178c0bc9a5b0978451",
              "IPY_MODEL_c6a76d7514464d519a5db4f9c75471de"
            ]
          }
        },
        "1675202443ee49968ff98b7150180722": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "65f6beee2c5c44178c0bc9a5b0978451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d2cda7ea3a444a9a162b836e66c0b49",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 8,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 8,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0616081f2b6547cf90094d1e86c78c70"
          }
        },
        "c6a76d7514464d519a5db4f9c75471de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b41011dd80a7466ab85c5ed32b447ebb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 8/8 [00:01&lt;00:00,  6.09it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71b9c6bde7324719b2704372cd013cba"
          }
        },
        "2d2cda7ea3a444a9a162b836e66c0b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0616081f2b6547cf90094d1e86c78c70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b41011dd80a7466ab85c5ed32b447ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71b9c6bde7324719b2704372cd013cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e272f66442a402fbfc0ac801d6fce6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2e1d1f38af9f4f7f8e88c2bbd321a362",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_78403d7821314514aef4b5beb7b8a523",
              "IPY_MODEL_babddf622a0944919716dcaa226117c6"
            ]
          }
        },
        "2e1d1f38af9f4f7f8e88c2bbd321a362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "78403d7821314514aef4b5beb7b8a523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2c0b996d8d214b529d5882232bed9a3a",
            "_dom_classes": [],
            "description": "Testing: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f87f31200fe4d24b00143c7aebce273"
          }
        },
        "babddf622a0944919716dcaa226117c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8c6b8ebdd084fe8aa4c8c85b94705ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 240/240 [00:04&lt;00:00, 52.16it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c375bd3295c4017a4179af4f70407f7"
          }
        },
        "2c0b996d8d214b529d5882232bed9a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f87f31200fe4d24b00143c7aebce273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8c6b8ebdd084fe8aa4c8c85b94705ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c375bd3295c4017a4179af4f70407f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4844be7af55d483bacf7105bc8631452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_36e09c71940442d194e139f6cafd37de",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aec298de56434afcb27c2ce4bad6ffdb",
              "IPY_MODEL_7f8bbf647f654f009b527675a98f4c65"
            ]
          }
        },
        "36e09c71940442d194e139f6cafd37de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "aec298de56434afcb27c2ce4bad6ffdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_430ff1b968884fe4ad3a9ddb50efd2b8",
            "_dom_classes": [],
            "description": "Predicting: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e1b8d2ae32e41d888b560b2b422e217"
          }
        },
        "7f8bbf647f654f009b527675a98f4c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d33a13605754c238c4f3593b153434b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 450/450 [00:03&lt;00:00, 137.58it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b109a2aad8c4a03abe8b2ec4c01dc71"
          }
        },
        "430ff1b968884fe4ad3a9ddb50efd2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e1b8d2ae32e41d888b560b2b422e217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d33a13605754c238c4f3593b153434b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b109a2aad8c4a03abe8b2ec4c01dc71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlozg/aicovid/blob/main/%5BTorch006_base%5D_AICOVID_115M.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYEmHeR7z_l1"
      },
      "source": [
        "Trong th√≠ nghi·ªám tr∆∞·ªõc, m√¨nh ƒë√£ t·∫≠p trung th·ª≠ (1) nhi·ªÅu lo·∫°i data (raw, chunking, augmented, SpecAug), (2) th·ª≠ c√°c tham s·ªë lr, batch size ƒë·ªÉ r√µ h∆°n. V√† m√¨nh c√≥ c√°c nh·∫≠n x√©t sau qua c√°c th·ª≠ nghi·ªám:\n",
        "- H·∫ßu h·∫øt tr∆∞·ªùng h·ª£p m√¥ h√¨nh **kh√¥ng h·ªôi t·ª• ƒë∆∞·ª£c**, ngo·∫°i tr·ª´ khi c√≥ chunking. L√Ω gi·∫£i ƒëi·ªÅu n√†y, m√¨nh nghƒ© l√† do ƒë·∫∑c tr∆∞ng c√≥ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh, nh∆∞ng d·ªØ li·ªáu c·ªßa m√¨nh l·∫°i l√† d·∫°ng sequence n√™n khi l·∫•y Global Avg s·∫Ω b·ªã m·ªù ƒëi ƒë·∫∑c tr∆∞ng. M·ªôt l√Ω gi·∫£i kh√°c l√† do chunking s·ª≠ d·ª•ng batch size l·ªõn h∆°n r·∫•t nhi·ªÅu n√™n m√¥ h√¨nh h·ªôi t·ª± ƒë∆∞·ª£c.\n",
        "\n",
        "Nh·∫≠n th·∫•y nh∆∞·ªõc ƒëi·ªÉm qu√° l·ªõn c·ªßa m√¥ h√¨nh CNN c≈©ng nh∆∞ s·ª± thi·∫øu h·ª•t ki·∫øn th·ª©c, trong kho·∫£ng gi·ªØa 2 th√≠ nghi·ªám m√¨nh ƒë√£ ƒë·ªçc D2L. Th·ª±c s·ª± m√† n√≥i vi·ªác ƒë·ªçc cu·ªën s√°ch n√†y r·∫•t h·ªØu √≠ch khi ƒë√£ cho m√¨nh r·∫•t nhi·ªÅu √Ω t∆∞·ªüng ƒë·ªÉ c·∫£i thi·ªán. Trong th√≠ nghi·ªám n√†y, m√¨nh s·∫Ω th·ª±c hi·ªán c√°c ƒëi·ªÅu sau:\n",
        "- ‚ûñ Th·ª≠ c·∫£i thi·ªán ki·∫øn tr√∫c ho·∫∑c th·ª≠ ki·∫øn tr√∫c m·ªõi. (t·∫°m ng∆∞ng, ƒë·ªçc th√™m paper; ƒë√£ t√¨m ƒë∆∞·ª£c c√°ch ƒë·ªÉ converge b·∫±ng ƒë·ªïi Adam -> SGD)\n",
        "- ‚úÖ T√¨m c√°ch s·ª≠ d·ª•ng torchmetrics ƒë√∫ng trong lightning module (do hay b·ªã l·ªói CUDA error: device-side assert triggered)\n",
        "- ‚úÖ S·ª≠ d·ª•ng auc metric (auc ch·ªâ d√πng ƒë∆∞·ª£c cho binary, th√≠ nghi·ªám tr∆∞·ªõc m√¨nh l√†m kh√¥ng ph·∫£i binary m√† l√† ph√¢n 2 l·ªõp ü§ß)\n",
        "- ‚úÖ S·ª≠ d·ª•ng neptune logger thay cho tensor board ƒë·ªÉ c√≥ th·ªÉ coi live.\n",
        "- ‚úÖ Log confusion matrix üò≥.\n",
        "- ‚úÖ C√≥ c∆° ch·∫ø l∆∞u checkpoint. \n",
        "- ‚úÖ M·ªü r·ªông ra l√† t√°i c∆° c·∫•u l·∫°i c√°c ƒëo·∫°n code kh√¥ng quan tr·ªçng th√†nh c√°c callback.\n",
        "- ‚úÖ Ph·∫ßn ƒë√°nh gi√° m√¥ h√¨nh ch∆∞a ho√†n ch·ªânh, c·∫ßn c·∫£i thi·ªán ƒë·ªÉ ho·∫°t ƒë·ªông tr∆°n tru h∆°n.\n",
        "\n",
        "B√™n c·∫°nh ƒë√≥ c√≤n c√≥ v·∫•n ƒë·ªÅ t·ªìn ƒë·ªçng:\n",
        "- Chunking khi·∫øn l∆∞·ª£ng data b√πng n·ªï."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ikasEdh-I_wD",
        "cellView": "form"
      },
      "source": [
        "#@title C√†i c√°c th∆∞ vi·ªán b·ªï sung.\n",
        "#@markdown (note: c√†i xong ph·∫£i restart runtime)\n",
        "\n",
        "#@markdown C√°c th∆∞ vi·ªán b·ªï sung bao g·ªìm:\n",
        "#@markdown - PyDrive2 (ƒë·ªÉ upload file c√≥ k√≠ch th∆∞·ªõc l·ªõn l√™n GDrive)\n",
        "#@markdown - torchaudio\n",
        "#@markdown - Pytorch Lightning\n",
        "#@markdown - Neptune client (ƒë·ªÉ t·∫°o logger coi online, tr√°nh ph·∫£i ng·ªìi canh v√† backup th·ªß c√¥ng khi d√πng tensor board)\n",
        "\n",
        "try:\n",
        "  import torchaudio\n",
        "except ImportError:\n",
        "  !pip install PyDrive2\n",
        "  !pip install torchaudio\n",
        "  !pip install pytorch-lightning\n",
        "  !pip install 'neptune-client[pytorch-lightning]'\n",
        "  exit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsOJoIodiHt1",
        "cellView": "form"
      },
      "source": [
        "#@title L·∫•y x√°c th·ª±c google ƒë·ªÉ upload/download file\n",
        "#@markdown Vui l√≤ng b·∫•m v√†o link khi ƒë∆∞·ª£c y√™u c·∫ßu v√† l·∫•y m√£ ƒë·ªÉ nh·∫≠p v√†o\n",
        "\n",
        "# X√°c th·ª±c google ƒë·ªÉ upload/download qua google drive\n",
        "from pydrive2.auth import GoogleAuth\n",
        "from pydrive2.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "class GDrive():\n",
        "    def __init__(self):\n",
        "        self._gauth = GoogleAuth()\n",
        "        self._gauth.credentials = self._get_creds()\n",
        "        self._drive = GoogleDrive(self._gauth)\n",
        "\n",
        "    def _get_creds(self):\n",
        "        auth.authenticate_user()\n",
        "        return GoogleCredentials.get_application_default()\n",
        "\n",
        "    def Refresh_Auth(self):\n",
        "        self._gauth.credentials = self._get_creds()\n",
        "\n",
        "    def SearchInFolder(self, parent_id, file_name):\n",
        "        self.Refresh_Auth()\n",
        "        return self._drive.ListFile({'q': f\"'{parent_id}' in parents and title = '{file_name}'\"}).GetList()\n",
        "\n",
        "    def CreateFile(self, file_name=None, parent_id=None):\n",
        "        self.Refresh_Auth()\n",
        "        file = self._drive.CreateFile({'title': file_name, \n",
        "                                       'parents': [{'id': parent_id}]})\n",
        "        return file\n",
        "\n",
        "    def Upload(self, file_path, parent_id, file_name=None):\n",
        "        if file_name == None:\n",
        "          file_name = file_path.split('/')[-1]\n",
        "        # Ki·ªÉm tra file t·ªìn t·∫°i\n",
        "        file_list = self.SearchInFolder(parent_id, file_name)\n",
        "        if len(file_list) > 1:\n",
        "          for file in file_list:\n",
        "            print('title: %s, id: %s' % (file['title'], file['id']))\n",
        "          raise NameError('More than 1 file with same name exist, please resolve this')\n",
        "        \n",
        "        elif len(file_list) == 0:\n",
        "          # File ch∆∞a c√≥ th√¨ t·∫°o m·ªõi\n",
        "          file = self.CreateFile(file_name, parent_id)\n",
        "        else:\n",
        "          # T·ªìn t·∫°i duy nh·∫•t 1 file\n",
        "          file = file_list[0]\n",
        "        \n",
        "        file.SetContentFile(file_path)\n",
        "        file.Upload()\n",
        "\n",
        "    def Download(self, file_name, parent_id):\n",
        "        # Ki·ªÉm tra file t·ªìn t·∫°i\n",
        "        file_list = self.SearchInFolder(parent_id, file_name)\n",
        "        if len(file_list) > 1:\n",
        "            for file in file_list:\n",
        "                print('title: %s, id: %s' % (file['title'], file['id']))\n",
        "            raise NameError('More than 1 file with same name exist, please resolve this')\n",
        "        elif len(file_list) == 0:\n",
        "            raise NameError(f'File named {file_name} not exist')\n",
        "        else:\n",
        "            # T·ªìn t·∫°i duy nh·∫•t 1 file\n",
        "            file = file_list[0]\n",
        "        \n",
        "        file.GetContentFile(file_name)\n",
        "\n",
        "drive = GDrive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8N-dhNNq152",
        "cellView": "form",
        "outputId": "26d0e218-47e0-4482-a588-a7e16c3ec30a"
      },
      "source": [
        "from getpass import getpass\n",
        "\n",
        "#@title Nh·∫≠p Neptune API token\n",
        "api_token = getpass('Enter your private Neptune API token: ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your private Neptune API token: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_pyzy0LjMrg"
      },
      "source": [
        "# Detect COVID-19 patients via forced-cough cell phone recording\n",
        "\n",
        "- **B√†i to√°n**: Nh·∫≠n di·ªán ng∆∞·ªùi nhi·ªÖm COVID-19 qua ti·∫øng ho √©p bu·ªôc\n",
        "    - **Input**: ƒêo·∫°n ghi √¢m ti·∫øng ho, tu·ªïi v√† gi·ªõi t√≠nh\n",
        "    - **Output**: Ph√¢n lo·∫°i ng∆∞·ªùi nhi·ªÖm b·ªánh hay kh√¥ng"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_YA074tx3l"
      },
      "source": [
        "## T√¨m hi·ªÉu b√†i to√°n \n",
        "Qua paper (https://dspace.mit.edu/bitstream/handle/1721.1/128954/09208795.pdf?sequence=1&isAllowed=y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pbmNRtmnFNl"
      },
      "source": [
        "# C√°c bi·∫øn thi·∫øt l·∫≠p cho th·ª≠ nghi·ªám"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9Pxvi0cclld",
        "cellView": "form"
      },
      "source": [
        "# N·∫øu mu·ªën train m√¥ h√¨nh th√¨ set th√†nh True\n",
        "train_mode = True #@param {type:\"boolean\"}\n",
        "experiment_id = '006' #@param {type:\"string\"}\n",
        "val_split = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.05}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPKjksovwzjL"
      },
      "source": [
        "# ID c·ªßa folder l∆∞u model tr√™n drive\n",
        "model_zoo = 'secret'\n",
        "# ID c·ªßa folder ch·ª©a submission\n",
        "submission_folder = 'secret'\n",
        "# T√™n c·ªßa file n√©n ƒë·ªÉ n·ªôp\n",
        "zip_name = f'Torch_ver{experiment_id}'\n",
        "# ID c·ªßa folder ch·ª©a data ƒë√£ preprocess\n",
        "datadump_folder = 'secret'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6trLD9GlZeY"
      },
      "source": [
        "# Setup\n",
        "Import th∆∞ vi·ªán, t·∫£i data, ƒë·ªçc data, t·∫°o helper function,..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ewK6TTR-tdL"
      },
      "source": [
        "## Import th∆∞ vi·ªán"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zceUdpcYV4aK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd501f1a-22db-4dd6-8c00-876a8983b202"
      },
      "source": [
        "# Qu·∫£n l√Ω file, folder\n",
        "import os\n",
        "\n",
        "# X·ª≠ l√Ω audio\n",
        "import torchaudio\n",
        "\n",
        "# Hi·ªán audio nghe th·ª≠\n",
        "import IPython.display as ipd\n",
        "from IPython.display import Audio, display\n",
        "from tqdm import tqdm\n",
        "\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "pl.utilities.seed.seed_everything(seed=1)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ1eHjGs_BnM"
      },
      "source": [
        "## T·∫£i d·ªØ li·ªáu\n",
        "Bao g·ªìm: warmup (public train, public test, private set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "aZvrpobaYbVy"
      },
      "source": [
        "%%capture\n",
        "# download public train data\n",
        "# official link: https://drive.google.com/file/d/1MPhz3zYl2yefCq-J5XySbFJt99BfKIZD/view\n",
        "# personal link: https://drive.google.com/file/d/1hoGLxjLmPY-pX-jSVGIaWIZhovQBMKU1/view?usp=sharing\n",
        "if not os.path.isfile('./aicv115m_public_train.zip'):\n",
        "  !gdown --id 1MPhz3zYl2yefCq-J5XySbFJt99BfKIZD\n",
        "  !unzip -o aicv115m_public_train.zip\n",
        "\n",
        "# dowload public test data\n",
        "# official link: https://drive.google.com/file/d/1UrMudzopA3CyR1Ih2J63Kfi2mY_0uhRK/view\n",
        "# personal link: https://drive.google.com/file/d/1X7vOjHos9f9w48-iTWyu5JElFqCjcH_R/view?usp=sharing\n",
        "if not os.path.isfile('./aicv115m_public_test.zip'):\n",
        "  !gdown --id 1UrMudzopA3CyR1Ih2J63Kfi2mY_0uhRK\n",
        "  !unzip -o aicv115m_public_test.zip\n",
        "\n",
        "# dowload private test data\n",
        "# personal link: https://drive.google.com/file/d/1Ec64sSm2dZqe3da_LVyE_jUBD0DnLyqB/view?usp=sharing\n",
        "if not os.path.isfile('./aicv115m_private_test.zip'):\n",
        "  !gdown --id 1Ec64sSm2dZqe3da_LVyE_jUBD0DnLyqB\n",
        "  !unzip -o aicv115m_private_test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RPgo8DvmDeu"
      },
      "source": [
        "## Setup th∆∞ m·ª•c ch·ª©a data v√† ƒë·ªçc meta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQu9TA9rtogL",
        "cellView": "form"
      },
      "source": [
        "#@markdown Gi·∫£i n√©n data\n",
        "%%capture\n",
        "!unzip -n aicv115m_public_train/train_audio_files_8k.zip\n",
        "!unzip -n aicv115m_public_test/public_test_audio_files_8k.zip\n",
        "\n",
        "train_path = 'train_audio_files_8k/'\n",
        "test_path = 'public_test_audio_files_8k/'\n",
        "private_test_path = 'aicv115m_private_test/private_test_audio_files_8k/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDG2YKjYvtH-",
        "outputId": "26ab21d6-51c1-4915-912c-50f8f0ccf256"
      },
      "source": [
        "print(f'Train path: {train_path}')\n",
        "print(f'Test path: {test_path}')\n",
        "print(f'Private test path: {private_test_path}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train path: train_audio_files_8k/\n",
            "Test path: public_test_audio_files_8k/\n",
            "Private test path: aicv115m_private_test/private_test_audio_files_8k/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLyEqGLbunhR",
        "cellView": "form"
      },
      "source": [
        "#@markdown ƒê·ªçc meta\n",
        "train_meta = pd.read_csv('aicv115m_public_train/metadata_train_challenge.csv')\n",
        "train_meta['file_path'] = train_path+train_meta['file_path']\n",
        "test_meta = pd.read_csv('aicv115m_public_test/metadata_public_test.csv')\n",
        "test_meta['file_path'] = test_path+test_meta['file_path']\n",
        "private_test_meta = pd.read_csv('aicv115m_private_test/metadata_private_test.csv')\n",
        "private_test_meta['file_path'] = private_test_path+private_test_meta['file_path']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlLbjcQdvZ7w",
        "outputId": "4687fad9-6a94-4096-9537-ccbb77e77c6c"
      },
      "source": [
        "display(train_meta.shape)\n",
        "train_meta.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(1199, 5)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>subject_gender</th>\n",
              "      <th>subject_age</th>\n",
              "      <th>assessment_result</th>\n",
              "      <th>file_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3284bcf1-2446-4f3a-ac66-14c76b294177</td>\n",
              "      <td>male</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_audio_files_8k/3284bcf1-2446-4f3a-ac66-1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>431334e1-5946-4576-bb51-8e342ccc22b4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>train_audio_files_8k/431334e1-5946-4576-bb51-8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1d6fac4b-1e7f-4bdc-81cd-3a720bfbb1e1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>train_audio_files_8k/1d6fac4b-1e7f-4bdc-81cd-3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c7ee0695-b2e7-4beb-b904-f1455c9609d9</td>\n",
              "      <td>male</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_audio_files_8k/c7ee0695-b2e7-4beb-b904-f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dd541704-b696-4181-8fd8-816daac0fcf9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>train_audio_files_8k/dd541704-b696-4181-8fd8-8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   uuid  ...                                          file_path\n",
              "0  3284bcf1-2446-4f3a-ac66-14c76b294177  ...  train_audio_files_8k/3284bcf1-2446-4f3a-ac66-1...\n",
              "1  431334e1-5946-4576-bb51-8e342ccc22b4  ...  train_audio_files_8k/431334e1-5946-4576-bb51-8...\n",
              "2  1d6fac4b-1e7f-4bdc-81cd-3a720bfbb1e1  ...  train_audio_files_8k/1d6fac4b-1e7f-4bdc-81cd-3...\n",
              "3  c7ee0695-b2e7-4beb-b904-f1455c9609d9  ...  train_audio_files_8k/c7ee0695-b2e7-4beb-b904-f...\n",
              "4  dd541704-b696-4181-8fd8-816daac0fcf9  ...  train_audio_files_8k/dd541704-b696-4181-8fd8-8...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fxXmdwxvitS",
        "outputId": "8fe56c0a-2220-4ac0-9689-c88e8831d013"
      },
      "source": [
        "display(test_meta.shape)\n",
        "test_meta.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(350, 4)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>subject_gender</th>\n",
              "      <th>subject_age</th>\n",
              "      <th>file_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>66ef1f05-fbb0-44cb-8bdb-8eb4df83359a</td>\n",
              "      <td>female</td>\n",
              "      <td>28.0</td>\n",
              "      <td>public_test_audio_files_8k/66ef1f05-fbb0-44cb-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>73d13a12-f9bc-4554-af49-be24f6024a25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>public_test_audio_files_8k/73d13a12-f9bc-4554-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d27dbe98-e061-4018-9900-d1f1d47feab1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>public_test_audio_files_8k/d27dbe98-e061-4018-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43c30e4c-5d35-4ebc-8235-8920b7688550</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>public_test_audio_files_8k/43c30e4c-5d35-4ebc-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1952aa84-d077-495d-a1a9-9686a30722e0</td>\n",
              "      <td>female</td>\n",
              "      <td>NaN</td>\n",
              "      <td>public_test_audio_files_8k/1952aa84-d077-495d-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   uuid  ...                                          file_path\n",
              "0  66ef1f05-fbb0-44cb-8bdb-8eb4df83359a  ...  public_test_audio_files_8k/66ef1f05-fbb0-44cb-...\n",
              "1  73d13a12-f9bc-4554-af49-be24f6024a25  ...  public_test_audio_files_8k/73d13a12-f9bc-4554-...\n",
              "2  d27dbe98-e061-4018-9900-d1f1d47feab1  ...  public_test_audio_files_8k/d27dbe98-e061-4018-...\n",
              "3  43c30e4c-5d35-4ebc-8235-8920b7688550  ...  public_test_audio_files_8k/43c30e4c-5d35-4ebc-...\n",
              "4  1952aa84-d077-495d-a1a9-9686a30722e0  ...  public_test_audio_files_8k/1952aa84-d077-495d-...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgMLDOItrKUM",
        "outputId": "40e5cc44-1d25-4a4d-cd8f-c2285f88f77d"
      },
      "source": [
        "display(private_test_meta.shape)\n",
        "private_test_meta.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(450, 4)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uuid</th>\n",
              "      <th>subject_gender</th>\n",
              "      <th>subject_age</th>\n",
              "      <th>file_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bce020a3-6ab7-46df-8a75-7f8009a1883e</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aicv115m_private_test/private_test_audio_files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>efe397fd-5ff1-41d8-b991-b8acdafd663c</td>\n",
              "      <td>male</td>\n",
              "      <td>45.0</td>\n",
              "      <td>aicv115m_private_test/private_test_audio_files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5954077a-4c41-4a2e-9cad-e3bb2d6402c4</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>aicv115m_private_test/private_test_audio_files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2b330c25-0816-480a-bb87-9d3d0d632c0c</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aicv115m_private_test/private_test_audio_files...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bfa78793-b3b8-42b8-bad0-77e3c55abfda</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aicv115m_private_test/private_test_audio_files...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   uuid  ...                                          file_path\n",
              "0  bce020a3-6ab7-46df-8a75-7f8009a1883e  ...  aicv115m_private_test/private_test_audio_files...\n",
              "1  efe397fd-5ff1-41d8-b991-b8acdafd663c  ...  aicv115m_private_test/private_test_audio_files...\n",
              "2  5954077a-4c41-4a2e-9cad-e3bb2d6402c4  ...  aicv115m_private_test/private_test_audio_files...\n",
              "3  2b330c25-0816-480a-bb87-9d3d0d632c0c  ...  aicv115m_private_test/private_test_audio_files...\n",
              "4  bfa78793-b3b8-42b8-bad0-77e3c55abfda  ...  aicv115m_private_test/private_test_audio_files...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTp2e79LSHVx"
      },
      "source": [
        "## H√†m x·ª≠ l√Ω √¢m thanh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjCQwg-opB0L",
        "cellView": "form"
      },
      "source": [
        "#@markdown ## C√°c h√†m v·ªè b·ªçc cho ƒë·ªçc file\n",
        "#@markdown `read_audio(path)`: v·ªè b·ªçc cho `torchaudio.load(path)`.<br>\n",
        "#@markdown `read_resample_audio(path)`: ch·ªâ tr·∫£ v·ªÅ wave v√¨ sample rate ƒë√£ ƒë∆∞·ª£c c·ªë ƒë·ªãnh.\n",
        "\n",
        "'''\n",
        "  Read audio from given path and return (wave, sample_rate)\n",
        "'''\n",
        "def read_audio(full_audio_path):\n",
        "  return torchaudio.load(full_audio_path)\n",
        "\n",
        "'''\n",
        "  Read audio from given path, then resample if sample rate is not matched \n",
        "  and return wave.\n",
        "\n",
        "  Tips: \n",
        "    you should provide resampler from torchaudio.transform\n",
        "    when batch resampling with same params since this can\n",
        "    give a huge speed up.\n",
        "'''\n",
        "def read_resample_audio(\n",
        "    full_audio_path, resample,\n",
        "    resampler=None\n",
        "):\n",
        "  wave, sr = torchaudio.load(full_audio_path)\n",
        "  if resampler is not None:\n",
        "      wave = resampler(wave)\n",
        "  elif sr != resample:\n",
        "      wave = torchaudio.functional.resample(wave, sr, resample)\n",
        "  return wave"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEboAF063rLi"
      },
      "source": [
        "### Audio features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPA3iLpQ1fhs"
      },
      "source": [
        "# Spectrogram transformation\n",
        "n_fft = 2048\n",
        "win_length = 160\n",
        "hop_length = 80\n",
        "n_mels = 200\n",
        "n_mfcc = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuHhNXmvCYuR",
        "cellView": "form"
      },
      "source": [
        "#@markdown `spectrogram(waveform)` --> spec \n",
        "spectrogram = torchaudio.transforms.Spectrogram(\n",
        "    n_fft=n_fft,\n",
        "    win_length=win_length,\n",
        "    hop_length=hop_length,\n",
        "    center=True,\n",
        "    normalized=True,\n",
        "    pad_mode=\"reflect\",\n",
        "    power=2.0,\n",
        ")\n",
        "\n",
        "#@markdown `mel_spectrogram(waveform)` --> mel_spec \n",
        "mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=8000,\n",
        "    n_fft=n_fft,\n",
        "    win_length=win_length,\n",
        "    hop_length=hop_length,\n",
        "    center=True,\n",
        "    pad_mode=\"reflect\",\n",
        "    power=2.0,\n",
        "    #norm='slaney',\n",
        "    onesided=True,\n",
        "    normalized=True,\n",
        "    n_mels=n_mels,\n",
        "    mel_scale=\"htk\",\n",
        ")\n",
        "\n",
        "#@markdown `log_spectrogram(spec)` --> log(spec)\n",
        "log_spectrogram = torchaudio.transforms.AmplitudeToDB(\n",
        "    stype='power',\n",
        "    top_db=80\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkxxsDa8r0ql"
      },
      "source": [
        "### Augmentation cho audio\n",
        "Bao g·ªìm: th√™m noise (nhi·ªÅu m·ª©c ƒë·ªô), SpecAugment, chunking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp1GX9b5pN_C",
        "cellView": "form"
      },
      "source": [
        "#@markdown `AudioChunking(chunk_size=400, chunk_step=200)`\n",
        "class AudioChunking(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 chunk_size: int=400,\n",
        "                 chunk_step: int=200) -> None:\n",
        "        super(AudioChunking, self).__init__()\n",
        "        self.chunk_size = chunk_size\n",
        "        self.chunk_step = chunk_step\n",
        "        \n",
        "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
        "        _, _, spec_len = spec.shape\n",
        "        pad_size = self.chunk_size - spec_len%self.chunk_size\n",
        "        pad_size = (pad_size//2, pad_size//2+pad_size%2)\n",
        "        padded_spec = torch.nn.functional.pad(spec, pad_size, mode='constant', value=0)\n",
        "        chunks = padded_spec.unfold(-1, self.chunk_size, self.chunk_step).permute(2,0,1,3)\n",
        "        return chunks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK5OCYJfpYz6",
        "cellView": "form"
      },
      "source": [
        "#@markdown `SpecAugment(time_W=50, freq_W=50, T=80, F=80)`\n",
        "def _h_poly(t):\n",
        "    tt = t.unsqueeze(-2)**torch.arange(4, device=t.device).view(-1,1)\n",
        "    A = torch.tensor([\n",
        "        [1, 0, -3, 2],\n",
        "        [0, 1, -2, 1],\n",
        "        [0, 0, 3, -2],\n",
        "        [0, 0, -1, 1]\n",
        "    ], dtype=t.dtype, device=t.device)\n",
        "    return A @ tt\n",
        "\n",
        "\n",
        "def _cspline_interpolate(x, y, xs):\n",
        "    '''\n",
        "    Input x and y must be of shape (batch, n) or (n)\n",
        "    '''\n",
        "    m = (y[..., 1:] - y[..., :-1]) / (x[..., 1:] - x[..., :-1])\n",
        "    m = torch.cat([m[...,[0]], (m[...,1:] + m[...,:-1]) / 2, m[...,[-1]]], -1)\n",
        "    idxs = torch.searchsorted(x[..., 1:], xs)\n",
        "    dx = (x.take_along_dim(idxs+1, dim=-1) - x.take_along_dim(idxs, dim=-1))\n",
        "    hh = _h_poly((xs - x.take_along_dim(idxs, dim=-1)) / dx)\n",
        "    return hh[...,0,:] * y.take_along_dim(idxs, dim=-1) \\\n",
        "        + hh[...,1,:] * m.take_along_dim(idxs, dim=-1) * dx \\\n",
        "        + hh[...,2,:] * y.take_along_dim(idxs+1, dim=-1) \\\n",
        "        + hh[...,3,:] * m.take_along_dim(idxs+1, dim=-1) * dx\n",
        "        \n",
        "\n",
        "class SpecAugment(torch.nn.Module):\n",
        "  def __init__(\n",
        "      self,\n",
        "      time_W: int = 0,\n",
        "      freq_W: int = 0,\n",
        "      T: int = 0,\n",
        "      F: int = 0,\n",
        "      mT: int = 1,\n",
        "      mF: int = 1\n",
        "  ) -> None:\n",
        "      super(SpecAugment, self).__init__()\n",
        "      self.identity_fn = lambda x: x\n",
        "      self.time_W = time_W\n",
        "      self.freq_W = freq_W\n",
        "      if time_W==0 and freq_W==0:\n",
        "          self.cum_warping = lambda x: x\n",
        "      elif time_W!=0 and freq_W==0:\n",
        "          self.cum_warping = self.time_warping\n",
        "      elif time_W==0 and freq_W!=0:\n",
        "          self.cum_warping = self.freq_warping\n",
        "      else:\n",
        "          self.cum_warping = self.time_freq_warping\n",
        "      self.time_masking = torchaudio.transforms.TimeMasking(time_mask_param=T) if T>0 else self.identity_fn\n",
        "      self.freq_masking = torchaudio.transforms.FrequencyMasking(freq_mask_param=F) if F>0 else self.identity_fn\n",
        "\n",
        "\n",
        "  def _get_warping_flow(self,\n",
        "                        warp_p: torch.Tensor,\n",
        "                        warp_d: torch.Tensor,\n",
        "                        interp_len: int) -> torch.Tensor:\n",
        "      '''\n",
        "      Get interpolated flow\n",
        "      Warning: This function doesn't check for batch size match between warp_p and warp_d\n",
        "      '''\n",
        "      device = warp_p.device\n",
        "      batch_size = warp_p.shape[0]\n",
        "\n",
        "      src_control_points = torch.stack([torch.tensor([0], device=device).expand(batch_size),\n",
        "                                        warp_p, torch.tensor([interp_len-1], device=device).expand(batch_size)], dim=1)\n",
        "      dest_control_points = torch.stack([torch.tensor([-1.], device=device).expand(batch_size),\n",
        "                                        (warp_p-warp_d)*2/(interp_len-1)-1, torch.tensor([1], device=device).expand(batch_size)], dim=1)\n",
        "\n",
        "      # Interpolate from 3 points to interp_len points\n",
        "      src_interp_points = torch.linspace(0, interp_len-1, interp_len, device=device).unsqueeze(0).expand(batch_size, -1)\n",
        "      dest_interp_points = _cspline_interpolate(src_control_points, dest_control_points, src_interp_points)\n",
        "\n",
        "      return dest_interp_points\n",
        "\n",
        "\n",
        "  def freq_warping(self, specs: torch.Tensor) -> torch.Tensor:\n",
        "      '''\n",
        "      Frequency warping augmentation, only return interpolated flow\n",
        "\n",
        "      param:\n",
        "        specs: spectrogram of size (batch, channel, freq_bin, length)\n",
        "      '''\n",
        "      W = self.freq_W\n",
        "      device = specs.device\n",
        "      batch_size, _, num_freqs, num_frames = specs.shape\n",
        "\n",
        "      warp_p = torch.randint(W, num_freqs - W, (batch_size,), device=device)\n",
        "\n",
        "      # Uniform distribution from (0,W) with chance to be up to W negative\n",
        "      warp_d = torch.randint(-W, W, (batch_size,), device=device)\n",
        "      \n",
        "      dest_freq_points = self._get_warping_flow(warp_p, warp_d, num_freqs)\n",
        "      dest_frame_points = torch.linspace(-1, 1, num_frames, device=device)\n",
        "\n",
        "      grid = torch.cat(\n",
        "          (dest_frame_points.view(-1,1).expand(batch_size,num_freqs,-1,-1),\n",
        "          dest_freq_points.view(batch_size,-1,1,1).expand(-1,-1,num_frames,-1)), dim=-1)\n",
        "\n",
        "      return torch.nn.functional.grid_sample(specs, grid, align_corners=True)\n",
        "\n",
        "\n",
        "  def time_warping(self, specs: torch.Tensor) -> torch.Tensor:\n",
        "      '''\n",
        "      Time warping augmentation, only return interpolated flow\n",
        "\n",
        "      param:\n",
        "        specs: spectrogram of size (batch, channel, freq_bin, length)\n",
        "      '''\n",
        "      W = self.time_W\n",
        "      device = specs.device\n",
        "      batch_size, _, num_freqs, num_frames = specs.shape\n",
        "\n",
        "      warp_p = torch.randint(W, num_frames - W, (batch_size,), device=device)\n",
        "\n",
        "      # Uniform distribution from (0,W) with chance to be up to W negative\n",
        "      warp_d = torch.randint(-W, W, (batch_size,), device=device)\n",
        "\n",
        "      # Interpolate from 3 points to num_frames points\n",
        "      dest_frame_points = self._get_warping_flow(warp_p, warp_d, num_frames)\n",
        "      dest_freq_points = torch.linspace(-1, 1, num_freqs, device=device)\n",
        "\n",
        "      grid = torch.cat(\n",
        "          (dest_frame_points.view(batch_size,1,-1,1).expand(-1,num_freqs,-1,-1),\n",
        "          dest_freq_points.view(-1,1,1).expand(batch_size,-1,num_frames,-1)), dim=-1)\n",
        "\n",
        "      return torch.nn.functional.grid_sample(specs, grid, align_corners=True)\n",
        "\n",
        "\n",
        "  def time_freq_warping(self,specs: torch.Tensor) -> torch.Tensor:\n",
        "      '''\n",
        "      Doing both time warping and frequency warping augmentation\n",
        "\n",
        "      param:\n",
        "        specs: spectrogram of size (batch, channel, freq_bin, length)\n",
        "        W: strength of warp\n",
        "      '''\n",
        "      device = specs.device\n",
        "      batch_size, _, num_freqs, num_frames = specs.shape\n",
        "\n",
        "      time_warp_p = torch.randint(self.time_W, num_frames - self.time_W, (batch_size,), device=device)\n",
        "      freq_warp_p = torch.randint(self.freq_W, num_freqs - self.freq_W, (batch_size,), device=device)\n",
        "\n",
        "      # Uniform distribution from (0,W) with chance to be up to W negative\n",
        "      time_warp_d = torch.randint(-self.time_W, self.time_W, (batch_size,), device=device)\n",
        "      freq_warp_d = torch.randint(-self.freq_W, self.freq_W, (batch_size,), device=device)\n",
        "\n",
        "      # Interpolate l√™n theo k√≠ch th∆∞·ªõc spec\n",
        "      dest_freq_points = self._get_warping_flow(freq_warp_p, freq_warp_d, num_freqs)\n",
        "      dest_frame_points = self._get_warping_flow(time_warp_p, time_warp_d, num_frames)\n",
        "\n",
        "      grid = torch.cat(\n",
        "          (dest_frame_points.view(batch_size,1,-1,1).expand(-1,num_freqs,-1,-1),\n",
        "          dest_freq_points.view(batch_size,-1,1,1).expand(-1,-1,num_frames,-1)), dim=-1)\n",
        "\n",
        "      return torch.nn.functional.grid_sample(specs, grid, align_corners=True)\n",
        "\n",
        "\n",
        "  def forward(self, specs: torch.Tensor) -> torch.Tensor:\n",
        "      aug_specs = self.cum_warping(specs)\n",
        "      aug_specs = self.time_masking(aug_specs)\n",
        "      aug_specs = self.freq_masking(aug_specs)\n",
        "      return aug_specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "fOlyVYDtuJDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49107a84-3384-4a59-d67f-60035206a1b7"
      },
      "source": [
        "#@markdown T·∫£i noise audio\n",
        "import requests\n",
        "\n",
        "!mkdir _sample_data\n",
        "SAMPLE_NOISE_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/distractors/rm1/babb/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo.wav\"\n",
        "SAMPLE_NOISE_PATH = os.path.join('_sample_data', \"bg.wav\")\n",
        "SAMPLE_RIR_URL = \"https://pytorch-tutorial-assets.s3.amazonaws.com/VOiCES_devkit/distant-16k/room-response/rm1/impulse/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo.wav\"\n",
        "SAMPLE_RIR_PATH = os.path.join('_sample_data', \"rir.wav\")\n",
        "\n",
        "def _fetch_data():\n",
        "  uri = [\n",
        "    (SAMPLE_NOISE_URL, SAMPLE_NOISE_PATH),\n",
        "    (SAMPLE_RIR_URL, SAMPLE_RIR_PATH)\n",
        "  ]\n",
        "  for url, path in uri:\n",
        "    with open(path, 'wb') as file_:\n",
        "      file_.write(requests.get(url).content)\n",
        "\n",
        "_fetch_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‚Äò_sample_data‚Äô: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcKSZU1F4rAK"
      },
      "source": [
        "def _get_sample(path, resample=None):\n",
        "  effects = [\n",
        "    [\"remix\", \"1\"]\n",
        "  ]\n",
        "  if resample:\n",
        "    effects.extend([\n",
        "      [\"lowpass\", f\"{resample // 2}\"],\n",
        "      [\"rate\", f'{resample}'],\n",
        "    ])\n",
        "  return torchaudio.sox_effects.apply_effects_file(path, effects=effects)\n",
        "\n",
        "def get_noise_sample(*, resample=None):\n",
        "  return _get_sample(SAMPLE_NOISE_PATH, resample=resample)\n",
        "\n",
        "def get_rir_sample(*, resample=None, processed=False):\n",
        "  rir_raw, sample_rate = _get_sample(SAMPLE_RIR_PATH, resample=resample)\n",
        "  if not processed:\n",
        "    return rir_raw, sample_rate\n",
        "  rir = rir_raw[:, int(sample_rate*1.01):int(sample_rate*1.3)]\n",
        "  rir = rir / torch.norm(rir, p=2)\n",
        "  rir = torch.flip(rir, [1])\n",
        "  return rir, sample_rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "BEH8Qh2SqH6c"
      },
      "source": [
        "import math\n",
        "\n",
        "#@markdown `RoomReverb`, `NoiseInject`, `PhoneSim`\n",
        "class RoomReverb(torch.nn.Module):\n",
        "    def __init__(self, rir_list):\n",
        "        super(RoomReverb, self).__init__()\n",
        "        self.rirs = rir_list\n",
        "\n",
        "    def _get_rir(self):\n",
        "        if type(self.rirs) is list:\n",
        "            return random.choice(self.rirs)\n",
        "        else: \n",
        "            return next(self.rirs)\n",
        "\n",
        "    def forward(self, wave: torch.Tensor):\n",
        "        rir = self._get_rir()\n",
        "        _wave = torch.nn.functional.pad(wave, (rir.shape[-1]-1, 0))\n",
        "        _wave = torch.nn.functional.conv1d(_wave[None, ...], rir[None, ...])[0]\n",
        "        return _wave\n",
        "\n",
        "\n",
        "class NoiseInject(torch.nn.Module):\n",
        "    def __init__(self, noise_list, snr_db):\n",
        "        super(NoiseInject, self).__init__()\n",
        "        self.noises = noise_list\n",
        "        self.snr_db = snr_db\n",
        "\n",
        "    def _get_noise(self):\n",
        "        if type(self.noises) is list:\n",
        "            return random.choice(self.noises)\n",
        "        else: \n",
        "            return next(self.noises)\n",
        "\n",
        "    def forward(self, wave: torch.Tensor):\n",
        "        noise = self._get_noise()\n",
        "        _noise = noise.repeat(1, 1 + wave.shape[-1] // noise.shape[-1])[..., :wave.shape[-1]]\n",
        "        scale = math.exp(self.snr_db / 10) * _noise.norm(p=2) / wave.norm(p=2)\n",
        "        _wave = (scale * wave + _noise) / 2\n",
        "        return _wave\n",
        "\n",
        "\n",
        "class PhoneSim(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PhoneSim, self).__init__()\n",
        "\n",
        "    def forward(self, wave: torch.Tensor):\n",
        "        device = wave.device\n",
        "        _wave = wave.cpu()\n",
        "        _wave, _ = torchaudio.sox_effects.apply_effects_tensor(\n",
        "          _wave, 8000,\n",
        "          effects=[[\"lowpass\", \"4000\"],\n",
        "                   [\"compand\", \"0.02,0.05\", \"-60,-60,-30,-10,-20,-8,-5,-8,-2,-8\", \"-8\", \"-7\", \"0.05\"]]\n",
        "        )\n",
        "        _wave = torchaudio.functional.apply_codec(_wave, 8000, format=\"gsm\")\n",
        "        return _wave.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6qT41qMqY10"
      },
      "source": [
        "rir, _ = get_rir_sample(resample=8000, processed=True)\n",
        "noise, _ = get_noise_sample(resample=8000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0yQgDHKF_VG",
        "cellView": "form"
      },
      "source": [
        "#@markdown `StandardScaler()`\n",
        "class StandardScaler(torch.nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(StandardScaler, self).__init__()\n",
        "        \n",
        "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
        "        return ((spec-spec.mean())/spec.std()).nan_to_num(posinf=0.0, neginf=0.0)\n",
        "\n",
        "#@markdown `MinMaxScaler()`\n",
        "class MinMaxScaler(torch.nn.Module):\n",
        "    def __init__(self, min=None, max=None) -> None:\n",
        "        super(MinMaxScaler, self).__init__()\n",
        "        if min:\n",
        "            self._min = lambda x: min\n",
        "        else:\n",
        "            self._min = lambda x: x.min()\n",
        "        if max:\n",
        "            self._max = lambda x: max\n",
        "        else:\n",
        "            self._max = lambda x: x.max()\n",
        "        \n",
        "    def forward(self, spec: torch.Tensor) -> torch.Tensor:\n",
        "        return ((spec-self._min(spec))/(self._max(spec)-self._min(spec))).nan_to_num(posinf=0.0, neginf=0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2Lc0HIA2ZjG"
      },
      "source": [
        "## C√°c h√†m b·ªï tr·ª£ tr·ª±c quan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQCI3iYC5fVe",
        "cellView": "form"
      },
      "source": [
        "#@markdown V·∫Ω specgram `plot_specgram(wave, sr, title, xlim, ylim)`\n",
        "#@markdown (specgram ch·ªâ ƒë∆°n gi·∫£n l√† apply discrete-time Fourier transform)\n",
        "\n",
        "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\", xlim=None):\n",
        "  # Tensor --> Numpy\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
        "\n",
        "  figure, axes = plt.subplots(num_channels, 1)\n",
        "  if num_channels == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "  # Plot specgram for each channel\n",
        "  for c in range(num_channels):\n",
        "    axes[c].specgram(waveform[c], Fs=sample_rate)\n",
        "    if num_channels > 1:\n",
        "      axes[c].set_ylabel(f'Channel {c+1}')\n",
        "    if xlim:\n",
        "      axes[c].set_xlim(xlim)\n",
        "  figure.suptitle(title)\n",
        "  plt.show(block=False)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown V·∫Ω waveform `plot_waveform(wave, sr, title, xlim, ylim)`\n",
        "\n",
        "def plot_waveform(waveform, sample_rate, title=\"Waveform\", xlim=None, ylim=None):\n",
        "  # Tensor --> Numpy\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  time_axis = torch.arange(0, num_frames) / sample_rate\n",
        "\n",
        "  figure, axes = plt.subplots(num_channels, 1)\n",
        "  if num_channels == 1:\n",
        "    axes = [axes]\n",
        "\n",
        "  # Plot waveform for each channel\n",
        "  for c in range(num_channels):\n",
        "    axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
        "    axes[c].grid(True)\n",
        "    if num_channels > 1:\n",
        "      axes[c].set_ylabel(f'Channel {c+1}')\n",
        "    if xlim:\n",
        "      axes[c].set_xlim(xlim)\n",
        "    if ylim:\n",
        "      axes[c].set_ylim(ylim)\n",
        "  figure.suptitle(title)\n",
        "  plt.show(block=False)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown V·∫Ω spectrogram `plot_spectrogram(spec, axs, title, ylabel, aspect, xmax)`\n",
        "\n",
        "def plot_spectrogram(spec, fig=None, axs=None, title=None, ylabel='freq_bin', aspect='auto', xmax=None):\n",
        "  if axs is None:\n",
        "    fig, axs = plt.subplots(1, 1)\n",
        "  axs.set_title(title or 'Spectrogram (db)')\n",
        "  axs.set_ylabel(ylabel)\n",
        "  axs.set_xlabel('frame')\n",
        "  im = axs.imshow(log_spectrogram(spec), origin='lower', aspect=aspect)\n",
        "  if xmax:\n",
        "    axs.set_xlim((0, xmax))\n",
        "  fig.colorbar(im, ax=axs)\n",
        "\n",
        "\n",
        "\n",
        "#@markdown Hi·ªÉn th·ªã audio box `play_audio(wave, sr)`\n",
        "\n",
        "def play_audio(waveform, sample_rate):\n",
        "  waveform = waveform.numpy()\n",
        "\n",
        "  num_channels, num_frames = waveform.shape\n",
        "  if num_channels == 1:\n",
        "    display(Audio(waveform[0], rate=sample_rate))\n",
        "  elif num_channels == 2:\n",
        "    display(Audio((waveform[0], waveform[1]), rate=sample_rate))\n",
        "  else:\n",
        "    raise ValueError(\"Waveform with more than 2 channels are not supported.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1nyBy3_mgnh"
      },
      "source": [
        "# Function for preparing dataset/dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlMNZ1_rqxex"
      },
      "source": [
        "## T√°ch validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyhxy5nzXdvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b02beef0-0eeb-48c2-e3b2-5c545dde6fdf"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "idx_train, idx_val = train_test_split(train_meta.index,train_size=val_split)\n",
        "\n",
        "val_meta = train_meta.iloc[idx_val]\n",
        "train_meta = train_meta.iloc[idx_train]\n",
        "\n",
        "display(len(train_meta))\n",
        "display(len(val_meta))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "959"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "240"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GxCO0fvq1yr"
      },
      "source": [
        "## Dataset class v√† c√°c transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkGwlGUh6iM0",
        "cellView": "form"
      },
      "source": [
        "#@title Class `AICOVIDDataset`\n",
        "import tempfile, shutil\n",
        "import weakref\n",
        "import pickle\n",
        "\n",
        "class AICOVIDDataset(Dataset):\n",
        "    def __init__(self, \n",
        "                 meta_df: pd.DataFrame=None, \n",
        "                 audio_transforms: torch.nn.ModuleList=None, \n",
        "                 chunking: torch.nn.Module=None) -> None:\n",
        "        \n",
        "        # Create temporary folder to dump preprocessed data\n",
        "        self._temp_folder = tempfile.mkdtemp()\n",
        "        self._finalizer = weakref.finalize(self, shutil.rmtree, self._temp_folder)\n",
        "\n",
        "        self.meta_df = meta_df\n",
        "        self.file_paths = []\n",
        "        self.idxs = [] \n",
        "        \n",
        "        if meta_df is None: return  # Allow empty dataset for loading from gdrive later\n",
        "\n",
        "        for id, file in enumerate(self.meta_df['file_path']):\n",
        "            specs = self._read_spec_audio(file, audio_transforms)\n",
        "            if chunking:\n",
        "                for spec in specs:\n",
        "                    paths = self._dump_to_disk(chunking(spec))\n",
        "                    self.file_paths += paths\n",
        "                    self.idxs += [id]*len(paths)\n",
        "            else:\n",
        "                paths = self._dump_to_disk(specs)\n",
        "                self.file_paths += paths\n",
        "                self.idxs += [id]*len(paths)\n",
        "\n",
        "        # Pickle for backup later\n",
        "        with open(f\"{self._temp_folder}/meta_df.pkl\",'wb') as tmp:\n",
        "            pickle.dump(self.meta_df, tmp)\n",
        "        with open(f\"{self._temp_folder}/file_paths.pkl\",'wb') as tmp:\n",
        "            pickle.dump(self.file_paths, tmp)\n",
        "        with open(f\"{self._temp_folder}/idxs.pkl\",'wb') as tmp:\n",
        "            pickle.dump(self.idxs, tmp)\n",
        "            \n",
        "\n",
        "    def _read_spec_audio(self, \n",
        "                         file: str,\n",
        "                         transforms: torch.nn.ModuleList=None) -> list:\n",
        "        wave = read_resample_audio(file, 8000).cuda()\n",
        "        if transforms:\n",
        "            specs = [trans(wave) for trans in transforms]\n",
        "        else:\n",
        "            specs = [wave]\n",
        "        return specs\n",
        "\n",
        "    def _dump_to_disk(self, specs: list or torch.Tensor) -> list:\n",
        "        file_paths = []\n",
        "        for spec in specs:\n",
        "            fd, path = tempfile.mkstemp(suffix=\".pt\", dir=self._temp_folder)\n",
        "            with os.fdopen(fd, 'wb') as tmp:\n",
        "                # Clone to prevent view preserving of PyTorch\n",
        "                # also moving tensor to cpu so when load up\n",
        "                # pytorch will not moving them to gpu bebforehand!\n",
        "                torch.save(spec.cpu(), tmp)\n",
        "            file_paths.append(path)\n",
        "        return file_paths\n",
        "\n",
        "    def backup_to_drive(self, folder_id: str, upload_name: str):\n",
        "        if self.meta_df is None:\n",
        "            raise NamedError(\"Cannot backup an empty dataset.\")\n",
        "        \n",
        "        os.system(f'zip -j ./{upload_name} {self._temp_folder}/*')\n",
        "        drive.Upload(upload_name, folder_id)\n",
        "        os.remove(upload_name)\n",
        "\n",
        "\n",
        "    def load_from_drive(self, folder_id: str, backuped_name: str):\n",
        "        drive.Download(backuped_name, folder_id)\n",
        "        os.system(f'unzip -o {backuped_name} -d {self._temp_folder}')\n",
        "        os.remove(backuped_name)\n",
        "        with open(f\"{self._temp_folder}/meta_df.pkl\",'rb') as tmp:\n",
        "            self.meta_df = pickle.load(tmp)\n",
        "        with open(f\"{self._temp_folder}/idxs.pkl\",'rb') as tmp:\n",
        "            self.idxs = pickle.load(tmp)\n",
        "        with open(f\"{self._temp_folder}/file_paths.pkl\",'rb') as tmp:\n",
        "            self.file_paths = pickle.load(tmp)\n",
        "        # Replace old tmp dir with current tmp dir\n",
        "        for i, path in enumerate(self.file_paths):\n",
        "            self.file_paths[i] = self._temp_folder+'/'+path.split('/')[-1]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        spec = torch.load(self.file_paths[idx])\n",
        "        meta = self.meta_df.iloc[self.idxs[idx]]\n",
        "        try:\n",
        "            label = torch.tensor(meta['assessment_result'])\n",
        "        except KeyError:\n",
        "            label = None\n",
        "        id = meta['uuid']\n",
        "        gender = meta['subject_gender']\n",
        "        age = meta['subject_age']\n",
        "\n",
        "        return spec, label, id, gender, age"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqpTaQ4jsNAn"
      },
      "source": [
        "# ƒê·ªçc, nh√¢n b·∫£n v√† r√∫t tr√≠ch mel spectrogram\n",
        "basic_transform = torch.nn.Sequential(mel_spectrogram,\n",
        "                                      log_spectrogram,\n",
        "                                      StandardScaler())\n",
        "transform0 = torch.nn.Sequential(basic_transform).cuda()\n",
        "transform1 = torch.nn.Sequential(NoiseInject([noise.cuda()], 8),\n",
        "                                 basic_transform).cuda()\n",
        "transform2 = torch.nn.Sequential(NoiseInject([noise.cuda()], 16),\n",
        "                                 basic_transform).cuda()\n",
        "transform3 = torch.nn.Sequential(RoomReverb([rir.cuda()]), \n",
        "                                 NoiseInject([noise.cuda()], 8), \n",
        "                                 PhoneSim(),\n",
        "                                 basic_transform).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37j76Vm4q9P2"
      },
      "source": [
        "## Collate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpswQ8ayvZOo"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_pad_seq_fn(batch):\n",
        "    # A data tuple has the form:\n",
        "    # spec, label\n",
        "\n",
        "    specs, labels = [], []\n",
        "\n",
        "    # Gather in lists, and encode labels as indices\n",
        "    for spec, label, _, _, _ in batch:\n",
        "        specs += [spec.permute(2,0,1)]\n",
        "        labels += [label]\n",
        "\n",
        "    # Group the list of tensors into a batched tensor\n",
        "    specs = pad_sequence(specs, batch_first=True).permute(0,2,3,1)\n",
        "    try:\n",
        "      labels = torch.stack(labels)\n",
        "      return specs, labels\n",
        "    except:\n",
        "      return specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpCUnnvX2Ajc"
      },
      "source": [
        "def collate_fn(batch):\n",
        "    # A data tuple has the form:\n",
        "    # spec, label\n",
        "\n",
        "    specs, labels = [], []\n",
        "\n",
        "    # Gather in lists, and encode labels as indices\n",
        "    for spec, label, _, _, _ in batch:\n",
        "        specs += [spec]\n",
        "        labels += [label]\n",
        "\n",
        "    # Group the list of tensors into a batched tensor\n",
        "    specs = torch.stack(specs)\n",
        "    try:\n",
        "      labels = torch.stack(labels)\n",
        "      return specs, labels\n",
        "    except:\n",
        "      return specs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA3wFkAMyA56"
      },
      "source": [
        "num_workers = 2\n",
        "pin_memory = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ-sePwC7BDh"
      },
      "source": [
        "# Lightning module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJggwl5C2OpG"
      },
      "source": [
        "class AICOVIDModule(pl.LightningModule):\n",
        "    def __init__(self, model, optim_config: dict, augment=None):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.augment = augment\n",
        "        self.optim_config = optim_config\n",
        "\n",
        "\n",
        "    ########################\n",
        "    # For inference/training forward\n",
        "    ########################\n",
        "\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        Do a forward pass for training/validating\n",
        "        '''\n",
        "        return self.model(x).squeeze(-1)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx: int , dataloader_idx: int = None):\n",
        "        '''\n",
        "        Do inference\n",
        "        '''\n",
        "        y_hat = self(batch)\n",
        "        y_hat = torch.sigmoid(y_hat)\n",
        "        y_hat = torch.where(y_hat > 0.5, 1, 0) # Kh√¥ng d√πng argmax ƒë∆∞·ª£c v√¨ ch·ªâ tr·∫£ v·ªÅ 1 gi√° tr·ªã\n",
        "        return y_hat\n",
        "\n",
        "\n",
        "    ########################\n",
        "    # Main function for train/val/test\n",
        "    ########################\n",
        "    \n",
        "    def loss_fn(self, logits, labels):\n",
        "        '''\n",
        "        Calculate loss ~manually since we need to handle autocast~\n",
        "        '''\n",
        "        # with torch.cuda.amp.autocast(False):\n",
        "        #     loss = F.binary_cross_entropy(logits.float(), labels.float())\n",
        "\n",
        "        loss = F.binary_cross_entropy_with_logits(logits, labels.float())\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def _shared_step(self, xs, ys):\n",
        "        '''\n",
        "        Shared step that happened in both train/val step\n",
        "        '''\n",
        "        logits = self(xs)\n",
        "        # negative log-likelihood for a tensor of size (batch x n_output)\n",
        "        loss = self.loss_fn(logits, ys)\n",
        "        # take sigmoid of logits to get probs\n",
        "        logits = torch.sigmoid(logits)\n",
        "        return loss, logits\n",
        "\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        x, y = train_batch\n",
        "        if self.augment:\n",
        "            x = self.augment(x)\n",
        "        loss, logits = self._shared_step(x, y)\n",
        "        self.log('train/loss_step', loss)        \n",
        "        return {'loss': loss, 'probs': logits, \"targets\": y}\n",
        "\n",
        "    \n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        x, y = val_batch\n",
        "        loss, logits = self._shared_step(x, y)\n",
        "        return {'loss': loss, 'probs': logits, \"targets\": y}\n",
        "\n",
        "    \n",
        "    def test_step(self, test_batch, batch_idx):\n",
        "        x, y = test_batch\n",
        "        loss, logits = self._shared_step(x, y)\n",
        "        return {'loss': loss, 'probs': logits, \"targets\": y}\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = self.optim_config['optimizer']\n",
        "        lr = self.optim_config['lr']\n",
        "        lrschedule = self.optim_config['scheduler']\n",
        "\n",
        "        ### SET OPTIMIZER\n",
        "\n",
        "        if optimizer['type'] == 'Adam':\n",
        "            self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
        "        elif optimizer['type'] == 'SGD':\n",
        "            self.optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
        "        else:\n",
        "            raise ValueError(f\"Optimizer not implemented: {optimizer}\")\n",
        "\n",
        "        # Number of gradient calculations per epoch\n",
        "        grad_update_step = math.ceil( len(self.train_dataloader()) / self.trainer.accumulate_grad_batches )\n",
        "        \n",
        "        ### SET SCHEDULER\n",
        "        \n",
        "        if lrschedule['type'] == \"OneCycleLR\":\n",
        "            # OneCycleLR\n",
        "            self.scheduler = torch.optim.lr_scheduler.OneCycleLR(self.optimizer, max_lr=lr, \n",
        "                                                             steps_per_epoch=grad_update_step,\n",
        "                                                             epochs=self.trainer.max_epochs)\n",
        "        elif lrschedule['type'] == \"CosineAnnealingLR\":\n",
        "            # CosineAnnealing\n",
        "            self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=10*grad_update_step)\n",
        "        elif lrschedule['type'] == \"None\":\n",
        "            # Set constant scheduler to prevent\n",
        "            self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lr_lambda=lambda epoch: lr)\n",
        "        else:\n",
        "            raise ValueError(f\"Scheduler not implemented: {lrschedule}\")\n",
        "\n",
        "        ### COMPLETE SETUP\n",
        "\n",
        "        if self.scheduler:\n",
        "            sched = {\n",
        "                'scheduler': self.scheduler,\n",
        "                'interval': 'step'\n",
        "            }\n",
        "            return [self.optimizer], [sched]\n",
        "        else:\n",
        "            return self.optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGMCT2ocfb9A"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt9IviIkfqt7"
      },
      "source": [
        "from pytorch_lightning.callbacks import Callback, LearningRateMonitor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuxxKOO_FCaj",
        "cellView": "form"
      },
      "source": [
        "#@markdown Upload lightning_logs folder to gdrive (**depricated** since we're using Neptune logger)\n",
        "\n",
        "class BackupCallback(Callback):\n",
        "    def _backup(self):\n",
        "        os.system(f\"zip -r ./tmp_lightning_logs_{experiment_id}.zip ./lightning_logs\")\n",
        "        try:\n",
        "            drive.Upload(f\"tmp_lightning_logs_{experiment_id}.zip\", model_zoo)\n",
        "        except:\n",
        "            print(\"Upload failed.\")\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        if (trainer.current_epoch+1)%20 == 0:\n",
        "            self._backup()\n",
        "            print(f\"Lightning logs backuped at epoch {trainer.current_epoch}.\")\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        self._backup()\n",
        "        print(f\"Lightning logs backuped at the end of training.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "dpxqdHn-3mfP"
      },
      "source": [
        "#@markdown Helper function: confusion matrix tensor --> Neptune file\n",
        "from neptune.new.types import File\n",
        "\n",
        "def comfmat_to_neptune_html(confmat):\n",
        "    return File.as_html(pd.DataFrame(confmat.cpu().numpy()))\n",
        "\n",
        "def comfmat_to_neptune_img(confmat):\n",
        "    df = pd.DataFrame(confmat.cpu().numpy().astype(int))\n",
        "    plt.close('all')\n",
        "    fig = plt.figure(figsize = (7,7))\n",
        "    fig.add_subplot(sns.heatmap(df, annot=True, cmap=\"YlGnBu\", fmt=\"d\"))\n",
        "    return File.as_image(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "x1bvgNgkvKzG"
      },
      "source": [
        "#@markdown Logging metrics to Neptune logger\n",
        "from torchmetrics import Accuracy, MetricCollection, Precision, Recall, ConfusionMatrix, AUC, AverageMeter\n",
        "\n",
        "class LogMetricsNeptune(Callback):\n",
        "    def on_pretrain_routine_start(self, trainer, pl_module):\n",
        "        device = pl_module.device\n",
        "        self.metrics = MetricCollection([Accuracy(compute_on_step=False), \n",
        "                                         Precision(compute_on_step=False), \n",
        "                                         Recall(compute_on_step=False), \n",
        "                                         AUC(reorder=True, compute_on_step=False)]).to(device)\n",
        "        self.comfmat = ConfusionMatrix(num_classes=2, compute_on_step=False).to(device)\n",
        "        self.avg_loss = AverageMeter().to(device)\n",
        "\n",
        "    def _update_metrics(self, **kwargs):\n",
        "        # Prevent autocast since sometime it turn y to float, cause metric raise error...\n",
        "        probs = kwargs['probs']\n",
        "        targets = kwargs['targets']\n",
        "        loss = kwargs['loss']\n",
        "        with torch.cuda.amp.autocast(False):\n",
        "            self.metrics(probs, targets)\n",
        "            self.comfmat(probs, targets)\n",
        "            self.avg_loss(loss)\n",
        "\n",
        "\n",
        "    def _log_metrics(self, trainer, type: str):\n",
        "        comfmat_file = comfmat_to_neptune_img(self.comfmat.compute())\n",
        "        \n",
        "        if trainer.logger is None:\n",
        "            return\n",
        "        # Catch exception from stopped logger\n",
        "        try:\n",
        "            # Log confusion matrix\n",
        "            trainer.logger.experiment[f'comfmat/{type}/latest'].upload(comfmat_file)\n",
        "            trainer.logger.experiment[f'comfmat/{type}/series'].log(comfmat_file)\n",
        "            \n",
        "            # Log metrics\n",
        "            trainer.logger.experiment[f'metrics/{type}/loss'].log(self.avg_loss.compute())\n",
        "            for key, value in self.metrics.compute().items():\n",
        "                trainer.logger.experiment[f'metrics/{type}/{key}'].log(value)\n",
        "        except Exception as e:\n",
        "            if type(e).__name__ == \"InactiveRunException\":\n",
        "                print(\"Warning: Neptune logger has stopped running. Logging couldn't be done.\")\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "\n",
        "    def _print_metrics(self):\n",
        "        print(\"Loss: \", self.avg_loss.compute().item())\n",
        "        for key, value in self.metrics.compute().items():\n",
        "            print(f\"{key}: {value}\")\n",
        "        \n",
        "\n",
        "    def _reset_metrics(self):\n",
        "        self.comfmat.reset()\n",
        "        self.metrics.reset()\n",
        "        self.avg_loss.reset()\n",
        "\n",
        "\n",
        "    def on_train_batch_end(self, trainer, pl_module, \n",
        "                           outputs, batch, batch_idx, dataloader_idx):\n",
        "        self._update_metrics(probs=outputs[\"probs\"], targets=outputs[\"targets\"], loss=outputs[\"loss\"])\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        self._log_metrics(trainer, \"train\")\n",
        "        self._reset_metrics()\n",
        "\n",
        "    def on_validation_batch_end(self, trainer, pl_module, \n",
        "                           outputs, batch, batch_idx, dataloader_idx):\n",
        "        self._update_metrics(probs=outputs[\"probs\"], targets=outputs[\"targets\"], loss=outputs[\"loss\"])\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        self._log_metrics(trainer, \"val\")\n",
        "        self._reset_metrics()\n",
        "\n",
        "    def on_test_batch_end(self, trainer, pl_module, \n",
        "                           outputs, batch, batch_idx, dataloader_idx):\n",
        "        self._update_metrics(probs=outputs[\"probs\"], targets=outputs[\"targets\"], loss=outputs[\"loss\"])\n",
        "\n",
        "    def on_test_epoch_end(self, trainer, pl_module):\n",
        "        self._log_metrics(trainer, \"test\")\n",
        "        self._print_metrics()\n",
        "        self._reset_metrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3mtpjC95X1Io"
      },
      "source": [
        "#@markdown Save last checkpoint to Neptune logger\n",
        "import glob\n",
        "\n",
        "class SaveCheckpointNeptune(Callback):\n",
        "    def __init__(self, interval: int=1):\n",
        "        self.interval = interval\n",
        "\n",
        "\n",
        "    def _upload_latest_ckp(self, trainer):\n",
        "        if trainer.logger is None:\n",
        "            return\n",
        "        try:\n",
        "            ckp_dir = \"/\".join([trainer.default_root_dir, trainer.logger.name, trainer.logger.version])\n",
        "            ckp_file = glob.glob(ckp_dir+\"/checkpoints/*.ckpt\")[0]\n",
        "            trainer.logger.experiment[f'checkpoints/latest'].upload(ckp_file)\n",
        "            print(\"Backuped \", ckp_file)\n",
        "        except Exception as e:\n",
        "            if type(e).__name__ == \"InactiveRunException\":\n",
        "                print(\"Warning: Neptune logger has stopped running. Logging couldn't be done.\")\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module):\n",
        "        if (trainer.current_epoch+1)%self.interval != 0:\n",
        "            return\n",
        "        self._upload_latest_ckp(trainer)\n",
        "\n",
        "\n",
        "    def on_train_end(self, trainer, pl_module):\n",
        "        self._upload_latest_ckp(trainer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y9lvxslO4sU"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8x6CcaJTyVJ2"
      },
      "source": [
        "## NiN ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeL6iyCEryP5"
      },
      "source": [
        "from torchvision.models import resnet\n",
        "\n",
        "class ResNet_NiN(resnet.ResNet):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        super(ResNet_NiN, self).__init__(**kwargs)\n",
        "        \n",
        "        # Reinit conv1 to have flexible in channels\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "        # NiN layer (without Conv2d)\n",
        "        nin_in_channels = self.fc.in_features\n",
        "        nin_out_channels = self.fc.out_features\n",
        "        self.nin = nn.Sequential(\n",
        "            nn.ReLU(), nn.Conv2d(nin_in_channels, nin_out_channels, kernel_size=1),\n",
        "            nn.ReLU(), nn.Conv2d(nin_out_channels, nin_out_channels, kernel_size=1))\n",
        "        self.maxpool = nn.AdaptiveMaxPool2d((1, 1))\n",
        "\n",
        "        # Delete unused layers\n",
        "        del self.avgpool\n",
        "        del self.fc\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.nin(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLR3pZnkyYRn"
      },
      "source": [
        "## ResNet for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acqFtBtK3gs1"
      },
      "source": [
        "from torchvision.models import resnet\n",
        "\n",
        "class CustomFCResNet(resnet.ResNet):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        fc_layers: list,\n",
        "        **kwargs\n",
        "    ) -> None:\n",
        "        super(CustomFCResNet, self).__init__(**kwargs)\n",
        "        \n",
        "        # Reinit conv1 to have flexible in channels\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "        # FC layer\n",
        "        num_filters = self.fc.in_features\n",
        "        fc = [nn.Linear(num_filters, fc_layers[0])]\n",
        "        for i in range(1, len(fc_layers)):\n",
        "            fc.append(nn.ReLU())\n",
        "            fc.append(nn.Linear(fc_layers[i-1], fc_layers[i]))\n",
        "        self.fc = nn.Sequential(*fc)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self._forward_impl(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl4ARbbJ7M-A"
      },
      "source": [
        "# Trainer params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6ouAXvOHxbd",
        "cellView": "form"
      },
      "source": [
        "#@markdown Make a Neptune logger instance `logger(name)`\n",
        "\n",
        "# from pytorch_lightning.loggers import NeptuneLogger\n",
        "\n",
        "# logger = lambda ver: NeptuneLogger(\n",
        "#     api_key=api_token,\n",
        "#     project_name='vulong61/AICOVID', \n",
        "#     experiment_name=f'{experiment_id}_{ver}',  # Optional\n",
        "# )\n",
        "\n",
        "#-------------New from neptune-----------------\n",
        "\n",
        "from neptune.new.integrations.pytorch_lightning import NeptuneLogger\n",
        "\n",
        "logger = lambda ver: NeptuneLogger(\n",
        "    api_key=api_token,\n",
        "    project='vulong61/AICOVID', \n",
        "    name=f'{experiment_id}_{ver}',  # Optional\n",
        "    tags=[],\n",
        "    close_after_fit=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzBCX9xE7OqI",
        "cellView": "form"
      },
      "source": [
        "#@title Trainer params\n",
        "mixed_precision = True #@param {type:\"boolean\"}\n",
        "swa = False #@param {type:\"boolean\"}\n",
        "max_epochs = 80 #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Dataloader params\n",
        "batch_size = 128 #@param {type:\"integer\"}\n",
        "grad_accum =  1#@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Logger name on Neptune.AI\n",
        "logger_exp_name = \"test_neptune_checkrun\" #@param {type:\"string\"}\n",
        "\n",
        "trainer_params = {\n",
        "    \"gpus\": 1,\n",
        "    \"precision\": 16 if mixed_precision else 32,\n",
        "    \"max_epochs\": max_epochs,\n",
        "    \"progress_bar_refresh_rate\": 10,\n",
        "    \"accumulate_grad_batches\": grad_accum,\n",
        "    \"stochastic_weight_avg\": swa,\n",
        "\n",
        "    \"callbacks\": [LogMetricsNeptune(),\n",
        "                  LearningRateMonitor(logging_interval=\"step\"),\n",
        "                  SaveCheckpointNeptune(10)],\n",
        "\n",
        "    # flag for debugging\n",
        "    \"track_grad_norm\": 2,\n",
        "    \"terminate_on_nan\": True,\n",
        "    \"weights_summary\": 'full',\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yQrcjYYtCeV",
        "cellView": "form"
      },
      "source": [
        "#@title Optimizer params\n",
        "lr = 0.025 #@param {type:\"number\"}\n",
        "optimizer = \"SGD\" #@param [\"SGD\", \"Adam\"]\n",
        "scheduler = \"OneCycleLR\" #@param [\"OneCycleLR\", \"CosineAnnealingLR\", \"None\"]\n",
        "optim_config = {\n",
        "    'optimizer': {\"type\": optimizer,\n",
        "                  \"kawrgs\": None},\n",
        "    'scheduler': {\"type\": scheduler,\n",
        "                  \"kawrgs\": None},\n",
        "    'lr': lr,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kOPNwZBmUX7"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC9H2rfap_hJ"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEemzQd6650h",
        "cellView": "form"
      },
      "source": [
        "#@markdown Test dataloader with dataset backuped\n",
        "test_set = AICOVIDDataset()\n",
        "test_set.load_from_drive(datadump_folder, \"type1_val_dump.zip\")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    collate_fn=collate_pad_seq_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ztDaiXJpHFZ"
      },
      "source": [
        "train_set = AICOVIDDataset(train_meta, torch.nn.ModuleList([transform0,transform1,transform2,transform3]), chunking=AudioChunking(400, 200))\n",
        "val_set = AICOVIDDataset(val_meta, torch.nn.ModuleList([transform0]), chunking=AudioChunking(400, 200))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTy3Zayd3H3D"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xcTzY1smd1H"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8spWmDjjmcqK",
        "outputId": "169f2066-42fa-4737-cdb8-523b5dfe59bd"
      },
      "source": [
        "exp_logger = logger(logger_exp_name)\n",
        "# Log hyperparam to logger for convinient\n",
        "exp_logger.experiment['hyperparam'] = trainer_params\n",
        "exp_logger.experiment['hyperparam'] = optim_config\n",
        "\n",
        "resnet18 = CustomFCResNet(in_channels=1, fc_layers=[1], block=resnet.BasicBlock, layers=[2, 2, 2, 2])\n",
        "model = AICOVIDModule(resnet18, optim_config=optim_config, augment=SpecAugment(time_W=100, freq_W=50, T=80))\n",
        "trainer = pl.Trainer(**trainer_params, logger=exp_logger, max_steps=200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://app.neptune.ai/vulong61/AICOVID/e/AIC-71\n",
            "Remember to stop your run once you‚Äôve finished logging your metadata (https://docs.neptune.ai/api-reference/run#stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Using native 16bit precision.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fa9ad4c423f94e2d82336c7875edf8fa",
            "99191948268e4d3d9c9d0afa08a4bef1",
            "fb199159c2ba4082b91b51c42e0f1569",
            "d2823aaf3c8749e685347875163b15f8",
            "03085d9d46eb4d7ea7c5d7a39ef4e472",
            "14f9bf82827f45a1a4bd1ad967d1416f",
            "159db56ce0d8458088c9a72499908571",
            "08d7b75a30b1450dbe7b819903367e52",
            "4913c84fd74347e6b958abb5ac3a8de3",
            "b2ec18fcd8ce4b278413fcaadca50091",
            "9c360fed825142fda9cca5d1a718186f",
            "ecc4bdb3bc0c4cc783285c77205479dc",
            "813950ef55294d8c9c9333cb4a1d3140",
            "40ce94f506b5415f9f7e96a0754c1b60",
            "ad7a24f0fabf41a694f65dc2fe6aa962",
            "a321e1efa46a483ab689e9c5698703d1",
            "f0eb953f1800466e9cea748284cc7f77",
            "1675202443ee49968ff98b7150180722",
            "65f6beee2c5c44178c0bc9a5b0978451",
            "c6a76d7514464d519a5db4f9c75471de",
            "2d2cda7ea3a444a9a162b836e66c0b49",
            "0616081f2b6547cf90094d1e86c78c70",
            "b41011dd80a7466ab85c5ed32b447ebb",
            "71b9c6bde7324719b2704372cd013cba"
          ]
        },
        "id": "UtkN__wPmcqM",
        "outputId": "f1d2ea70-ff42-4c26-d051-9211f7ddde31"
      },
      "source": [
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:37: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "\n",
            "   | Name                        | Type              | Params\n",
            "-------------------------------------------------------------------\n",
            "0  | model                       | CustomFCResNet    | 11.2 M\n",
            "1  | model.conv1                 | Conv2d            | 3.1 K \n",
            "2  | model.bn1                   | BatchNorm2d       | 128   \n",
            "3  | model.relu                  | ReLU              | 0     \n",
            "4  | model.maxpool               | MaxPool2d         | 0     \n",
            "5  | model.layer1                | Sequential        | 147 K \n",
            "6  | model.layer1.0              | BasicBlock        | 74.0 K\n",
            "7  | model.layer1.0.conv1        | Conv2d            | 36.9 K\n",
            "8  | model.layer1.0.bn1          | BatchNorm2d       | 128   \n",
            "9  | model.layer1.0.relu         | ReLU              | 0     \n",
            "10 | model.layer1.0.conv2        | Conv2d            | 36.9 K\n",
            "11 | model.layer1.0.bn2          | BatchNorm2d       | 128   \n",
            "12 | model.layer1.1              | BasicBlock        | 74.0 K\n",
            "13 | model.layer1.1.conv1        | Conv2d            | 36.9 K\n",
            "14 | model.layer1.1.bn1          | BatchNorm2d       | 128   \n",
            "15 | model.layer1.1.relu         | ReLU              | 0     \n",
            "16 | model.layer1.1.conv2        | Conv2d            | 36.9 K\n",
            "17 | model.layer1.1.bn2          | BatchNorm2d       | 128   \n",
            "18 | model.layer2                | Sequential        | 525 K \n",
            "19 | model.layer2.0              | BasicBlock        | 230 K \n",
            "20 | model.layer2.0.conv1        | Conv2d            | 73.7 K\n",
            "21 | model.layer2.0.bn1          | BatchNorm2d       | 256   \n",
            "22 | model.layer2.0.relu         | ReLU              | 0     \n",
            "23 | model.layer2.0.conv2        | Conv2d            | 147 K \n",
            "24 | model.layer2.0.bn2          | BatchNorm2d       | 256   \n",
            "25 | model.layer2.0.downsample   | Sequential        | 8.4 K \n",
            "26 | model.layer2.0.downsample.0 | Conv2d            | 8.2 K \n",
            "27 | model.layer2.0.downsample.1 | BatchNorm2d       | 256   \n",
            "28 | model.layer2.1              | BasicBlock        | 295 K \n",
            "29 | model.layer2.1.conv1        | Conv2d            | 147 K \n",
            "30 | model.layer2.1.bn1          | BatchNorm2d       | 256   \n",
            "31 | model.layer2.1.relu         | ReLU              | 0     \n",
            "32 | model.layer2.1.conv2        | Conv2d            | 147 K \n",
            "33 | model.layer2.1.bn2          | BatchNorm2d       | 256   \n",
            "34 | model.layer3                | Sequential        | 2.1 M \n",
            "35 | model.layer3.0              | BasicBlock        | 919 K \n",
            "36 | model.layer3.0.conv1        | Conv2d            | 294 K \n",
            "37 | model.layer3.0.bn1          | BatchNorm2d       | 512   \n",
            "38 | model.layer3.0.relu         | ReLU              | 0     \n",
            "39 | model.layer3.0.conv2        | Conv2d            | 589 K \n",
            "40 | model.layer3.0.bn2          | BatchNorm2d       | 512   \n",
            "41 | model.layer3.0.downsample   | Sequential        | 33.3 K\n",
            "42 | model.layer3.0.downsample.0 | Conv2d            | 32.8 K\n",
            "43 | model.layer3.0.downsample.1 | BatchNorm2d       | 512   \n",
            "44 | model.layer3.1              | BasicBlock        | 1.2 M \n",
            "45 | model.layer3.1.conv1        | Conv2d            | 589 K \n",
            "46 | model.layer3.1.bn1          | BatchNorm2d       | 512   \n",
            "47 | model.layer3.1.relu         | ReLU              | 0     \n",
            "48 | model.layer3.1.conv2        | Conv2d            | 589 K \n",
            "49 | model.layer3.1.bn2          | BatchNorm2d       | 512   \n",
            "50 | model.layer4                | Sequential        | 8.4 M \n",
            "51 | model.layer4.0              | BasicBlock        | 3.7 M \n",
            "52 | model.layer4.0.conv1        | Conv2d            | 1.2 M \n",
            "53 | model.layer4.0.bn1          | BatchNorm2d       | 1.0 K \n",
            "54 | model.layer4.0.relu         | ReLU              | 0     \n",
            "55 | model.layer4.0.conv2        | Conv2d            | 2.4 M \n",
            "56 | model.layer4.0.bn2          | BatchNorm2d       | 1.0 K \n",
            "57 | model.layer4.0.downsample   | Sequential        | 132 K \n",
            "58 | model.layer4.0.downsample.0 | Conv2d            | 131 K \n",
            "59 | model.layer4.0.downsample.1 | BatchNorm2d       | 1.0 K \n",
            "60 | model.layer4.1              | BasicBlock        | 4.7 M \n",
            "61 | model.layer4.1.conv1        | Conv2d            | 2.4 M \n",
            "62 | model.layer4.1.bn1          | BatchNorm2d       | 1.0 K \n",
            "63 | model.layer4.1.relu         | ReLU              | 0     \n",
            "64 | model.layer4.1.conv2        | Conv2d            | 2.4 M \n",
            "65 | model.layer4.1.bn2          | BatchNorm2d       | 1.0 K \n",
            "66 | model.avgpool               | AdaptiveAvgPool2d | 0     \n",
            "67 | model.fc                    | Sequential        | 513   \n",
            "68 | model.fc.0                  | Linear            | 513   \n",
            "69 | augment                     | SpecAugment       | 0     \n",
            "70 | augment.time_masking        | TimeMasking       | 0     \n",
            "-------------------------------------------------------------------\n",
            "11.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "11.2 M    Total params\n",
            "44.683    Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa9ad4c423f94e2d82336c7875edf8fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Global seed set to 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4913c84fd74347e6b958abb5ac3a8de3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0eb953f1800466e9cea748284cc7f77",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Backuped  /content/NeptuneLogger/AIC-71/checkpoints/epoch=1-step=199.ckpt\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8CPhdRxwVZA"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG9B5DFxmcqO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668,
          "referenced_widgets": [
            "5e272f66442a402fbfc0ac801d6fce6d",
            "2e1d1f38af9f4f7f8e88c2bbd321a362",
            "78403d7821314514aef4b5beb7b8a523",
            "babddf622a0944919716dcaa226117c6",
            "2c0b996d8d214b529d5882232bed9a3a",
            "8f87f31200fe4d24b00143c7aebce273",
            "c8c6b8ebdd084fe8aa4c8c85b94705ba",
            "3c375bd3295c4017a4179af4f70407f7"
          ]
        },
        "outputId": "f012561d-53a4-415a-8760-58aff85e5651"
      },
      "source": [
        "trainer.test(test_dataloaders=test_loader)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e272f66442a402fbfc0ac801d6fce6d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(0.6799, device='cuda:0')\n",
            "Accuracy: 0.6041666865348816\n",
            "Precision: 0.5392156839370728\n",
            "Recall: 0.5339806079864502\n",
            "AUC: 0.328125\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHfFgV0uJL84"
      },
      "source": [
        "## Stop online logger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhu6ypKHJPAT",
        "outputId": "30ceb051-d4a9-403f-a5c0-3b19768c5827"
      },
      "source": [
        "exp_logger.experiment.stop()\n",
        "\n",
        "# M√¨nh kh√¥ng c√†i logger trong lightning module nh∆∞ng pl h·ªç t·ª± g·ªçi log khi trainer c√≥ logger\n",
        "# do ƒë√≥ c·∫ßn x√≥a logger ƒëi ƒë·ªÉ tr√°nh l·ªói khi ƒë√£ ng∆∞ng logger\n",
        "trainer.logger=None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shutting down background jobs, please wait a moment...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Waiting for the remaining 109 operations to synchronize with Neptune. Do not kill this process.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All 109 operations synced, thanks for waiting!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35ohhS599zA3"
      },
      "source": [
        "# Hyper-parameters report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIZ0DN6993LL"
      },
      "source": [
        "`exp001`: kh√¥ng h·ªôi t·ª• ƒë∆∞·ª£c\n",
        "\n",
        "- batch size: 128\n",
        "- **grad accumulate: 4**\n",
        "- max epoch: 80\n",
        "- **learning rate: 0.05**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DvXOMZk-E-d"
      },
      "source": [
        "`exp002`: exploding gradient at epoch 30th (?)\n",
        "- batch size: 128\n",
        "- grad accumulate: 1\n",
        "- max epoch: 80\n",
        "- **learning rate: 0.05**\n",
        "\n",
        "Error report:\n",
        "```python\n",
        "  Traceback (most recent call last):\n",
        "    File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
        "      self.run()\n",
        "    File \"/usr/lib/python3.7/threading.py\", line 870, in run\n",
        "      self._target(*self._args, **self._kwargs)\n",
        "    File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in _pin_memory_loop\n",
        "      r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
        "    File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n",
        "      return _ForkingPickler.loads(res)\n",
        "    File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\", line 289, in rebuild_storage_fd\n",
        "      fd = df.detach()\n",
        "    File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n",
        "      with _resource_sharer.get_connection(self._id) as conn:\n",
        "    File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
        "      c = Client(address, authkey=process.current_process().authkey)\n",
        "    File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n",
        "      c = SocketClient(address)\n",
        "    File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n",
        "      s.connect(address)\n",
        "  FileNotFoundError: [Errno 2] No such file or directory\n",
        "\n",
        "  /usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py:897: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
        "    rank_zero_warn('Detected KeyboardInterrupt, attempting graceful shutdown...')\n",
        "  Traceback (most recent call last):\n",
        "    File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
        "      send_bytes(obj)\n",
        "    File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
        "      self._send_bytes(m[offset:offset + size])\n",
        "    File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
        "      self._send(header + buf)\n",
        "    File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
        "      n = write(self._handle, buf)\n",
        "  BrokenPipeError: [Errno 32] Broken pipe\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE2UeEMdrj_l"
      },
      "source": [
        "`exp003`: Have a sign of convergence at epoch 40th, but as all experiments before, validation start to diverge too...\n",
        "- batch size: 128\n",
        "- grad accumulate: 1\n",
        "- max epoch: 80\n",
        "- learning rate: 0.025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N0BCPKB9EeJ"
      },
      "source": [
        "`exp004`: fail to converge. User warning t·∫°i epoch cu·ªëi khi d√πng SWA\n",
        "- batch size: 128\n",
        "- grad accumulate: 1\n",
        "- max epoch: 80\n",
        "- **learning rate: 0.01**\n",
        "- **LR Schedule: CosineAnnealing + SWA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWbcDpZBuWcX"
      },
      "source": [
        "`exp005`: c√≥ v·∫ª h·ªôi t·ª• t·ªët h∆°n Adam (t·ª´ epoch 20 l√† th·∫•y)\n",
        "- batch size: 128\n",
        "- grad accumulate: 1\n",
        "- max epoch: 80\n",
        "- learning rate: 0.025\n",
        "- **Optimizer: SGD**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NdDA6uC13XV"
      },
      "source": [
        "# Evaluating model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQtRaoeOwVDP"
      },
      "source": [
        "## Visualize misclassified samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsU1QJa8zSl_"
      },
      "source": [
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdXrW8PC1qUN"
      },
      "source": [
        "# Inference on private set for submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9e2e-cZQaUr"
      },
      "source": [
        "## Dataloader for private test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4K8aCudQemK"
      },
      "source": [
        "private_set = AICOVIDDataset(private_test_meta, torch.nn.ModuleList([transform0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXnRu87vi4II"
      },
      "source": [
        "private_loader = torch.utils.data.DataLoader(\n",
        "    private_set,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g50Y8yRZw6JT"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440,
          "referenced_widgets": [
            "4844be7af55d483bacf7105bc8631452",
            "36e09c71940442d194e139f6cafd37de",
            "aec298de56434afcb27c2ce4bad6ffdb",
            "7f8bbf647f654f009b527675a98f4c65",
            "430ff1b968884fe4ad3a9ddb50efd2b8",
            "9e1b8d2ae32e41d888b560b2b422e217",
            "3d33a13605754c238c4f3593b153434b",
            "8b109a2aad8c4a03abe8b2ec4c01dc71"
          ]
        },
        "id": "5glbNSnVw8AS",
        "outputId": "e9823a27-60a1-41a7-b19c-dd3316e9eb17"
      },
      "source": [
        "preds = trainer.predict(dataloaders=private_loader)\n",
        "preds = np.array([ts.item() for ts in preds])\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4844be7af55d483bacf7105bc8631452",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Predicting', layout=Layout(flex='2'), m‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mlQ9N2J1x21"
      },
      "source": [
        "# L∆∞u k·∫øt qu·∫£"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb7KoY9Mi4Oj",
        "cellView": "form"
      },
      "source": [
        "#@markdown L∆∞u l·∫°i model l√™n Google Drive\n",
        "if train_mode:\n",
        "  os.system('mkdir trained_models')\n",
        "  compressed_name = f'{zip_name}_model.zip'\n",
        "  torch.save(model.state_dict(), './trained_models/model_weights.pth')\n",
        "  \n",
        "  os.system(f'zip -j ./{compressed_name} ./trained_models/*')\n",
        "  drive.Upload(compressed_name, model_zoo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQMWT6nXWebS",
        "cellView": "form"
      },
      "source": [
        "#@markdown L∆∞u l·∫°i public test submission l√™n Google Drive\n",
        "submit_df = pd.DataFrame({'uuid': test_meta['uuid'],\n",
        "                          'assessment_result': preds})\n",
        "submit_df.to_csv('results.csv', index=False)\n",
        "\n",
        "# N√©n file\n",
        "os.system(f'zip -j ./{zip_name}.zip ./results.csv')\n",
        "\n",
        "drive.Upload(zip_name+'.zip', submission_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv4lQXEsrep-",
        "cellView": "form"
      },
      "source": [
        "#@markdown L∆∞u l·∫°i private test submission l√™n Google Drive\n",
        "submit_df = pd.DataFrame({'uuid': private_test_meta['uuid'],\n",
        "                          'assessment_result': preds})\n",
        "submit_df.to_csv('results.csv', index=False)\n",
        "\n",
        "# N√©n file\n",
        "os.system(f'zip -j ./{zip_name}_private_test.zip ./results.csv')\n",
        "\n",
        "drive.Upload(zip_name+'_private_test.zip', submission_folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHzHpd7InP8M",
        "cellView": "form"
      },
      "source": [
        "#@markdown Load model l∆∞u s·∫µn\n",
        "if not train_mode:\n",
        "  drive.Download(f'{zip_name}_model.zip', model_zoo)\n",
        "  os.system(f'unzip -o {zip_name}_model.zip')\n",
        "  model.load_state_dict(torch.load('model_weights.pth'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}